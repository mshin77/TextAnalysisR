search_result$results$heldout <- as.numeric(search_result$results$heldout)
search_result$results$residual <- as.numeric(search_result$results$residual)
search_result$results$semcoh <- as.numeric(search_result$results$semcoh)
search_result$results$lbound <- as.numeric(search_result$results$lbound)
p1 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~heldout,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Held-out Likelihood:", round(heldout, 3)),
hoverinfo = 'text'
)
p2 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~residual,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Residuals:", round(residual, 3)),
hoverinfo = 'text'
)
p3 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~semcoh,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Semantic Coherence:", round(semcoh, 3)),
hoverinfo = 'text'
)
p4 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~lbound,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Lower Bound:", round(lbound, 3)),
hoverinfo = 'text'
)
# Combine plots into a subplot
plotly::subplot(p1, p2, p3, p4, nrows = 2, margin = 0.1) %>%
plotly::layout(
title = list(
text = "Model Diagnostics by Number of Topics (K)",
font = list(size = 16)
),
showlegend = FALSE,
margin = list(t = 100, b = 150, l = 50, r = 50),
annotations = list(
list(
x = 0.25, y = 1.05, text = "Held-out Likelihood", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.75, y = 1.05, text = "Residuals", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.25, y = 0.5, text = "Semantic Coherence", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.75, y = 0.5, text = "Lower Bound", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.5, y = -0.2, text = "Number of Topics (K)", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'top',
font = list(size = 14)
)
),
yaxis = list(
title = list(
text = "Metric Value",
font = list(size = 14)
)
)
)
}
evaluate_optimal_topic_number(
dfm_object = dfm_object,
topic_range = 3:7,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
verbose = FALSE
)
install.packages("mgcv")
evaluate_optimal_topic_number <- function(dfm_object,
topic_range,
max.em.its = 75,
categorical_var = NULL,
continuous_var = NULL,
verbose = FALSE, ...) {
# Check if 'categorical_var' exists in docvars
if (!is.null(categorical_var) && !(categorical_var %in% names(quanteda::docvars(dfm_object)))) {
stop(paste("Categorical variable", categorical_var, "is missing in dfm_object's document variables."))
}
# Check if 'continuous_var' exists in docvars
if (!is.null(continuous_var) && !(continuous_var %in% names(quanteda::docvars(dfm_object)))) {
stop(paste("Continuous variable", continuous_var, "is missing in dfm_object's document variables."))
}
# Convert dfm_object to STM format
out <- quanteda::convert(dfm_object, to = "stm")
if (!all(c("meta", "documents", "vocab") %in% names(out))) {
stop("Conversion of dfm_object must result in 'meta', 'documents', and 'vocab'.")
}
meta <- out$meta
documents <- out$documents
vocab <- out$vocab
# Check alignment between meta and documents
if (nrow(meta) != length(documents)) {
stop("Number of rows in 'meta' does not match number of 'documents' after conversion.")
}
# Verify variable types
if (!is.null(categorical_var)) {
meta[[categorical_var]] <- as.factor(meta[[categorical_var]])
}
if (!is.null(continuous_var)) {
meta[[continuous_var]] <- as.numeric(meta[[continuous_var]])
if (any(is.na(meta[[continuous_var]]))) {
stop(paste("Continuous variable", continuous_var, "contains NA values. Please handle them before proceeding."))
}
}
# Print variable types
message("Variable types in metadata:")
print(str(meta))
# Construct prevalence formula using reformulate
terms <- c()
if (!is.null(categorical_var)) {
terms <- c(terms, categorical_var)
}
if (!is.null(continuous_var)) {
terms <- c(terms, paste0("s(", continuous_var, ")"))
}
if (length(terms) > 0) {
formula_string <- paste("~", paste(terms, collapse = " + "))
prevalence_formula <- as.formula(formula_string)
message("Prevalence formula: ", deparse(prevalence_formula))
} else {
prevalence_formula <- NULL
message("No prevalence formula specified.")
}
# Perform searchK with error handling
search_result <- tryCatch({
stm::searchK(
data = meta,
documents = documents,
vocab = vocab,
max.em.its = max.em.its,
init.type = "Spectral",
K = topic_range,
prevalence = prevalence_formula,
verbose = verbose,
...
)
}, error = function(e) {
stop("Error in stm::searchK: ", e$message)
})
print(search_result$results)
# Convert diagnostics to numeric
search_result$results$heldout <- as.numeric(search_result$results$heldout)
search_result$results$residual <- as.numeric(search_result$results$residual)
search_result$results$semcoh <- as.numeric(search_result$results$semcoh)
search_result$results$lbound <- as.numeric(search_result$results$lbound)
# Create plots
p1 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~heldout,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Held-out Likelihood:", round(heldout, 3)),
hoverinfo = 'text'
)
p2 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~residual,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Residuals:", round(residual, 3)),
hoverinfo = 'text'
)
p3 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~semcoh,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Semantic Coherence:", round(semcoh, 3)),
hoverinfo = 'text'
)
p4 <- plotly::plot_ly(
data = search_result$results,
x = ~K,
y = ~lbound,
type = 'scatter',
mode = 'lines+markers',
text = ~paste("K:", K, "<br>Lower Bound:", round(lbound, 3)),
hoverinfo = 'text'
)
# Combine plots into a subplot
plotly::subplot(p1, p2, p3, p4, nrows = 2, margin = 0.1) %>%
plotly::layout(
title = list(
text = "Model Diagnostics by Number of Topics (K)",
font = list(size = 16)
),
showlegend = FALSE,
margin = list(t = 100, b = 150, l = 50, r = 50),
annotations = list(
list(
x = 0.25, y = 1.05, text = "Held-out Likelihood", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.75, y = 1.05, text = "Residuals", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.25, y = 0.5, text = "Semantic Coherence", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.75, y = 0.5, text = "Lower Bound", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'bottom',
font = list(size = 14)
),
list(
x = 0.5, y = -0.2, text = "Number of Topics (K)", showarrow = FALSE,
xref = 'paper', yref = 'paper', xanchor = 'center', yanchor = 'top',
font = list(size = 14)
)
),
yaxis = list(
title = list(
text = "Metric Value",
font = list(size = 14)
)
)
)
}
evaluate_optimal_topic_number(
dfm_object = dfm_object,
topic_range = 3:7,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
verbose = FALSE
)
evaluate_optimal_topic_number(
dfm_object = dfm_object,
topic_range = 3:7,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
verbose = FALSE
)
df <- TextAnalysisR::SpecialEduTech
united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c("title", "keyword", "abstract"))
tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = "united_texts")
dfm_object <- quanteda::dfm(tokens)
word_frequency_plot <- TextAnalysisR::plot_word_frequency(dfm_object, n = 20)
word_frequency_plot
TextAnalysisR::evaluate_optimal_topic_number(
dfm_object = dfm_object,
topic_range = 5:30,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
verbose = FALSE)
TextAnalysisR::evaluate_optimal_topic_number(
dfm_object = dfm_object,
topic_range = 3:7,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
verbose = TRUE)
TextAnalysisR::plot_word_probabilities(
dfm_object = dfm_object,
topic_n = 5,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
top_term_n = 5,
ncol = 3,
height = 1000,
width = 800,
verbose = FALSE)
TextAnalysisR::plot_word_probabilities(
dfm_object = dfm_object,
topic_n = 5,
max.em.its = 75,
categorical_var = "reference_type",
continuous_var = "year",
top_term_n = 5,
ncol = 3,
height = 1000,
width = 800,
verbose = TRUE)
shiny::runApp('inst/TextAnalysisR.app')
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 100,
height = 700,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 500,
height = 700,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 200,
height = 700,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 150,
height = 700,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 100,
height = 700,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 100,
height = 800,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 120,
height = 800,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 150,
height = 800,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 150,
height = 1000,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 200,
height = 1000,
width = 800
)
TextAnalysisR::plot_word_co_occurrence_network(
dfm_object,
co_occur_n = 200,
height = 800,
width = 800
)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.3,
height = 800,
width = 800
)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.3,
height = 1000,
width = 800
)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.4,
height = 800,
width = 800)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 100,
corr_n = 0.3,
height = 800,
width = 800)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 100,
corr_n = 0.2,
height = 800,
width = 800)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.35,
height = 800,
width = 800)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.35,
height = 1000,
width = 800)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 50,
corr_n = 0.35,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 30,
corr_n = 0.35,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 30,
corr_n = 0.3,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 10,
corr_n = 0.4,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 10,
corr_n = 0.5,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 20,
corr_n = 0.5,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 20,
corr_n = 0.4,
height = 1000,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 20,
corr_n = 0.4,
height = 900,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 20,
corr_n = 0.45,
height = 900,
width = 900)
TextAnalysisR::plot_word_correlation_network(
dfm_object,
co_occur_n = 20,
corr_n = 0.45,
height = 1000,
width = 900)
stm_15 <- TextAnalysisR::stm_15
TextAnalysisR::word_frequency_trends(dfm_object,
stm_model = stm_15,
time_variable = "year",
selected_terms = c("calculator", "computer"),
height = 700,
width = 1000)
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
