% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/topic_modeling.R
\name{fit_embedding_model}
\alias{fit_embedding_model}
\title{Fit Embedding-based Topic Model}
\usage{
fit_embedding_model(
  texts,
  method = "umap_hdbscan",
  n_topics = 10,
  embedding_model = "all-MiniLM-L6-v2",
  clustering_method = "kmeans",
  similarity_threshold = 0.7,
  min_topic_size = 3,
  cluster_selection_method = "eom",
  umap_neighbors = 15,
  umap_min_dist = 0,
  umap_n_components = 5,
  representation_method = "c-tfidf",
  diversity = 0.5,
  reduce_outliers = TRUE,
  seed = 123,
  verbose = TRUE,
  precomputed_embeddings = NULL
)
}
\arguments{
\item{texts}{A character vector of texts to analyze.}

\item{method}{The topic modeling method: "umap_hdbscan" (uses BERTopic), "embedding_clustering", "hierarchical_semantic".}

\item{n_topics}{The number of topics to identify. For UMAP+HDBSCAN, use NULL or "auto" for automatic determination, or specify an integer.}

\item{embedding_model}{The embedding model to use (default: "all-MiniLM-L6-v2").}

\item{clustering_method}{The clustering method for embedding-based approach: "kmeans", "hierarchical", "dbscan", "hdbscan".}

\item{similarity_threshold}{The similarity threshold for topic assignment (default: 0.7).}

\item{min_topic_size}{The minimum number of documents per topic (default: 3).}

\item{cluster_selection_method}{HDBSCAN cluster selection method: "eom" (Excess of Mass, default) or "leaf" (finer-grained topics).}

\item{umap_neighbors}{The number of neighbors for UMAP dimensionality reduction (default: 15).}

\item{umap_min_dist}{The minimum distance for UMAP (default: 0.0). Use 0.0 for tight, well-separated clusters. Use 0.1+ for visualization purposes. Range: 0.0-0.99.}

\item{umap_n_components}{The number of UMAP components (default: 5).}

\item{representation_method}{The method for topic representation: "c-tfidf", "tfidf", "mmr", "frequency" (default: "c-tfidf").}

\item{diversity}{Topic diversity parameter between 0 and 1 (default: 0.5).}

\item{reduce_outliers}{Logical, if TRUE, reduces outliers in HDBSCAN clustering (default: TRUE).}

\item{seed}{Random seed for reproducibility (default: 123).}

\item{verbose}{Logical, if TRUE, prints progress messages.}

\item{precomputed_embeddings}{Optional matrix of pre-computed document embeddings.
If provided, skips embedding generation for improved performance. Must have
the same number of rows as the length of texts.}
}
\value{
A list containing topic assignments, topic keywords, and quality metrics.
}
\description{
This function performs embedding-based topic modeling using transformer embeddings
and specialized clustering techniques. The primary method uses the BERTopic library,
which combines transformer embeddings with UMAP dimensionality reduction and HDBSCAN
clustering for optimal topic discovery. This approach creates more semantically coherent
topics compared to traditional methods by leveraging deep learning embeddings.
}
\examples{
if (interactive()) {
  mydata <- TextAnalysisR::SpecialEduTech
  united_tbl <- TextAnalysisR::unite_cols(
    mydata,
    listed_vars = c("title", "keyword", "abstract")
  )
  texts <- united_tbl$united_texts

  # Embedding-based topic modeling (powered by BERTopic)
  result <- TextAnalysisR::fit_embedding_model(
    texts = texts,
    method = "umap_hdbscan",
    n_topics = 8,
    min_topic_size = 3
  )

  print(result$topic_assignments)
  print(result$topic_keywords)
}
}
\seealso{
Other topic-modeling: 
\code{\link{analyze_semantic_evolution}()},
\code{\link{assess_embedding_stability}()},
\code{\link{assess_hybrid_stability}()},
\code{\link{auto_tune_embedding_topics}()},
\code{\link{calculate_assignment_consistency}()},
\code{\link{calculate_eval_metrics_internal}()},
\code{\link{calculate_keyword_stability}()},
\code{\link{calculate_semantic_drift}()},
\code{\link{calculate_topic_probability}()},
\code{\link{calculate_topic_stability}()},
\code{\link{find_optimal_k}()},
\code{\link{find_topic_matches}()},
\code{\link{fit_hybrid_model}()},
\code{\link{fit_temporal_model}()},
\code{\link{generate_topic_labels}()},
\code{\link{get_topic_prevalence}()},
\code{\link{get_topic_terms}()},
\code{\link{get_topic_texts}()},
\code{\link{identify_topic_trends}()},
\code{\link{plot_model_comparison}()},
\code{\link{plot_quality_metrics}()},
\code{\link{run_contrastive_topics_internal}()},
\code{\link{run_neural_topics_internal}()},
\code{\link{run_temporal_topics_internal}()},
\code{\link{validate_semantic_coherence}()}
}
\concept{topic-modeling}
