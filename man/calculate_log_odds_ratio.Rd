% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lexical_analysis.R
\name{calculate_log_odds_ratio}
\alias{calculate_log_odds_ratio}
\title{Calculate Log Odds Ratio Between Categories}
\usage{
calculate_log_odds_ratio(
  dfm_object,
  group_var,
  comparison_mode = c("binary", "one_vs_rest", "pairwise"),
  reference_level = NULL,
  top_n = 10,
  min_count = 5
)
}
\arguments{
\item{dfm_object}{A quanteda dfm object}

\item{group_var}{Character, name of the grouping variable in docvars}

\item{comparison_mode}{Character, one of "binary", "one_vs_rest", or "pairwise"
\itemize{
\item binary: Compare two categories directly
\item one_vs_rest: Compare each category against all others combined
\item pairwise: Compare all pairs of categories
}}

\item{reference_level}{Character, reference category for binary comparison (default: first level)}

\item{top_n}{Number of top terms per comparison (default: 10)}

\item{min_count}{Minimum word count to include (default: 5)}
}
\value{
Data frame with columns:
\itemize{
\item term: The word/feature
\item category1: First category in comparison
\item category2: Second category in comparison
\item count1: Count in category 1
\item count2: Count in category 2
\item odds1: Odds in category 1
\item odds2: Odds in category 2
\item odds_ratio: Ratio of odds
\item log_odds_ratio: Log of odds ratio (positive = more in compared category)
}
}
\description{
Computes log odds ratio to compare word frequencies between categories.
Identifies words that are distinctively used in one category vs another.
Uses Laplace smoothing to handle zero counts.
}
\examples{
\dontrun{
library(quanteda)
corp <- corpus(c("The cat runs fast", "Dogs are loyal pets",
                 "Cats sleep all day", "My dog loves walks"),
               docvars = data.frame(animal = c("cat", "dog", "cat", "dog")))
dfm <- tokens(corp) \%>\% dfm()
log_odds <- calculate_log_odds_ratio(dfm, "animal")
}
}
\seealso{
Other lexical: 
\code{\link{calculate_dispersion_metrics}()},
\code{\link{calculate_lexical_dispersion}()},
\code{\link{calculate_text_readability}()},
\code{\link{clear_lexdiv_cache}()},
\code{\link{detect_multi_words}()},
\code{\link{extract_keywords_keyness}()},
\code{\link{extract_keywords_tfidf}()},
\code{\link{extract_morphology}()},
\code{\link{extract_named_entities}()},
\code{\link{extract_noun_chunks}()},
\code{\link{extract_pos_tags}()},
\code{\link{extract_subjects_objects}()},
\code{\link{find_similar_words}()},
\code{\link{get_sentences}()},
\code{\link{get_spacy_embeddings}()},
\code{\link{get_spacy_model_info}()},
\code{\link{get_word_similarity}()},
\code{\link{init_spacy_nlp}()},
\code{\link{lexical_analysis}},
\code{\link{lexical_diversity_analysis}()},
\code{\link{lexical_frequency_analysis}()},
\code{\link{parse_morphology_string}()},
\code{\link{plot_keyness_keywords}()},
\code{\link{plot_keyword_comparison}()},
\code{\link{plot_lexical_diversity_distribution}()},
\code{\link{plot_morphology_feature}()},
\code{\link{plot_readability_by_group}()},
\code{\link{plot_readability_distribution}()},
\code{\link{plot_tfidf_keywords}()},
\code{\link{plot_top_readability_documents}()},
\code{\link{render_displacy_dep}()},
\code{\link{render_displacy_ent}()},
\code{\link{spacy_extract_entities}()},
\code{\link{spacy_has_vectors}()},
\code{\link{spacy_initialized}()},
\code{\link{spacy_parse_full}()},
\code{\link{summarize_morphology}()}
}
\concept{lexical}
