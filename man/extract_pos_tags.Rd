% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lexical_analysis.R
\name{extract_pos_tags}
\alias{extract_pos_tags}
\title{Extract Part-of-Speech Tags from Tokens}
\usage{
extract_pos_tags(
  tokens,
  include_lemma = TRUE,
  include_entity = FALSE,
  include_dependency = FALSE,
  model = "en_core_web_sm"
)
}
\arguments{
\item{tokens}{A quanteda tokens object or character vector of texts.}

\item{include_lemma}{Logical; include lemmatized forms (default: TRUE).}

\item{include_entity}{Logical; include named entity recognition (default: FALSE).}

\item{include_dependency}{Logical; include dependency parsing (default: FALSE).}

\item{model}{Character; spaCy model to use (default: "en_core_web_sm").}
}
\value{
A data frame with columns:
\itemize{
\item \code{doc_id}: Document identifier
\item \code{sentence_id}: Sentence number within document
\item \code{token_id}: Token position within sentence
\item \code{token}: Original token
\item \code{pos}: Universal POS tag (e.g., NOUN, VERB, ADJ)
\item \code{tag}: Detailed POS tag (e.g., NN, VBD, JJ)
\item \code{lemma}: Lemmatized form (if include_lemma = TRUE)
\item \code{entity}: Named entity type (if include_entity = TRUE)
\item \code{head_token_id}: Head token in dependency tree (if include_dependency = TRUE)
\item \code{dep_rel}: Dependency relation type, e.g., nsubj, dobj (if include_dependency = TRUE)
}
}
\description{
Uses spaCy to extract part-of-speech (POS) tags from tokenized text.
Returns a data frame with token-level POS annotations.
}
\details{
This function requires the Python
with spaCy installed. If spaCy is not initialized, this function will
attempt to initialize it with the specified model.
}
\examples{
\dontrun{
tokens <- quanteda::tokens("The quick brown fox jumps over the lazy dog.")
pos_data <- extract_pos_tags(tokens)
print(pos_data)
}
}
\seealso{
Other lexical: 
\code{\link{calculate_dispersion_metrics}()},
\code{\link{calculate_lexical_dispersion}()},
\code{\link{calculate_log_odds_ratio}()},
\code{\link{calculate_text_readability}()},
\code{\link{clear_lexdiv_cache}()},
\code{\link{detect_multi_words}()},
\code{\link{extract_keywords_keyness}()},
\code{\link{extract_keywords_tfidf}()},
\code{\link{extract_morphology}()},
\code{\link{extract_named_entities}()},
\code{\link{extract_noun_chunks}()},
\code{\link{extract_subjects_objects}()},
\code{\link{find_similar_words}()},
\code{\link{get_sentences}()},
\code{\link{get_spacy_embeddings}()},
\code{\link{get_spacy_model_info}()},
\code{\link{get_word_similarity}()},
\code{\link{init_spacy_nlp}()},
\code{\link{lexical_analysis}},
\code{\link{lexical_diversity_analysis}()},
\code{\link{lexical_frequency_analysis}()},
\code{\link{parse_morphology_string}()},
\code{\link{plot_keyness_keywords}()},
\code{\link{plot_keyword_comparison}()},
\code{\link{plot_lexical_diversity_distribution}()},
\code{\link{plot_morphology_feature}()},
\code{\link{plot_readability_by_group}()},
\code{\link{plot_readability_distribution}()},
\code{\link{plot_tfidf_keywords}()},
\code{\link{plot_top_readability_documents}()},
\code{\link{render_displacy_dep}()},
\code{\link{render_displacy_ent}()},
\code{\link{spacy_extract_entities}()},
\code{\link{spacy_has_vectors}()},
\code{\link{spacy_initialized}()},
\code{\link{spacy_parse_full}()},
\code{\link{summarize_morphology}()}
}
\concept{lexical}
