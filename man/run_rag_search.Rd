% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ai_integration.R
\name{run_rag_search}
\alias{run_rag_search}
\title{RAG-Enhanced Semantic Search}
\usage{
run_rag_search(
  query,
  documents,
  ollama_model = "llama3",
  ollama_base_url = "http://localhost:11434",
  embedding_model = "nomic-embed-text",
  top_k = 5,
  envname = "textanalysisr-env"
)
}
\arguments{
\item{query}{Character string, user question}

\item{documents}{Character vector, corpus to search}

\item{ollama_model}{Character string, LLM model (default: "llama3")}

\item{ollama_base_url}{Character string, Ollama API endpoint}

\item{embedding_model}{Character string, embedding model (default: "nomic-embed-text")}

\item{top_k}{Integer, number of documents to retrieve (default: 5)}

\item{envname}{Character string, Python environment name}
}
\value{
List with:
\itemize{
\item success: Logical
\item answer: Generated answer
\item confidence: Confidence score (0-1)
\item sources: Vector of source document IDs
\item retrieved_docs: Retrieved document chunks
\item scores: Similarity scores
}
}
\description{
Uses LangGraph multi-agent workflow for Retrieval Augmented Generation.
Provides question-answering over document corpus with source attribution.
}
\details{
Multi-agent workflow:
\enumerate{
\item Retrieval Agent: Find relevant documents via embeddings
\item Generation Agent: Create answer from context
\item Validation Agent: Assess answer quality
\item Conditional retry if confidence < 0.4
}

Requires Ollama with embedding model:

\if{html}{\out{<div class="sourceCode">}}\preformatted{ollama pull llama3
ollama pull nomic-embed-text
}\if{html}{\out{</div>}}
}
\examples{
\dontrun{
documents <- c(
  "Assistive technology helps students with disabilities access curriculum.",
  "Universal Design for Learning provides multiple means of engagement.",
  "Response to Intervention uses tiered support systems."
)

result <- run_rag_search(
  query = "How does assistive technology support learning?",
  documents = documents
)

if (result$success) {
  cat("Answer:", result$answer, "\n")
  cat("Confidence:", result$confidence, "\n")
  cat("Sources:", paste(result$sources, collapse = ", "), "\n")
}
}
}
\seealso{
Other ai: 
\code{\link{analyze_contrastive_similarity}()},
\code{\link{call_ollama}()},
\code{\link{check_ollama}()},
\code{\link{create_label_selection_data}()},
\code{\link{format_label_candidates}()},
\code{\link{generate_survey_items}()},
\code{\link{generate_topic_content}()},
\code{\link{generate_topic_labels_langgraph}()},
\code{\link{get_content_type_prompt}()},
\code{\link{get_content_type_user_template}()},
\code{\link{get_recommended_ollama_model}()},
\code{\link{list_ollama_models}()},
\code{\link{validate_topic_labels_langgraph}()}
}
\concept{ai}
