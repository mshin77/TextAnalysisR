% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{get_api_embeddings}
\alias{get_api_embeddings}
\title{Get Embeddings from API}
\usage{
get_api_embeddings(
  texts,
  provider = c("ollama", "openai", "gemini"),
  model = NULL,
  api_key = NULL,
  batch_size = 100
)
}
\arguments{
\item{texts}{Character vector of texts to embed}

\item{provider}{Character string: "ollama" (local API, free), "openai", or "gemini"}

\item{model}{Character string specifying the embedding model. Defaults:
\itemize{
\item ollama: "nomic-embed-text"
\item openai: "text-embedding-3-small"
\item gemini: "text-embedding-004"
}}

\item{api_key}{Character string with API key (not required for Ollama)}

\item{batch_size}{Integer, number of texts to embed per API call (default: 100)}
}
\value{
Matrix with embeddings (rows = texts, columns = dimensions)
}
\description{
Generates text embeddings using Ollama (local), OpenAI, or Gemini embedding APIs.
}
\examples{
\dontrun{
data(SpecialEduTech)
texts <- SpecialEduTech$abstract[1:5]

# Using local Ollama API (free, no API key required)
embeddings <- get_api_embeddings(texts, provider = "ollama")

# Using OpenAI API
embeddings <- get_api_embeddings(texts, provider = "openai")

dim(embeddings)
}
}
\seealso{
Other ai: 
\code{\link{call_gemini_chat}()},
\code{\link{call_llm_api}()},
\code{\link{call_ollama}()},
\code{\link{call_openai_chat}()},
\code{\link{check_ollama}()},
\code{\link{generate_topic_content}()},
\code{\link{get_best_embeddings}()},
\code{\link{get_content_type_prompt}()},
\code{\link{get_content_type_user_template}()},
\code{\link{get_recommended_ollama_model}()},
\code{\link{list_ollama_models}()},
\code{\link{run_rag_search}()}
}
\concept{ai}
