% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{sanitize_llm_input}
\alias{sanitize_llm_input}
\title{Sanitize LLM Input}
\usage{
sanitize_llm_input(text, max_length = 2000)
}
\arguments{
\item{text}{Character string of user input destined for an LLM prompt}

\item{max_length}{Maximum allowed character length (default: 2000)}
}
\value{
Sanitized character string
}
\description{
Sanitizes user input before inclusion in LLM prompts to mitigate prompt
injection attacks. Filters common injection patterns such as instruction
overrides, system prompt markers, and role-switching attempts.
Distinct from \code{sanitize_text_input()} which targets XSS.
}
\section{NIST Compliance}{

Implements NIST SI-10 (Information Input Validation) for AI/LLM contexts.
}

\keyword{internal}
