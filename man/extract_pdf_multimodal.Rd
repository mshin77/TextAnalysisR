% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/multimodal_processing.R
\name{extract_pdf_multimodal}
\alias{extract_pdf_multimodal}
\title{Extract PDF with Multimodal Analysis}
\usage{
extract_pdf_multimodal(
  file_path,
  vision_provider = "ollama",
  vision_model = NULL,
  api_key = NULL,
  describe_images = TRUE,
  envname = "langgraph-env"
)
}
\arguments{
\item{file_path}{Character string path to PDF file}

\item{vision_provider}{Character: "ollama" (local, default) or "openai" (cloud)}

\item{vision_model}{Character: Model name
\itemize{
\item For Ollama: "llava", "llava:13b", "bakllava"
\item For OpenAI: "gpt-4-vision-preview", "gpt-4o"
}}

\item{api_key}{Character: OpenAI API key (required if vision_provider="openai")}

\item{describe_images}{Logical: Convert images to text descriptions (default: TRUE)}

\item{envname}{Character: Python environment name (default: "langgraph-env")}
}
\value{
List with:
\itemize{
\item success: Logical
\item combined_text: Character string with all content for text analysis
\item text_content: List of text chunks
\item image_descriptions: List of image descriptions
\item num_images: Integer count of processed images
\item vision_provider: Character indicating provider used
\item message: Character status message
}
}
\description{
Extract both text and visual content from PDFs, converting everything
to text for downstream analysis in your existing workflow.
}
\details{
\strong{Workflow Integration:}
\enumerate{
\item Extracts text using Marker (preserves equations, tables, structure)
\item Detects images/charts/diagrams in PDF
\item Uses vision LLM to describe visual content as text
\item Merges text + descriptions â†’ single text corpus
\item Feed to existing text analysis pipeline
}

\strong{Vision Provider Options:}

\strong{Ollama (Default - Local & Free):}
\itemize{
\item Privacy: Everything runs locally
\item Cost: Free
\item Setup: Requires Ollama installed + vision model pulled
\item Models: llava, bakllava, llava-phi3
}

\strong{OpenAI (Optional - Cloud):}
\itemize{
\item Privacy: Data sent to OpenAI
\item Cost: Paid (user's API key)
\item Setup: Just provide API key
\item Models: gpt-4-vision-preview, gpt-4o
}
}
\examples{
\dontrun{
# Local analysis with Ollama (free, private)
result <- extract_pdf_multimodal("research_paper.pdf")

# Access combined text for analysis
text_for_analysis <- result$combined_text

# Use in existing workflow
corpus <- prep_texts(text_for_analysis)
topics <- fit_semantic_model(corpus, k = 5)

# Optional: Use OpenAI for better accuracy
result <- extract_pdf_multimodal(
  "paper.pdf",
  vision_provider = "openai",
  vision_model = "gpt-4o",
  api_key = Sys.getenv("OPENAI_API_KEY")
)
}
}
\seealso{
Other pdf: 
\code{\link{check_vision_models}()},
\code{\link{detect_pdf_content_type}()},
\code{\link{detect_pdf_content_type_py}()},
\code{\link{extract_pdf_smart}()},
\code{\link{extract_tables_from_pdf_py}()},
\code{\link{extract_text_from_pdf}()},
\code{\link{extract_text_from_pdf_py}()},
\code{\link{process_pdf_file}()},
\code{\link{process_pdf_file_py}()}
}
\concept{pdf}
