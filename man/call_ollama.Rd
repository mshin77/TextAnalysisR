% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ollama_utils.R
\name{call_ollama}
\alias{call_ollama}
\title{Call Ollama for Text Generation}
\usage{
call_ollama(
  prompt,
  model = "phi3:mini",
  temperature = 0.3,
  max_tokens = 512,
  timeout = 60,
  verbose = FALSE
)
}
\arguments{
\item{prompt}{Character string containing the prompt.}

\item{model}{Character string specifying the Ollama model (default: "phi3:mini").}

\item{temperature}{Numeric value controlling randomness (default: 0.3).}

\item{max_tokens}{Maximum number of tokens to generate (default: 512).}

\item{timeout}{Timeout in seconds for the request (default: 60).}

\item{verbose}{Logical, if TRUE, prints progress messages.}
}
\value{
Character string with the generated text, or NULL if failed.
}
\description{
Sends a prompt to Ollama and returns the generated text.
}
\examples{
\dontrun{
response <- call_ollama(
  prompt = "Summarize these keywords: machine learning, neural networks, AI",
  model = "phi3:mini"
)
print(response)
}
}
