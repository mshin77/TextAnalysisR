% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{call_ollama}
\alias{call_ollama}
\title{Call Ollama for Text Generation}
\usage{
call_ollama(
  prompt,
  model = "llama3.2",
  temperature = 0.3,
  max_tokens = 512,
  timeout = 60,
  verbose = FALSE
)
}
\arguments{
\item{prompt}{Character string containing the prompt.}

\item{model}{Character string specifying the Ollama model (default: "llama3.2").}

\item{temperature}{Numeric value controlling randomness (default: 0.3).}

\item{max_tokens}{Maximum number of tokens to generate (default: 512).}

\item{timeout}{Timeout in seconds for the request (default: 60).}

\item{verbose}{Logical, if TRUE, prints progress messages.}
}
\value{
Character string with the generated text, or NULL if failed.
}
\description{
Sends a prompt to Ollama and returns the generated text.
}
\examples{
\dontrun{
response <- call_ollama(
  prompt = "Summarize these keywords: machine learning, neural networks, AI",
  model = "llama3.2"
)
print(response)
}
}
\seealso{
Other ai: 
\code{\link{call_gemini_chat}()},
\code{\link{call_llm_api}()},
\code{\link{call_openai_chat}()},
\code{\link{check_ollama}()},
\code{\link{generate_topic_content}()},
\code{\link{get_api_embeddings}()},
\code{\link{get_best_embeddings}()},
\code{\link{get_content_type_prompt}()},
\code{\link{get_content_type_user_template}()},
\code{\link{get_recommended_ollama_model}()},
\code{\link{list_ollama_models}()},
\code{\link{run_rag_search}()}
}
\concept{ai}
