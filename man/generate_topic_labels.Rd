% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/topic_modeling.R
\name{generate_topic_labels}
\alias{generate_topic_labels}
\title{Generate Topic Labels Using OpenAI's API}
\usage{
generate_topic_labels(
  top_topic_terms,
  model = "gpt-3.5-turbo",
  system = NULL,
  user = NULL,
  temperature = 0.5,
  openai_api_key = NULL,
  verbose = TRUE
)
}
\arguments{
\item{top_topic_terms}{A data frame containing the top terms for each topic.}

\item{model}{A character string specifying which OpenAI model to use (default: "gpt-3.5-turbo").}

\item{system}{A character string containing the system prompt for the OpenAI API.
If NULL, the function uses the default system prompt.}

\item{user}{A character string containing the user prompt for the OpenAI API.
If NULL, the function uses the default user prompt.}

\item{temperature}{A numeric value controlling the randomness of the output (default: 0.5).}

\item{openai_api_key}{A character string containing the OpenAI API key.
If NULL, the function attempts to load the key from the OPENAI_API_KEY
environment variable or the .env file in the working directory.}

\item{verbose}{Logical, if TRUE, prints progress messages.}
}
\value{
A data frame containing the top terms for each topic along with their generated labels.
}
\description{
This function generates descriptive labels for each topic based on their
top terms using OpenAI's ChatCompletion API.
}
\examples{
if (interactive()) {
  mydata <- TextAnalysisR::SpecialEduTech

  united_tbl <- TextAnalysisR::unite_cols(
    mydata,
    listed_vars = c("title", "keyword", "abstract")
  )

  tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = "united_texts")

  dfm_object <- quanteda::dfm(tokens)

  out <- quanteda::convert(dfm_object, to = "stm")

stm_15 <- stm::stm(
  data = out$meta,
  documents = out$documents,
  vocab = out$vocab,
  max.em.its = 75,
  init.type = "Spectral",
  K = 15,
  prevalence = ~ reference_type + s(year),
  verbose = TRUE)

top_topic_terms <- TextAnalysisR::get_topic_terms(
  stm_model = stm_15,
  top_term_n = 10,
  verbose = TRUE
  )

top_labeled_topic_terms <- TextAnalysisR::generate_topic_labels(
  top_topic_terms,
  model = "gpt-3.5-turbo",
  temperature = 0.5,
  openai_api_key = "your_openai_api_key",
  verbose = TRUE)
print(top_labeled_topic_terms)

top_labeled_topic_terms <- TextAnalysisR::generate_topic_labels(
  top_topic_terms,
  model = "gpt-3.5-turbo",
  temperature = 0.5,
  verbose = TRUE)
print(top_labeled_topic_terms)
}
}
\seealso{
Other topic-modeling: 
\code{\link{analyze_semantic_evolution}()},
\code{\link{assess_hybrid_stability}()},
\code{\link{calculate_assignment_consistency}()},
\code{\link{calculate_eval_metrics_internal}()},
\code{\link{calculate_keyword_stability}()},
\code{\link{calculate_semantic_drift}()},
\code{\link{calculate_topic_probability}()},
\code{\link{calculate_topic_stability}()},
\code{\link{find_optimal_k}()},
\code{\link{find_topic_matches}()},
\code{\link{fit_embedding_topics}()},
\code{\link{fit_hybrid_model}()},
\code{\link{fit_temporal_model}()},
\code{\link{get_topic_prevalence}()},
\code{\link{get_topic_terms}()},
\code{\link{get_topic_texts}()},
\code{\link{identify_topic_trends}()},
\code{\link{plot_model_comparison}()},
\code{\link{plot_quality_metrics}()},
\code{\link{run_contrastive_topics_internal}()},
\code{\link{run_neural_topics_internal}()},
\code{\link{run_temporal_topics_internal}()},
\code{\link{validate_semantic_coherence}()}
}
\concept{topic-modeling}
