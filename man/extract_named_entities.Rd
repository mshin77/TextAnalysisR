% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lexical_analysis.R
\name{extract_named_entities}
\alias{extract_named_entities}
\title{Extract Named Entities from Tokens}
\usage{
extract_named_entities(
  tokens,
  include_pos = TRUE,
  include_lemma = TRUE,
  model = "en_core_web_sm"
)
}
\arguments{
\item{tokens}{A quanteda tokens object or character vector of texts.}

\item{include_pos}{Logical; include POS tags (default: TRUE).}

\item{include_lemma}{Logical; include lemmatized forms (default: TRUE).}

\item{model}{Character; spaCy model to use (default: "en_core_web_sm").}
}
\value{
A data frame with columns:
\itemize{
\item \code{doc_id}: Document identifier
\item \code{token}: Original token
\item \code{entity}: Named entity type (e.g., PERSON, ORG, GPE)
\item \code{pos}: Universal POS tag (if include_pos = TRUE)
\item \code{lemma}: Lemmatized form (if include_lemma = TRUE)
}
}
\description{
Uses spaCy to extract named entities (NER) from tokenized text.
Returns a data frame with token-level entity annotations.
}
\details{
This function requires the Python
with spaCy installed. If spaCy is not initialized, this function will
attempt to initialize it with the specified model.
}
\examples{
\dontrun{
tokens <- quanteda::tokens("Apple Inc. was founded by Steve Jobs in California.")
entity_data <- extract_named_entities(tokens)
print(entity_data)
}
}
\seealso{
Other lexical: 
\code{\link{calculate_dispersion_metrics}()},
\code{\link{calculate_lexical_dispersion}()},
\code{\link{calculate_log_odds_ratio}()},
\code{\link{calculate_text_readability}()},
\code{\link{clear_lexdiv_cache}()},
\code{\link{detect_multi_words}()},
\code{\link{extract_keywords_keyness}()},
\code{\link{extract_keywords_tfidf}()},
\code{\link{extract_morphology}()},
\code{\link{extract_noun_chunks}()},
\code{\link{extract_pos_tags}()},
\code{\link{extract_subjects_objects}()},
\code{\link{find_similar_words}()},
\code{\link{get_sentences}()},
\code{\link{get_spacy_embeddings}()},
\code{\link{get_spacy_model_info}()},
\code{\link{get_word_similarity}()},
\code{\link{init_spacy_nlp}()},
\code{\link{lexical_analysis}},
\code{\link{lexical_diversity_analysis}()},
\code{\link{lexical_frequency_analysis}()},
\code{\link{parse_morphology_string}()},
\code{\link{plot_keyness_keywords}()},
\code{\link{plot_keyword_comparison}()},
\code{\link{plot_lexical_diversity_distribution}()},
\code{\link{plot_morphology_feature}()},
\code{\link{plot_readability_by_group}()},
\code{\link{plot_readability_distribution}()},
\code{\link{plot_tfidf_keywords}()},
\code{\link{plot_top_readability_documents}()},
\code{\link{render_displacy_dep}()},
\code{\link{render_displacy_ent}()},
\code{\link{spacy_extract_entities}()},
\code{\link{spacy_has_vectors}()},
\code{\link{spacy_initialized}()},
\code{\link{spacy_lemmatize}()},
\code{\link{spacy_parse_full}()},
\code{\link{summarize_morphology}()}
}
\concept{lexical}
