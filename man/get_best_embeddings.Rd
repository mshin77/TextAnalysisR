% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{get_best_embeddings}
\alias{get_best_embeddings}
\title{Get Best Available Embeddings}
\usage{
get_best_embeddings(
  texts,
  provider = "auto",
  model = NULL,
  api_key = NULL,
  verbose = TRUE
)
}
\arguments{
\item{texts}{Character vector of texts to embed}

\item{provider}{Character string: "auto" (default), "ollama", "sentence-transformers",
"openai", or "gemini". Use "auto" for automatic detection.}

\item{model}{Character string specifying the embedding model. If NULL, uses default
model for the selected provider.}

\item{api_key}{Optional API key for OpenAI or Gemini providers. If NULL, falls back
to environment variables (OPENAI_API_KEY, GEMINI_API_KEY).}

\item{verbose}{Logical, whether to print progress messages (default: TRUE)}
}
\value{
Matrix with embeddings (rows = texts, columns = dimensions)
}
\description{
Auto-detects and uses the best available embedding provider with the following priority:
\enumerate{
\item Ollama (free, local, fast) - if running
\item sentence-transformers (local Python) - if Python environment is set up
\item OpenAI API - if OPENAI_API_KEY is set
\item Gemini API - if GEMINI_API_KEY is set
}
}
\examples{
\dontrun{
data(SpecialEduTech)
texts <- SpecialEduTech$abstract[1:5]

# Auto-detect best available provider
embeddings <- get_best_embeddings(texts)

# Force specific provider
embeddings <- get_best_embeddings(texts, provider = "ollama")

dim(embeddings)
}
}
\seealso{
Other ai: 
\code{\link{call_gemini_chat}()},
\code{\link{call_llm_api}()},
\code{\link{call_ollama}()},
\code{\link{call_openai_chat}()},
\code{\link{check_ollama}()},
\code{\link{generate_topic_content}()},
\code{\link{get_api_embeddings}()},
\code{\link{get_content_type_prompt}()},
\code{\link{get_content_type_user_template}()},
\code{\link{get_recommended_ollama_model}()},
\code{\link{list_ollama_models}()},
\code{\link{run_rag_search}()}
}
\concept{ai}
