---
title: "Text-Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Text-Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(TextAnalysisR)
```

The `TextAnalysisR` package provides a supporting workflow for text mining analysis. The `TextAnalysisR.app()` function allows users to launch and browse a Shiny app. This web app incorporates 'quanteda' (text preprocessing), 'stm' (structural topic modeling), 'ggraph' as well as 'widyr' (network analysis). 'tidytext' was implemented to tidy non-tidy format objects.

## Installation

The development version from [GitHub](https://github.com/mshin77/TextAnalysisR) with:

```{r, message=FALSE, eval=FALSE}
install.packages("devtools")
devtools::install_github("mshin77/TextAnalysisR")
```

## Browse the interative Shiny app

Launch and browse the TextAnalysisR app:

```{r, message=FALSE, eval=FALSE}
library(TextAnalysisR)
TextAnalysisR.app()
```

### Preprocess Text Data

Preprocess text data using the `preprocess_texts` function:

```{r, message=FALSE, eval=FALSE}
data <- TextAnalysisR::SpecialEduTech 

# Preprocess text data
preprocessed_data <- preprocess_texts(data, text_field = "united_texts")
```

### Plot Word Frequency

Use the `plot_word_frequency` function to plot word frequency results:

```{r, message=FALSE, eval=FALSE}
# data is a document-feature matrix (dfm) object through the quanteda package.

# Plot word frequency for the top 20 terms
word_freq_plot <- plot_word_frequency(data, n = 20)
print(word_freq_plot)
```

### Extract Frequently Observed Words

Use the `extract_frequent_word` function to extract frequently observed top words:

```{r, message=FALSE, eval=FALSE}
# data is a document-feature matrix (dfm) object through the quanteda package.

# Extract the top 20 frequent words
top_words <- extract_frequent_word(data, n = 20)
print(top_words)
```

### Plot Topic Per-Term Per-Topic Probabilities

Use the `plot_topic_term` function to visualize topic per-term per-topic probabilities:

```{r, message=FALSE, eval=FALSE}
# data is a tidy data frame that includes per-term per-topic probabilities (beta).

# Plot per-term per-topic probabilities for the top 10 terms
topic_term_plot <- plot_topic_term(data, top_n = 10)
print(topic_term_plot)
```

### Examine Highest Per-Term Per-Topic Probabilities

Use the `examine_top_terms` function to examine the highest per-term per-topic probabilities:

```{r, message=FALSE, eval=FALSE}
# data is a tidy data frame that includes per-term per-topic probabilities (beta).

# Examine the top 5 terms with the highest per-term per-topic probabilities (number of top_n can be changed).
top_terms <- examine_top_terms(data, top_n = 5)
print(top_terms)
```

### Plot Per-Document Per-Topic Probabilities

use the `topic_probability_plot` function to visualize per-document per-topic probabilities:

```{r, message=FALSE, eval=FALSE}
# data is a tidy data frame that includes per-document per-topic probabilities (gamma).

# Plot per-document per-topic probabilities for the top 15 topics (number of top_n can be changed)
topic_prob_plot <- topic_probability_plot(data, top_n = 15)
print(topic_prob_plot)
```

### Visualize a Table for Per-Document Per-Topic Probabilities

Use the `topic_probability_table` function to create a table of per-document per-topic probabilities:

```{r, message=FALSE, eval=FALSE}
# data is a tidy data frame that includes per-document per-topic probabilities (gamma).

# Create a table of per-document per-topic probabilities for the top 15 topics (number of top_n can be changed)
topic_prob_table <- topic_probability_table(gamma_td, top_n = 15)
print(topic_prob_table)
```




