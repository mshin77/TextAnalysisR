---
title: "TextAnalysisR Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TextAnalysisR Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(TextAnalysisR)
```

The `TextAnalysisR` package provides a supporting workflow for text mining analysis. The `TextAnalysisR.app()` function allows users to launch and browse a Shiny app. This web app incorporates 'quanteda' (text preprocessing), 'stm' (structural topic modeling), 'ggraph' as well as 'widyr' (network analysis). 'tidytext' was implemented to tidy non-tidy format objects.

**These steps are similar to those demonstrated in the Shiny web app at `TextAnalysisR::TextAnalysisR.app()`.**

## Installation

The development version can be installed from [GitHub](https://github.com/mshin77/TextAnalysisR):

```{r, message=FALSE, eval=FALSE}
install.packages("devtools")
devtools::install_github("mshin77/TextAnalysisR")
```

## Launch and Browse the Shiny app

```{r, message=FALSE, eval=FALSE}
library(TextAnalysisR)

if (interactive()) {
  TextAnalysisR.app()
}
```

### Preprocess Text Data

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
tokens <- preprocess_texts(df, text_field = "abstract")
tokens
```

### Plot Word Frequency

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm()
plot <- plot_word_frequency(dfm_object, n = 20)
print(plot)
```

### Examine Highest Per-Term Per-Topic Probabilities

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm()
out <- quanteda::convert(dfm_object, to = "stm") 
stm_model <- stm(out$documents,
                 out$vocab,
                 data = out$meta,
                 prevalence = ~ 
                   I((year >= 1980)*(year - 1980)) +
                   I((year >= 1990)*(year - 1990)) +
                   I((year >= 2000)*(year - 2000)) +
                   I((year >= 2010)*(year - 2010)),
                 max.em.its = 75,
                 init.type = 'Spectral',
                 K = 15,
                 verbose = FALSE)

beta_td <- tidytext::tidy(stm_model, matrix="beta")
top_terms <- examine_top_terms(beta_td, top_n = 5)
head(top_terms)
```

### Plot Topic Per-Term Per-Topic Probabilities

```{r, message=FALSE, eval=FALSE}
# Assume stm_model is a fitted STM model.
beta_td <- tidytext::tidy(stm_model, matrix = "beta", log = FALSE)
plot <- plot_topic_term(beta_td, ncol = 3)
print(plot)
```

### Plot Per-Document Per-Topic Probabilities

```{r, message=FALSE, eval=FALSE}
# Assume stm_model is a fitted STM model.
gamma_td <- tidytext::tidy(stm_model, matrix = "gamma", document_names = rownames(dfm), log = FALSE)
plot <- topic_probability_plot(gamma_td, top_n = 10)
print(plot)
```

### Create a Table for Per-Document Per-Topic Probabilities

```{r, message=FALSE, eval=FALSE}
# Assume stm_model is a fitted STM model.
gamma_td <- tidytext::tidy(stm_model, matrix="gamma")
table <- topic_probability_table(gamma_td, top_n = 10)
print(table)
```

### Plot a Hierarchical Clustering Dendrogram

```{r, message=FALSE, eval=FALSE}
# Assume stm_model is a fitted STM model.
gamma_matrix <- stm_model$gamma
hierarchical_clustering(gamma_matrix, method = "ward.D2")
```

### Plot a Word Co-occurrence Network

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- preprocess_texts(df, text_field = "abstract") %>%
  quanteda::dfm()
dfm_td <- tidytext::tidy(dfm_object)
plot_word_co_occurrence_network(dfm_td,
                                term_col = "abstract",
                                doc_col = "document",
                                co_occur_n = 5)
```

### Plot a Word Correlation Network

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- preprocess_texts(df, text_field = "") %>%
  quanteda::dfm()
dfm_td <- tidytext::tidy(dfm_object)
plot_word_correlation_network(dfm_td,
                              term_col = "abstract",
                              doc_col = "document",
                              correlation_threshold = 0.3)
```

### Visualize Word Frequency Trends Over Time

```{r, message=FALSE, eval=FALSE}
# Assume stm_model is a fitted STM model.
df <- TextAnalysisR::SpecialEduTech
dfm_object <- preprocess_texts(df, text_field = "abstract") %>% quanteda::dfm()
gamma_td <- tidytext::tidy(stm_model, matrix = "gamma")
word_frequency_trends(dfm_object, 
                      gamma_td, time_variable = "year", 
                      selected_terms = c("computer", "disability"))
```


  

