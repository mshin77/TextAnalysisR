---
title: "TextAnalysisR Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TextAnalysisR Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(TextAnalysisR)
```

The `TextAnalysisR` package provides a supporting workflow for text mining analysis. The `TextAnalysisR.app()` function allows users to launch and browse a Shiny app. This web app incorporates 'quanteda' (text preprocessing), 'stm' (structural topic modeling), 'ggraph' as well as 'widyr' (network analysis). 'tidytext' was implemented to tidy non-tidy format objects.

**These steps are similar to those demonstrated in the Shiny web app at `TextAnalysisR::TextAnalysisR.app()`.**

## Installation

The development version can be installed from [GitHub](https://github.com/mshin77/TextAnalysisR):

```{r, message=FALSE, eval=FALSE}
install.packages("devtools")
devtools::install_github("mshin77/TextAnalysisR")
```

## Launch and Browse the Shiny app

```{r, message=FALSE, eval=FALSE}
library(TextAnalysisR)

if (interactive()) {
  TextAnalysisR.app()
}
```

### Preprocess Text Data

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
tokens <- TextAnalysisR::preprocess_texts(df, text_field = "abstract")
tokens
```

### Plot Word Frequency

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  TextAnalysisR::preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 1, min_docfreq = 1) %>%
  .[quanteda::ntoken(.) > 0, ]
TextAnalysisR::plot_word_frequency(dfm_object, n = 20)
```

### Evaluate Optimal Number of Topics

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  TextAnalysisR::preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 1, min_docfreq = 1) %>%
  .[quanteda::ntoken(.) > 0, ]
TextAnalysisR::evaluate_optimal_topic_number(
  dfm_object = dfm_object,
  K_range = 5:30,
  max.em.its = 75,
  categorical_var = "reference_type",
  continuous_var = "year")
```

### Plot Highest Word Probabilities for Each Topic

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  TextAnalysisR::preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 1, min_docfreq = 1) %>%
  .[quanteda::ntoken(.) > 0, ]
TextAnalysisR::plot_word_probabilities(
  dfm_object = dfm_object,
  K_number = 15,
  max.em.its = 75,
  categorical_var = "reference_type",
  continuous_var = "year",
  top_n = 10,
  ncol = 3,
  height = 2000,
  width = 1000,
  verbose = TRUE)
```

### Plot Mean Topic Prevalence Across Documents

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  TextAnalysisR::preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 1, min_docfreq = 1) %>%
  .[quanteda::ntoken(.) > 0, ]
TextAnalysisR::plot_mean_topic_prevalence(
  dfm_object = dfm_object,
  K_number = 15,
  max.em.its = 75,
  categorical_var = "reference_type",
  continuous_var = "year",
  top_n = 15,
  height = 500,
  width = 1000,
  verbose = TRUE)
```

### Plot a Word Co-occurrence Network

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- df %>%
  TextAnalysisR::preprocess_texts(text_field = "abstract") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 1, min_docfreq = 1) %>%
  .[quanteda::ntoken(.) > 0, ]
TextAnalysisR::plot_word_co_occurrence_network(dfm_object,
                                               term_col = "abstract",
                                               document = "document",
                                               co_occur_n = 5,
                                               height = 700,
                                               width = 1000)
```

### Plot a Word Correlation Network

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- preprocess_texts(df, text_field = "text") %>%
  quanteda::dfm()
dfm_td <- tidytext::tidy(dfm_object)
TextAnalysisR::plot_word_correlation_network(dfm_td,
                                             term_col = "abstract",
                                             doc_col = "document",
                                             correlation_threshold = 0.3,
                                             height = 700,
                                             width = 1000)
```

### Visualize Word Frequency Trends Over Time

```{r, message=FALSE, eval=FALSE}
df <- TextAnalysisR::SpecialEduTech
dfm_object <- preprocess_texts(df, text_field = "abstract") %>%
  quanteda::dfm()
out <- quanteda::convert(dfm_object, to = "stm") 
stm_model <- stm::stm(out$documents,
                      out$vocab,
                      data = out$meta,
                      prevalence = ~
                        I((year >= 1980)*(year - 1980)) +
                        I((year >= 1990)*(year - 1990)) +
                        I((year >= 2000)*(year - 2000)) +
                        I((year >= 2010)*(year - 2010)),
                      max.em.its = 75,
                      init.type = 'Spectral',
                      K = 15,
                      verbose = FALSE)
gamma_td <- tidytext::tidy(stm_model, matrix = "gamma")
TextAnalysisR::word_frequency_trends(dfm_object,
                                     gamma_td, time_variable = "year",
                                     selected_terms = c("computer", "disability"),
                                     height = 700, width = 1000)
```




