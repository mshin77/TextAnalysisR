[{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"TextAnalysisR Vignette","text":"development version can installed GitHub:","code":"install.packages(\"devtools\") devtools::install_github(\"mshin77/TextAnalysisR\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"load-the-textanalysisr-package","dir":"Articles","previous_headings":"","what":"Load the TextAnalysisR Package","title":"TextAnalysisR Vignette","text":"","code":"library(TextAnalysisR)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"alternatively-launch-and-browse-the-shiny-app","dir":"Articles","previous_headings":"","what":"Alternatively, Launch and Browse the Shiny App","title":"TextAnalysisR Vignette","text":"","code":"if (interactive()) {   TextAnalysisR.app() }"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"unite-text-columns","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Unite Text Columns","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) united_tbl ## # A tibble: 490 × 7 ##    united_texts               reference_type author  year title keyword abstract ##    <chr>                      <chr>          <chr>  <dbl> <chr> <chr>   <chr>    ##  1 Dyscalculia and the minic… journal_artic… Block…  1980 Dysc… Arithm… Notes t… ##  2 The effects of computer-a… thesis         Bukat…  1981 The … locus … This st… ##  3 Computer Assisted Instruc… journal_artic… Watki…  1981 Comp… Comput… Results… ##  4 Arc-Ed Curriculum: Applic… journal_artic… Chaff…  1982 Arc-… Comput… The Arc… ##  5 ARC-ED curriculum: the ap… journal_artic… Chaff…  1982 ARC-… Electr… This ar… ##  6 The Effect of the Hand-he… thesis         Golde…  1982 The … NA      The pur… ##  7 A review of some traditio… journal_artic… Neal,…  1982 A re… tradit… Discuss… ##  8 A study of the effectiven… thesis         Engle…  1983 A st… microc… The pur… ##  9 The influence of computer… thesis         Foste…  1983 The … comput… The eff… ## 10 Using Computer Software t… journal_artic… Pomme…  1983 Usin… Comput… The art… ## # ℹ 480 more rows"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"preprocess-text-data","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Preprocess Text Data","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl,                                            text_field = \"united_texts\",                                            verbose = FALSE) tokens ## Tokens consisting of 490 documents and 6 docvars. ## text1 : ##  [1] \"dyscalculia\"    \"minicalculator\" \"alp\"            \"program\"        ##  [5] \"arithmetic\"     \"arithmetic\"     \"remedial\"       \"teaching\"       ##  [9] \"education\"      \"learning\"       \"disabled\"       \"children\"       ## [ ... and 71 more ] ##  ## text2 : ##  [1] \"effects\"        \"computer\"       \"assisted\"       \"instruction\"    ##  [5] \"mastery\"        \"multiplication\" \"facts\"          \"learning\"       ##  [9] \"disabled\"       \"elementary\"     \"school\"         \"aged\"           ## [ ... and 54 more ] ##  ## text3 : ##  [1] \"computer\"    \"assisted\"    \"instruction\" \"learning\"    \"disabled\"    ##  [6] \"students\"    \"computer\"    \"assisted\"    \"instruction\" \"computer\"    ## [11] \"programs\"    \"drills\"      ## [ ... and 42 more ] ##  ## text4 : ##  [1] \"arc\"           \"ed\"            \"curriculum\"    \"applicability\" ##  [5] \"severely\"      \"handicapped\"   \"pupils\"        \"computer\"      ##  [9] \"assisted\"      \"instruction\"   \"games\"         \"online\"        ## [ ... and 37 more ] ##  ## text5 : ##  [1] \"arc\"         \"ed\"          \"curriculum\"  \"application\" \"video\"       ##  [6] \"game\"        \"formats\"     \"educational\" \"software\"    \"electronic\"  ## [11] \"games\"       \"curriculum\"  ## [ ... and 89 more ] ##  ## text6 : ##  [1] \"effect\"      \"hand\"        \"held\"        \"calculator\"  \"mathematics\" ##  [6] \"speed\"       \"accuracy\"    \"motivation\"  \"secondary\"   \"educable\"    ## [11] \"mentally\"    \"retarded\"    ## [ ... and 223 more ] ##  ## [ reached max_ndoc ... 484 more documents ]"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"plot-word-frequency","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Plot Word Frequency","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) word_frequency_plot <- TextAnalysisR::plot_word_frequency(dfm_object, n = 20) word_frequency_plot"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"remove-common-words-across-documents","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Remove Common Words Across Documents","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) dfm_removed <- TextAnalysisR::remove_common_words(tokens = tokens,                                     remove_vars = c(\"students\", \"study\"),                                     dfm_object = dfm_object) TextAnalysisR::plot_word_frequency(dfm_removed, n = 20)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"evaluate-optimal-number-of-topics","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Evaluate Optimal Number of Topics","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) TextAnalysisR::evaluate_optimal_topic_number(   dfm_object = dfm_object,   topic_range = 5:30,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   height = 600,   width = 800,   verbose = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"plot-highest-word-probabilities-for-each-topic","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Plot Highest Word Probabilities for Each Topic","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) TextAnalysisR::plot_word_probabilities(   dfm_object = dfm_object,   topic_n = 15,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   top_term_n = 10,   ncol = 3,   height = 1200,   width = 800,   verbose = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"plot-mean-topic-prevalence-across-documents","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App","what":"Plot Mean Topic Prevalence Across Documents","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) TextAnalysisR::plot_mean_topic_prevalence(   dfm_object = dfm_object,   topic_n = 5,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   top_term_n = 10,   top_topic_n = 15,   height = 500,   width = 900,   verbose = FALSE)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-co-occurrence-network-plot","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Co-Occurrence Networks","what":"Word Co-occurrence Network Plot","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) word_co_occurrence_network_results <-    TextAnalysisR::word_co_occurrence_network(     dfm_object,     co_occur_n = 130,     top_node_n = 30,     height = 800,     width = 900) word_co_occurrence_network_results$plot"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-co-occurrence-network-centrality-table","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Co-Occurrence Networks","what":"Word Co-occurrence Network Centrality Table","title":"TextAnalysisR Vignette","text":"","code":"word_co_occurrence_network_results$table"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-co-occurrence-network-summary","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Co-Occurrence Networks","what":"Word Co-occurrence Network Summary","title":"TextAnalysisR Vignette","text":"","code":"word_co_occurrence_network_results$summary"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-correlation-network-plot","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Correlation Networks","what":"Word Correlation Network Plot","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) word_correlation_network_results <-    TextAnalysisR::word_correlation_network(     dfm_object,     co_occur_n = 30,     corr_n = 0.4,     top_node_n = 40,     height = 1000,     width = 900) word_correlation_network_results$plot"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-correlation-network-centrality-table","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Correlation Networks","what":"Word Correlation Network Centrality Table","title":"TextAnalysisR Vignette","text":"","code":"word_correlation_network_results$table"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"word-correlation-network-summary","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Word Correlation Networks","what":"Word Correlation Network Summary","title":"TextAnalysisR Vignette","text":"","code":"word_correlation_network_results$summary"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"term-proportions-by-a-continuous-variable-plot","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Term Proportions by a Continuous Variable","what":"Term Proportions by a Continuous Variable Plot","title":"TextAnalysisR Vignette","text":"","code":"df <- TextAnalysisR::SpecialEduTech united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens) stm_15 <- TextAnalysisR::stm_15 term_proportion_results <-    TextAnalysisR::term_proportion(     dfm_object,     stm_model = stm_15,     continuous_variable = \"year\",     selected_terms = c(\"calculator\", \"computer\"),     height = 500,     width = 900) term_proportion_results$plot"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/TextAnalysisR_Vignette.html","id":"generalized-additive-model-with-logit-link-table","dir":"Articles","previous_headings":"Alternatively, Launch and Browse the Shiny App > Analyze and Visualize Term Proportions by a Continuous Variable","what":"Generalized Additive Model with Logit Link Table","title":"TextAnalysisR Vignette","text":"calculator computer","code":"term_proportion_results$table"},{"path":"https://mshin77.github.io/TextAnalysisR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mikyung Shin. Author, maintainer.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Shin M (2025). TextAnalysisR: text mining workflow tool. R package version 0.0.2, https://mshin77.github.io/TextAnalysisR.","code":"@Manual{,   title = {TextAnalysisR: A text mining workflow tool},   author = {Mikyung Shin},   year = {2025},   note = {R package version 0.0.2},   url = {https://mshin77.github.io/TextAnalysisR}, }"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A text mining workflow tool","text":"development version GitHub :","code":"install.packages(\"devtools\") devtools::install_github(\"mshin77/TextAnalysisR\")"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"load-the-textanalysisr-package","dir":"","previous_headings":"","what":"Load the TextAnalysisR Package","title":"A text mining workflow tool","text":"","code":"library(TextAnalysisR)"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"alternatively-launch-and-browse-the-shiny-app","dir":"","previous_headings":"","what":"Alternatively, Launch and Browse the Shiny App","title":"A text mining workflow tool","text":"Access web app https://www.textanalysisr.org. Launch browser TextAnalysisR.app local computer:","code":"TextAnalysisR.app()"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"A text mining workflow tool","text":"Shin, M. (2025). TextAnalysisR: text mining workflow tool (R package version 0.0.2) [Computer software]. https://mshin77.github.io/TextAnalysisR Shin, M. (2025). TextAnalysisR: text mining workflow tool [Web application]. https://www.textanalysisr.org","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"A text mining workflow tool","text":"Shin, M., Park, H., & Kang, E. (2024). Development education policies practices students learning disabilities South Korea using Delphi surveys topic modeling. Learning Disability Quarterly. GitHub Shin, M., Ok, M. W., Choo, S., Hossain, G., Bryant, D. P., & Kang, E. (2023). content analysis research technology use teaching mathematics students disabilities: word networks topic modeling. International Journal STEM Education, 10(1), 1-23. GitHub","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Mikyung Shin Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":null,"dir":"Reference","previous_headings":"","what":"Acronym list — acronym","title":"Acronym list — acronym","text":"Contains acronyms commonly observed bibliographic data research use technology teaching mathematics students disabilities.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acronym list — acronym","text":"","code":"acronym"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Acronym list — acronym","text":"object class spec_tbl_df (inherits tbl_df, tbl, data.frame) 145 rows 2 columns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acronym list — acronym","text":"","code":"acronym #> # A tibble: 145 × 2 #>    `3D`  `three-dimensional`                               #>    <chr> <chr>                                             #>  1 3-D   three-dimensional                                 #>  2 AAC   Augmentative and Alternative Communication        #>  3 ADHD  attention deficit/hyperactivity disorder          #>  4 ADHD  attention deficit hyperactivity disorder          #>  5 AFB   American Foundation for the Blind                 #>  6 AI    app-based instruction                             #>  7 AITA  anchored Instruction with Technology Applications #>  8 ALTs  assistive learning technologies                   #>  9 ANS   Approximate Number System                         #> 10 ANS   Approximate Number System                         #> # ℹ 135 more rows"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Data-driven dictionary list 1 — dictionary_list_1","title":"Data-driven dictionary list 1 — dictionary_list_1","text":"Contains dictionary using wildcard values compound words SpecialEduTech","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data-driven dictionary list 1 — dictionary_list_1","text":"","code":"dictionary_list_1"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data-driven dictionary list 1 — dictionary_list_1","text":"object class list length 235.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data-driven dictionary list 1 — dictionary_list_1","text":"","code":"dictionary_list_1 #> $augmentative_and_alternative_communication #> [1] \"augmentative and alternative communication\" #> [2] \"aac\"                                        #>  #> $achievement_test #> [1] \"achievement test*\" #>  #> $adaptive_test #> [1] \"adaptive test*\"  \"adaptable test*\" #>  #> $adolescent #> [1] \"adolescents\" #>  #> $anchor #> [1] \"anchors\" #>  #> $approximate_number_system #> [1] \"approximate number system*\" \"ans\"                        #>  #> $arithmetic_fact #> [1] \"arithmetic fact*\" #>  #> $arithmetic_skill #> [1] \"arithmetic skill*\" #>  #> $artificial_intelligence #> [1] \"artificial intellig*\" #>  #> $assistive_technology #> [1] \"assistive technolog*\" #>  #> $asynchronous_learning #> [1] \"asynchronous learning\" #>  #> $augmentative_communication #> [1] \"augmentative communication*\" #>  #> $augmented_reality #> [1] \"augmented real*\" #>  #> $authoring_system #> [1] \"authoring system*\" #>  #> $basic_fact #> [1] \"basic fact\" #>  #> $basic_skill #> [1] \"basic skill*\" #>  #> $behavior #> [1] \"behaviors\"  \"behaviour*\" #>  #> $blended_instruction #> [1] \"blended instruction*\" #>  #> $blended_learning #> [1] \"blended learning\" #>  #> $case_based #> [1] \"case based\" #>  #> $common_core_state_standard #> [1] \"common core state standard*\" #>  #> $computational_thinking #> [1] \"computational thinking\" #>  #> $computer_assisted_instruction #> [1] \"computer assisted instruction*\" \"computer aided instruction*\"    #> [3] \"cai\"                            #>  #> $computer_based #> [1] \"computer based\" #>  #> $conceptual_knowledge #> [1] \"conceptual knowledge\" #>  #> $conceptual_model #> [1] \"conceptual model\" #>  #> $conceptual_understanding #> [1] \"conceptual understand*\" #>  #> $concrete_manipulatives #> [1] \"concrete manipulative*\" #>  #> $concrete_representational_abstract #> [1] \"concrete representational abstract\" \"cra\"                                #>  #> $criterion_referenced #> [1] \"criterion reference*\" #>  #> $curriculum_based_measurement #> [1] \"curriculum based measure*\" \"cbm\"                       #>  #> $data_based #> [1] \"data based\" #>  #> $digital_text #> [1] \"digital text*\" \"etext*\"        #>  #> $division_fact #> [1] \"division fact*\" #>  #> $down_syndrome #> [1] \"down syndrome\"   \"down's syndrome\" #>  #> $drill_practice #> [1] \"drill* and practice*\" \"drill* practice*\"     \"drill*\"               #>  #> $educational_technology #> [1] \"educational technolog*\" #>  #> $eigth_grade #> [1] \"eigth grade*\" \"8th grade*\"   #>  #> $e_learning #> [1] \"e learning\" \"elearning\"  #>  #> $elementary_education #> [1] \"elementary education\" #>  #> $elementary_mathematics #> [1] \"elementary mathematics\" #>  #> $elementary_level #> [1] \"elementary level*\" #>  #> $elementary_school #> [1] \"elementary school*\" #>  #> $elementary_student #> [1] \"elementary student*\" #>  #> $eleventh_grade #> [1] \"eleventh grade*\" \"11th grade\"      #>  #> $enhanced_anchored_instruction #> [1] \"enhanced anchor* instruction*\" \"eai\"                           #>  #> $evidence_based_practice #> [1] \"evidence based practice*\" \"ebp\"                      #>  #> $e_portfolio #> [1] \"e portfolio\" #>  #> $e_workbook #> [1] \"eworkbook*\" \"e workbook\" #>  #> $explicit_instruction #> [1] \"explicit instruction*\" #>  #> $eye_tracking #> [1] \"eye track*\" #>  #> $face_to_face #> [1] \"face to face\" #>  #> $fact_fluency #> [1] \"fact fluency\" #>  #> $fifth_grade #> [1] \"fifth grade*\" \"5th grade*\"   #>  #> $first_grade #> [1] \"first grade*\" \"1st grade*\"   #>  #> $flipped_classroom #> [1] \"flipped classroom*\" #>  #> $formative_assessment #> [1] \"formative assessment*\" #>  #> $fourth_grade #> [1] \"fourth grade*\" \"4th grade*\"    #>  #> $functional_relation #> [1] \"functional relation*\" #>  #> $goal_setting #> [1] \"goal setting\" #>  #> $graphic_organizer #> [1] \"graphic* organizer*\" #>  #> $graphing_calculator #> [1] \"graphing calculator*\" #>  #> $group_design #> [1] \"group design*\" #>  #> $hands_on #> [1] \"hand* on\" #>  #> $high_level #> [1] \"high* level*\" #>  #> $high_school #> [1] \"high school*\" #>  #> $higher_order_thinking #> [1] \"higher order think*\" #>  #> $inclusive_classroom #> [1] \"inclusive classroom*\" #>  #> $information_and_communication_technology #> [1] \"information and communication technology\"   #> [2] \"information and communication technologies\" #> [3] \"information communication technology\"       #> [4] \"information communication technologies\"     #> [5] \"ict\"                                        #>  #> $integrated_learning_system #> [1] \"integrated learning system*\" #>  #> $information_processing #> [1] \"information processing\" #>  #> $instructional_approach #> [1] \"instructional approach*\" #>  #> $instructional_component #> [1] \"instructional component*\" #>  #> $instructional_design #> [1] \"instructional design*\" #>  #> $instructional_method #> [1] \"instructional method*\" #>  #> $instructional_practice #> [1] \"instructional practice*\" #>  #> $instructional_program #> [1] \"instructional program*\" #>  #> $instructional_sequence #> [1] \"instructional sequence*\" #>  #> $instructional_strategy #> [1] \"instructional strateg*\" #>  #> $instructional_technology #> [1] \"instructional technolog*\" #>  #> $intelligent_tutor #> [1] \"intelligent* tutor*\" #>  #> $interactive_whiteboard #> [1] \"interactive whiteboard*\" #>  #> $learning_management_system #> [1] \"learning management system*\" #>  #> $learning_process #> [1] \"learning process*\" #>  #> $linear_equation #> [1] \"linear equation*\" #>  #> $long_term_memory #> [1] \"long term memory\" #>  #> $mathematical_concept #> [1] \"math* concept*\" #>  #> $mathematical_difficulty #> [1] \"math* difficult*\" #>  #> $mathematical_expression #> [1] \"math* expression*\" #>  #> $mathematical_reasoning #> [1] \"math* reasoning\" #>  #> $mathematics_assessment #> [1] \"math* assessment*\" #>  #> $mathematics_content #> [1] \"math* content*\" #>  #> $mathematics_fact #> [1] \"math* fact*\" #>  #> $mathematics_performance #> [1] \"mathematics performance*\" #>  #> $mathematics_skill #> [1] \"math* skill*\" #>  #> $mathematics_test #> [1] \"math* test*\" #>  #> $mental_retardation #> [1] \"mental* retard*\" #>  #> $microcomputer #> [1] \"microcomputers\"  \"micro computer\"  \"micro computers\" #>  #> $middle_school #> [1] \"middle school*\" #>  #> $multiple_baseline #> [1] \"multiple baseline\" #>  #> $multiple_probe #> [1] \"multiple probe\" #>  #> $multiplication_fact #> [1] \"\\tmultiplication fact*\" #>  #> $multiplicative_reasoning #> [1] \"multiplicative reasoning\" #>  #> $ninth_grade #> [1] \"ninth grade*\" \"9th grade*\"   #>  #> $norm_referenced #> [1] \"norm reference*\" #>  #> $number_concept #> [1] \"number concept*\" #>  #> $number_fact #> [1] \"number fact*\" #>  #> $number_line #> [1] \"number line*\" #>  #> $number_sense #> [1] \"number sense\" #>  #> $numerical_comparison #> [1] \"numerical comparison\" #>  #> $one_step #> [1] \"one step*\" #>  #> $open_educational_resource #> [1] \"open education* resource*\" \"oer\"                       #>  #> $paper_pencil #> [1] \"paper pencil*\"     \"paper and pencil*\" #>  #> $peer_tutoring #> [1] \"peer tutoring\" #>  #> $pilot_test #> [1] \"pilot test*\" #>  #> $physical_manipulatives #> [1] \"physical manipulative*\" #>  #> $posttest #> [1] \"post test*\" \"posttest*\"  #>  #> $pretest #> [1] \"pre test*\" \"pretest*\"  #>  #> $primary_education #> [1] \"primary education*\" #>  #> $primary_level #> [1] \"primary level*\" #>  #> $primary_school #> [1] \"primary school*\" #>  #> $problem_based #> [1] \"problem based\" #>  #> $problem_solving #> [1] \"problem solving\" #>  #> $procedural_knowledge #> [1] \"procedural knowledge\" #>  #> $procedural_understanding #> [1] \"procedural understand*\" #>  #> $progress_monitoring #> [1] \"progress monitoring\" #>  #> $project_based #> [1] \"project based\" #>  #> $quasi_experimental #> [1] \"quasi experimental\" #>  #> $read_aloud #> [1] \"read aloud*\" #>  #> $real_world #> [1] \"real world\" #>  #> $response_to_instruction #> [1] \"response to instruction\" \"rti\"                     #>  #> $schema_based_instruction #> [1] \"schema based instruction\" \"schema instruction\"       #> [3] \"sbi\"                      #>  #> $second_grade #> [1] \"second grade*\" \"2nd grade*\"    #>  #> $secondary_education #> [1] \"secondary education\" #>  #> $secondary_level #> [1] \"secondary level*\" #>  #> $secondary_mathematics #> [1] \"secondary mathematics\" #>  #> $secondary_school #> [1] \"secondary school*\" #>  #> $secondary_student #> [1] \"secondary student*\" #>  #> $self_assessment #> [1] \"self assess*\" #>  #> $self_contained #> [1] \"self contained\" #>  #> $self_directed #> [1] \"self direct*\" #>  #> $self_efficacy #> [1] \"self efficac*\" #>  #> $self_esteem #> [1] \"self esteem\" #>  #> $self_graphing #> [1] \"self graph*\" #>  #> $self_instruction #> [1] \"self instruct*\" #>  #> $self_management #> [1] \"self manag*\" #>  #> $self_modeling #> [1] \"self model*\" #>  #> $self_monitoring #> [1] \"self monitor*\" #>  #> $self_paced #> [1] \"self paced\" #>  #> $self_regulated #> [1] \"self regulat*\" #>  #> $self_recorded #> [1] \"self record*\" #>  #> $self_reported #> [1] \"self report*\" #>  #> $self_selected #> [1] \"self selected\" #>  #> $self_voicing #> [1] \"self voic*\" #>  #> $serious_game #> [1] \"serious game*\" #>  #> $seventh_grade #> [1] \"seventh grade*\" \"7th grade*\"     #>  #> $sixth_grade #> [1] \"sixth grade*\" \"6th grade*\"   #>  #> $short_term_memory #> [1] \"short term memory\" #>  #> $single_case #> [1] \"single case\" #>  #> $single_subject #> [1] \"single subject\" #>  #> $social_science #> [1] \"social science\" #>  #> $social_validity #> [1] \"social validit*\" #>  #> $special_education #> [1] \"special education\" #>  #> $special_needs #> [1] \"special needs\" #>  #> $speech_generating #> [1] \"speech generat*\" #>  #> $speech_recognition #> [1] \"speech recognit*\" #>  #> $standard_based #> [1] \"standard* based\" #>  #> $standardized_assessment #> [1] \"standardized assessment*\" #>  #> $standardized_test #> [1] \"standardized test*\" #>  #> $science_technology_engineering_and_mathematics #> [1] \"science technology engineering mathematics\"     #> [2] \"science technology engineering and mathematics\" #> [3] \"stem\"                                           #>  #> $story_problem #> [1] \"story problem*\" #>  #> $student_paced #> [1] \"student paced\" #>  #> $synchronous_learning #> [1] \"synchronous learning\" #>  #> $system_of_least_prompts #> [1] \"system of least prompt*\" #>  #> $systematic_instruction #> [1] \"systematic instruction*\" #>  #> $teacher_paced #> [1] \"teacher paced\" #>  #> $technology_assisted #> [1] \"technology assisted\" #>  #> $technology_based #> [1] \"technology based\" #>  #> $tenth_grade #> [1] \"tenth grade*\" \"10th grade*\"  #>  #> $third_grade #> [1] \"third grade*\" \"3rd grade*\"   #>  #> $three_dimensional #> [1] \"three dimension*\" #>  #> $three_step #> [1] \"three step*\" #>  #> $twelfth_grade #> [1] \"twelfth grade*\" \"12th grade*\"    #>  #> $two_step #> [1] \"two step*\" #>  #> $universal_design_for_learning #> [1] \"universal* design* for learning\" \"udl\"                             #>  #> $video_based #> [1] \"video based\" #>  #> $video_modeling #> [1] \"video model*\" #>  #> $video_prompting #> [1] \"video prompt*\" #>  #> $videodisc_instruction #> [1] \"videodisc* instruction*\" #>  #> $virtual_environment #> [1] \"virtual environment*\" #>  #> $virtual_learning #> [1] \"virtual learning\" #>  #> $virtual_manipulatives #> [1] \"virtual manipulative*\" #>  #> $virtual_reality #> [1] \"virtual realit*\" #>  #> $virtual_representational_abstract #> [1] \"virtual representational abstract\" \"vra\"                               #>  #> $visual_cue #> [1] \"visual cue*\" #>  #> $visual_image #> [1] \"visual image*\" #>  #> $visual_representation #> [1] \"visual representation*\" #>  #> $visual_support #> [1] \"visual support*\" #>  #> $whole_number #> [1] \"whole number*\" #>  #> $word_problem #> [1] \"word problem*\" #>  #> $working_memory #> [1] \"working memory\" #>  #> $attention_deficit_and_hyperactivity_disorder #> [1] \"attention deficit hyperactivity disorder*\"     #> [2] \"attention deficit and hyperactivity disorder*\" #> [3] \"adhd\"                                          #>  #> $autism_spectrum_disorder #> [1] \"autism spectrum disorder*\" \"asd\"                       #>  #> $dyscalculia #> [1] \"dyscalcul\" #>  #> $emotional_and_behavioral_disorder #> [1] \"emotional behavioral disorder*\"      \"emotional and behavioral disorder*\"  #> [3] \"emotional behavioral disabilit*\"     \"emotional and behavioral disabilit*\" #> [5] \"ebd\"                                 #>  #> $emotional_disturbance #> [1] \"emotional disturbance*\" #>  #> $fragile_x_syndrome #> [1] \"fragile x syndrome\" \"fxs\"                #>  #> $deaf_blindness #> [1] \"deaf-blind*\" \"deaf blind*\" #>  #> $hard_of_hearing #> [1] \"hard of hearing\" #>  #> $hearing_disability #> [1] \"hearing disabilit*\" #>  #> $hearing_disabled #> [1] \"hearing disabled\" #>  #> $hearing_impairment #> [1] \"hearing impairment*\" #>  #> $high_incidence_disability #> [1] \"high incidence disabilit*\" #>  #> $intellectual_disability #> [1] \"intellectual disabilit*\" #>  #> $learning_disability #> [1] \"learning disabilit*\" #>  #> $learning_disabled #> [1] \"learning disabled\" #>  #> $learning_handicapped #> [1] \"learning handicapped\" #>  #> $language_impairment #> [1] \"language impairment\" #>  #> $low_incidence_disability #> [1] \"low incidence disabilit*\" #>  #> $low_vision #> [1] \"low vision*\" #>  #> $mathematics_disability #> [1] \"math* disab*\"        \"disabilit* in math*\" #>  #> $mental_handicap #> [1] \"mental* handicap*\" #>  #> $mild_disabilities #> [1] \"mild* disabilit*\" #>  #> $mathematics_learning_disability #> [1] \"learning disabilit* in math*\" \"math* learning disabilit*\"    #>  #> $moderate_disability #> [1] \"moderate disabilit*\" #>  #> $multiple_disabilities #> [1] \"multiple disabilit*\" #>  #> $other_health_impairment #> [1] \"other health impairment\" \"ohi\"                     #>  #> $orthopedic_impairment #> [1] \"orthopedic impairment\" #>  #> $physical_disability #> [1] \"physical disabilit*\" #>  #> $severe_disability #> [1] \"severe* disabilit*\" #>  #> $Speech_or_language_impairment #> [1] \"Speech or language impairment\" #>  #> $Speech_impairment #> [1] \"Speech impairment\" #>  #> $traumatic_brain_injury #> [1] \"traumatic brain injury\" #>  #> $visual_disability #> [1] \"visual disabilit*\" #>  #> $visual_impairment #> [1] \"visual* impair*\" #>"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Data-driven dictionary list 2 — dictionary_list_2","title":"Data-driven dictionary list 2 — dictionary_list_2","text":"Contains dictionary using wildcard values compound words SpecialEduTech","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data-driven dictionary list 2 — dictionary_list_2","text":"","code":"dictionary_list_2"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data-driven dictionary list 2 — dictionary_list_2","text":"object class list length 200.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data-driven dictionary list 2 — dictionary_list_2","text":"","code":"dictionary_list_2 #> $ability #> [1] \"abilities\" #>  #> $access #> [1] \"accesses\" #>  #> $accommodation #> [1] \"accommodations\" #>  #> $achievement #> [1] \"achievements\" #>  #> $activity #> [1] \"activities\" #>  #> $adapt #> [1] \"adapts\" #>  #> $addition #> [1] \"adding\" \"add\"    \"adds\"   \"added\"  #>  #> $agent #> [1] \"agents\" #>  #> $algebra #> [1] \"algebra*\" #>  #> $analysis #> [1] \"analyses\" #>  #> $anchored_instruction #> [1] \"anchor* instruction*\" #>  #> $app #> [1] \"apps\" #>  #> $application #> [1] \"applications\" #>  #> $approach #> [1] \"approaches\" #>  #> $area #> [1] \"areas\" #>  #> $article #> [1] \"articles\" #>  #> $artifact #> [1] \"artifacts\" #>  #> $assess #> [1] \"assessing\" \"assesses\"  \"assessed\"  #>  #> $assessment #> [1] \"assessments\" #>  #> $assign #> [1] \"assigning\" \"assigns\"   \"assigned\"  #>  #> $assignment #> [1] \"assignments\" #>  #> $basic_mathematics #> [1] \"basic math*\" #>  #> $battery #> [1] \"batter*\" #>  #> $benefit #> [1] \"benefits\" #>  #> $calculator #> [1] \"calculators\" #>  #> $case #> [1] \"cases\" #>  #> $challenge #> [1] \"challenges\" #>  #> $change #> [1] \"chaning\" \"changes\" \"changed\" #>  #> $child #> [1] \"children\" #>  #> $class #> [1] \"classes\" #>  #> $classroom #> [1] \"classrooms\" #>  #> $clicker #> [1] \"clickers\" #>  #> $communicate #> [1] \"communicating\" \"communicates\"  \"communicated\"  #>  #> $communication #> [1] \"communications\" #>  #> $computer #> [1] \"computers\" #>  #> $condition #> [1] \"conditions\" #>  #> $concept #> [1] \"concepts\" #>  #> $course #> [1] \"courses\" #>  #> $decimal #> [1] \"decimals\" #>  #> $deficit #> [1] \"deficits\" #>  #> $demonstrate #> [1] \"demonstrating\" \"demonstrates\"  \"demonstrated\"  #>  #> $describe #> [1] \"describing\" \"describes\"  \"described\"  #>  #> $develop #> [1] \"developing\" \"develops\"   \"developed\"  #>  #> $development #> [1] \"developments\" #>  #> $device #> [1] \"devices\" #>  #> $diagram #> [1] \"diagrams\" #>  #> $difference #> [1] \"differences\" #>  #> $difficulty #> [1] \"difficulties\" #>  #> $disability #> [1] \"disabilities\" #>  #> $discuss #> [1] \"discusses\" #>  #> $disorder #> [1] \"disorders\" #>  #> $district #> [1] \"districts\" #>  #> $division #> [1] \"dividing\" \"divide\"   \"divides\"  \"divided\"  #>  #> $domain #> [1] \"domains\" #>  #> $dyscalculia #> [1] \"dyscalcul*\" #>  #> $education #> [1] \"educations\" #>  #> $educator #> [1] \"educators\" #>  #> $effect #> [1] \"effects\"       \"effectiveness\" #>  #> $environment #> [1] \"environments\" #>  #> $error #> [1] \"errors\" #>  #> $evaluate #> [1] \"evaluating\" \"evaluates\"  \"evaluated\"  #>  #> $evaluation #> [1] \"evaluations\" #>  #> $examine #> [1] \"examining\" \"examines\"  \"examined\"  #>  #> $examination #> [1] \"examinations\" #>  #> $exist #> [1] \"exists\" #>  #> $experience #> [1] \"experienc*\" #>  #> $fact #> [1] \"facts\" #>  #> $feature #> [1] \"features\" #>  #> $field #> [1] \"fields\" #>  #> $find #> [1] \"finding\" \"finds\"   \"found\"   #>  #> $form #> [1] \"forms\" #>  #> $formula #> [1] \"formulas\" #>  #> $framework #> [1] \"frameworks\" #>  #> $fractions #> [1] \"fraction\" #>  #> $`function` #> [1] \"functions\" #>  #> $game #> [1] \"games\" #>  #> $geometry #> [1] \"geometr*\" #>  #> $grade #> [1] \"grades\" #>  #> $graph #> [1] \"graphs\" #>  #> $group #> [1] \"groups\" #>  #> $guideline #> [1] \"guidelines\" #>  #> $handheld #> [1] \"hand held*\" #>  #> $identify #> [1] \"identif*\" #>  #> $image #> [1] \"images\" #>  #> $impairment #> [1] \"impairments\" #>  #> $implication #> [1] \"implications\" #>  #> $improvement #> [1] \"improvements\" #>  #> $include #> [1] \"includ*\" #>  #> $individual #> [1] \"individuals\" #>  #> $instruction #> [1] \"instructions\" #>  #> $interface #> [1] \"interfaces\" #>  #> $intervention #> [1] \"interventions\" #>  #> $involve #> [1] \"involv*\" #>  #> $iPad #> [1] \"ipad*\" #>  #> $iPod #> [1] \"ipod*\" #>  #> $learner #> [1] \"learners\" #>  #> $learning #> [1] \"learn\"   \"learns\"  \"learned\" #>  #> $lesson #> [1] \"lessons\" #>  #> $level #> [1] \"levels\" #>  #> $literature #> [1] \"literatures\" #>  #> $Kindle #> [1] \"kindle*\" #>  #> $manipulatives #> [1] \"manipulative\" #>  #> $map #> [1] \"maps\" #>  #> $material #> [1] \"materials\" #>  #> $measure #> [1] \"measur*\" #>  #> $mathematics #> [1] \"math\" #>  #> $method #> [1] \"methods\" #>  #> $mode #> [1] \"modes\" #>  #> $model #> [1] \"models\"   \"modeled\"  \"modelled\" #>  #> $modeling #> [1] \"modelling\" #>  #> $multiplication #> [1] \"multiplying\" \"multiply\"    \"multiplies\"  \"multiplied\"  #>  #> $need #> [1] \"needs\" #>  #> $number #> [1] \"numbers\" #>  #> $on_task #> [1] \"on task\" #>  #> $opportunity #> [1] \"opportunities\" #>  #> $outcome #> [1] \"outcomes\" #>  #> $participant #> [1] \"participants\" #>  #> $peer #> [1] \"peers\" #>  #> $performance #> [1] \"performances\" #>  #> $phase #> [1] \"phases\" #>  #> $possibility #> [1] \"possibilities\" #>  #> $practice #> [1] \"practices\" #>  #> $preference #> [1] \"preferences\" #>  #> $present #> [1] \"presenting\" \"presents\"   \"presented\"  #>  #> $presentation #> [1] \"presentations\" #>  #> $print #> [1] \"prints\" #>  #> $probe #> [1] \"probes\" #>  #> $procedure #> [1] \"procedures\" #>  #> $process #> [1] \"processes\" #>  #> $problem #> [1] \"problems\" #>  #> $program #> [1] \"programs\" #>  #> $prompt #> [1] \"prompts\" #>  #> $provide #> [1] \"providing\" \"provides\"  \"provided\"  #>  #> $publish #> [1] \"publish*\" #>  #> $pupil #> [1] \"pupils\" #>  #> $quality #> [1] \"qualities\" #>  #> $question #> [1] \"questions\" #>  #> $rate #> [1] \"rates\" #>  #> $reading #> [1] \"read*\" #>  #> $recommendation #> [1] \"recommendations\" #>  #> $reinforcement #> [1] \"reinforcement*\" #>  #> $relation #> [1] \"relations\" #>  #> $represent #> [1] \"representing\" \"represents\"   \"represented\"  #>  #> $representation #> [1] \"representations\" #>  #> $require #> [1] \"requires\" #>  #> $resource #> [1] \"resources\" #>  #> $response #> [1] \"responses\" #>  #> $result #> [1] \"results\" #>  #> $review #> [1] \"review*\" #>  #> $robot #> [1] \"robots\" #>  #> $school #> [1] \"schools\" #>  #> $score #> [1] \"scores\" #>  #> $session #> [1] \"sessions\" #>  #> $setting #> [1] \"settings\" #>  #> $show #> [1] \"showing\" \"shows\"   \"showed\"  #>  #> $simulation #> [1] \"simulations\" #>  #> $shape #> [1] \"shapes\" #>  #> $skill #> [1] \"skills\" #>  #> $software #> [1] \"softwares\" #>  #> $solving #> [1] \"solve\"  \"solves\" \"solved\" #>  #> $standard #> [1] \"standards\" #>  #> $step #> [1] \"steps\" #>  #> $strategy #> [1] \"strategies\" #>  #> $student #> [1] \"students\" \"ss\"       #>  #> $study #> [1] \"studies\"  \"studying\" \"studied\"  #>  #> $subject #> [1] \"subjects\" #>  #> $subtraction #> [1] \"subtracting\" \"subtract\"    \"subtracted\"  #>  #> $support #> [1] \"support*\" #>  #> $symmetry #> [1] \"symmetries\" #>  #> $system #> [1] \"systems\" #>  #> $tablet #> [1] \"tablets\" #>  #> $task #> [1] \"tasks\" #>  #> $teacher #> [1] \"teachers\" #>  #> $teach #> [1] \"teaching\" \"teaches\"  \"taught\"   #>  #> $technology #> [1] \"technologies\" #>  #> $term #> [1] \"terms\" #>  #> $testing #> [1] \"test\"   \"tests\"  \"tested\" #>  #> $text #> [1] \"texts\" #>  #> $textbook #> [1] \"textbooks\" #>  #> $time #> [1] \"times\" #>  #> $tool #> [1] \"tools\" #>  #> $topic #> [1] \"topics\" #>  #> $treatment #> [1] \"treatments\" #>  #> $type #> [1] \"types\" #>  #> $understanding #> [1] \"understand\"  \"understood\"  \"understands\" #>  #> $unit #> [1] \"units\" #>  #> $universal_design #> [1] \"universal* design*\" #>  #> $use #> [1] \"using\" \"uses\"  \"used\"  #>  #> $user #> [1] \"users\" #>  #> $variable #> [1] \"variables\" #>  #> $video #> [1] \"videos\" #>  #> $virtual_abstract #> [1] \"virtual abstract\" #>  #> $virtual_representational #> [1] \"virtual representational\" #>  #> $visual #> [1] \"visuals\" #>  #> $way #> [1] \"ways\" #>  #> $web #> [1] \"web*\" #>  #> $week #> [1] \"weeks\" #>  #> $writer #> [1] \"writers\" #>  #> $writing #> [1] \"write\"   \"wrote\"   \"writes\"  \"written\" #>  #> $year #> [1] \"years\" #>"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/evaluate_optimal_topic_number.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","title":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","text":"function performs search optimal number topics (K) using stm::searchK visualizes diagnostics, including held-likelihood, residuals, semantic coherence, lower bound metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/evaluate_optimal_topic_number.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","text":"","code":"evaluate_optimal_topic_number(   dfm_object,   topic_range,   max.em.its = 75,   categorical_var = NULL,   continuous_var = NULL,   height = 600,   width = 800,   verbose = TRUE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/evaluate_optimal_topic_number.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","text":"dfm_object quanteda document-feature matrix (dfm). topic_range numeric vector specifying range topics (K) search . max.em.Maximum number EM iterations (default: 75). categorical_var optional character string categorical variable metadata. continuous_var optional character string continuous variable metadata. height height resulting Plotly plot pixels (default: 600). width width resulting Plotly plot pixels (default: 800). verbose Logical; TRUE, prints progress information. ... arguments passed stm::searchK.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/evaluate_optimal_topic_number.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","text":"plotly object showing diagnostics number topics (K).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/evaluate_optimal_topic_number.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate Optimal Number of Topics — evaluate_optimal_topic_number","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   TextAnalysisR::evaluate_optimal_topic_number(     dfm_object = dfm_object,     topic_range = 5:30,     max.em.its = 75,     categorical_var = \"reference_type\",     continuous_var = \"year\",     height = 600,     width = 800,     verbose = TRUE   ) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"function calculates mean topic prevalence across documents plots top topics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"","code":"plot_mean_topic_prevalence(   dfm_object,   topic_n,   max.em.its = 75,   categorical_var = NULL,   continuous_var = NULL,   top_term_n = 10,   top_topic_n = 15,   topic_names = NULL,   height = 500,   width = 900,   verbose = TRUE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"dfm_object quanteda document-feature matrix (dfm). topic_n number topics display. max.em.Maximum number EM iterations (default: 75). categorical_var optional character string categorical variable metadata. continuous_var optional character string continuous variable metadata. top_term_n number top terms display topic (default: 10). top_topic_n number top topics display (default: 15). topic_names optional character vector labeling topics. provided, must length number topics. height height resulting Plotly plot, pixels. Defaults 500. width width resulting Plotly plot, pixels. Defaults 1000. verbose Logical; TRUE, prints progress information (default: FALSE). ... arguments passed stm::searchK.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"ggplot object showing bar plot topic prevalence. Topics ordered mean gamma value (average prevalence across documents).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"topic_names provided, replaces default \"Topic {n}\" labels custom names.#'","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_mean_topic_prevalence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Mean Topic Prevalence Across Documents — plot_mean_topic_prevalence","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens) TextAnalysisR::plot_mean_topic_prevalence(   dfm_object = dfm_object,   topic_n = 15,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   top_term_n = 10,   top_topic_n = 15,   height = 500,   width = 900,   verbose = TRUE) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Word Frequency — plot_word_frequency","title":"Plot Word Frequency — plot_word_frequency","text":"Given document-feature matrix (dfm), function computes frequent terms creates ggplot-based visualization term frequencies.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Word Frequency — plot_word_frequency","text":"","code":"plot_word_frequency(dfm_object, n = 20, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Word Frequency — plot_word_frequency","text":"dfm_object quanteda dfm object. n number top terms display (default: 20). ... arguments passed quanteda.textstats::textstat_frequency.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Word Frequency — plot_word_frequency","text":"ggplot object visualizing top terms frequency. plot shows term one axis frequency , points representing observed frequencies.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Word Frequency — plot_word_frequency","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   word_frequency_plot <- TextAnalysisR::plot_word_frequency(dfm_object, n = 20)   word_frequency_plot }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"function provides visualization top terms topic, ordered word probability distribution topic (beta).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"","code":"plot_word_probabilities(   dfm_object,   topic_n,   max.em.its = 75,   categorical_var = NULL,   continuous_var = NULL,   top_term_n = 10,   ncol = 3,   topic_names = NULL,   height = 1200,   width = 800,   verbose = TRUE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"dfm_object quanteda document-feature matrix (dfm). topic_n number topics display. max.em.Maximum number EM iterations (default: 75). categorical_var optional character string categorical variable metadata. continuous_var optional character string continuous variable metadata. top_term_n number top terms display topic (default: 10). ncol number columns facet plot (default: 3). topic_names optional character vector labeling topics. provided, must length number topics. height height resulting Plotly plot, pixels. Defaults 1200. width width resulting Plotly plot, pixels. Defaults 800. verbose Logical; TRUE, prints progress information. ... arguments passed stm::searchK.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"Plotly object showing facet-wrapped chart top terms topic, ordered per-topic probability (beta). facet represents topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"topic_names provided, replaces default \"Topic {n}\" labels custom names.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Highest Word Probabilities for Each Topic — plot_word_probabilities","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens) TextAnalysisR::plot_word_probabilities(   dfm_object = dfm_object,   topic_n = 15,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   top_term_n = 10,   ncol = 3,   height = 1200,   width = 800,   verbose = TRUE) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/preprocess_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Text Data — preprocess_texts","title":"Preprocess Text Data — preprocess_texts","text":"Preprocesses text data : Constructing corpus Tokenizing text words Converting lowercase Removing default English stopwords optional custom stopwords Specifying minimum token length. Typically used constructing dfm fitting STM model.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/preprocess_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Text Data — preprocess_texts","text":"","code":"preprocess_texts(   united_tbl,   text_field = \"united_texts\",   custom_stopwords = NULL,   min_char = 2,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/preprocess_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Text Data — preprocess_texts","text":"united_tbl data frame contains text data. text_field name column united_tbl contains text data. custom_stopwords character vector additional stopwords remove. Default NULL. min_char Minimum length characters tokens (default 2). ... arguments passed quanteda::corpus.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/preprocess_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Text Data — preprocess_texts","text":"quanteda tokens object. row object represents document, column represents token. object ready constructing dfm fitting STM model.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/preprocess_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess Text Data — preprocess_texts","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   tokens }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_common_words.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Common Words Across Documents — remove_common_words","title":"Remove Common Words Across Documents — remove_common_words","text":"function removes specified common words tokens object applies two dictionaries categorize remaining tokens. returns document-feature matrix (dfm) based processed tokens. words specified removal, returns initial dfm using provided initialization function.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_common_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Common Words Across Documents — remove_common_words","text":"","code":"remove_common_words(tokens, remove_vars, dfm_object)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_common_words.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Common Words Across Documents — remove_common_words","text":"tokens tokens object quanteda package, typically processed using functions like tokens_select tokens_remove. remove_vars character vector words remove tokens. NULL, function returns result dfm_init_func(). dfm_object dfm object process removing specified words.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_common_words.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Common Words Across Documents — remove_common_words","text":"dfm object specified words removed remaining tokens categorized","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_common_words.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Common Words Across Documents — remove_common_words","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   TextAnalysisR::remove_common_words(tokens = tokens,                                      remove_vars = c(\"level\", \"testing\"),                                      dfm_object = dfm_object) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":null,"dir":"Reference","previous_headings":"","what":"Special education technology bibliographic data — SpecialEduTech","title":"Special education technology bibliographic data — SpecialEduTech","text":"Contains bibliographic data journal articles dissertations use technology teaching mathematics students disabilities.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Special education technology bibliographic data — SpecialEduTech","text":"","code":"SpecialEduTech"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Special education technology bibliographic data — SpecialEduTech","text":"object class tbl_df (inherits tbl, data.frame) 490 rows 6 columns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Special education technology bibliographic data — SpecialEduTech","text":"","code":"SpecialEduTech #> # A tibble: 490 × 6 #>    reference_type  author                            year title keyword abstract #>    <chr>           <chr>                            <dbl> <chr> <chr>   <chr>    #>  1 journal_article Block, G. H.                      1980 Dysc… Arithm… Notes t… #>  2 thesis          Bukatman, K. L.                   1981 The … locus … This st… #>  3 journal_article Watkins, M. W., & Webb, C.        1981 Comp… Comput… Results… #>  4 journal_article Chaffin, J. D.                    1982 Arc-… Comput… The Arc… #>  5 journal_article Chaffin, J. D., Maxwell, B., & …  1982 ARC-… Electr… This ar… #>  6 thesis          Golden, C. K.                     1982 The … NA      The pur… #>  7 journal_article Neal, D.                          1982 A re… tradit… Discuss… #>  8 thesis          Englebert, B. B.                  1983 A st… microc… The pur… #>  9 thesis          Foster, K.                        1983 The … comput… The eff… #> 10 journal_article Pommer, L. T.                     1983 Usin… Comput… The art… #> # ℹ 480 more rows"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":null,"dir":"Reference","previous_headings":"","what":"An example structure of a structural topic model — stm_15","title":"An example structure of a structural topic model — stm_15","text":"Contains 15 topics, topic prevalences, etc. stm::stm.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An example structure of a structural topic model — stm_15","text":"","code":"stm_15"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An example structure of a structural topic model — stm_15","text":"object class STM length 11.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An example structure of a structural topic model — stm_15","text":"","code":"stm_15 #> A topic model with 15 topics, 488 documents and a 4511 word dictionary."},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Data-driven stopword list — stopwords_list","title":"Data-driven stopword list — stopwords_list","text":"Contains stopword list created based inverse document frequency SpecialEduTech","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data-driven stopword list — stopwords_list","text":"","code":"stopwords_list"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data-driven stopword list — stopwords_list","text":"object class character length 117.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data-driven stopword list — stopwords_list","text":"","code":"stopwords_list #>   [1] \"ability\"           \"able\"              \"across\"            #>   [4] \"activity\"          \"also\"              \"although\"          #>   [7] \"among\"             \"analysis\"          \"analyzed\"          #>  [10] \"approach\"          \"article\"           \"based\"             #>  [13] \"can\"               \"child\"             \"class\"             #>  [16] \"classroom\"         \"compared\"          \"completed\"         #>  [19] \"condition\"         \"conducted\"         \"content\"           #>  [22] \"control\"           \"current\"           \"data\"              #>  [25] \"demonstrate\"       \"describe\"          \"design\"            #>  [28] \"determine\"         \"disability\"        \"discussed\"         #>  [31] \"education\"         \"educator\"          \"effect\"            #>  [34] \"effective\"         \"examine\"           \"explored\"          #>  [37] \"find\"              \"findings\"          \"five\"              #>  [40] \"four\"              \"future\"            \"general\"           #>  [43] \"given\"             \"grade\"             \"group\"             #>  [46] \"help\"              \"however\"           \"i.e\"               #>  [49] \"implication\"       \"important\"         \"improve\"           #>  [52] \"improved\"          \"improvement\"       \"include\"           #>  [55] \"increase\"          \"increased\"         \"indicate\"          #>  [58] \"indicated\"         \"instruction\"       \"intervention\"      #>  [61] \"involve\"           \"learning\"          \"limitations\"       #>  [64] \"limited\"           \"literature\"        \"many\"              #>  [67] \"mathematics\"       \"may\"               \"method\"            #>  [70] \"often\"             \"one\"               \"outcome\"           #>  [73] \"overall\"           \"paper\"             \"participant\"       #>  [76] \"participated\"      \"performance\"       \"posttest\"          #>  [79] \"present\"           \"pretest\"           \"problem\"           #>  [82] \"provide\"           \"purpose\"           \"reading\"           #>  [85] \"regarding\"         \"research\"          \"researchers\"       #>  [88] \"result\"            \"revealed\"          \"review\"            #>  [91] \"school\"            \"science\"           \"setting\"           #>  [94] \"several\"           \"show\"              \"significant\"       #>  [97] \"significantly\"     \"skill\"             \"special_education\" #> [100] \"student\"           \"study\"             \"suggest\"           #> [103] \"support\"           \"teach\"             \"teacher\"           #> [106] \"technology\"        \"three\"             \"traditional\"       #> [109] \"treatment\"         \"two\"               \"use\"               #> [112] \"way\"               \"well\"              \"whether\"           #> [115] \"within\"            \"without\"           \"yet\""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"function analyzes visualizes term proportions continuous variable.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"","code":"term_proportion(   dfm_object,   stm_model,   continuous_variable,   selected_terms,   height = 500,   width = 900 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"dfm_object quanteda document-feature matrix (dfm). stm_model STM model object. continuous_variable continuous variable metadata. selected_terms vector terms analyze trends . height height resulting Plotly plot, pixels. Defaults 500. width width resulting Plotly plot, pixels. Defaults 900.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"list containing Plotly objects tables results.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"function requires fitted STM model object quanteda dfm object.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/term_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Term Proportions by a Continuous Variable — term_proportion","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   stm_15 <- TextAnalysisR::stm_15   term_proportion_results <- TextAnalysisR::term_proportion(                              dfm_object,                              stm_model = stm_15,                              continuous_variable = \"year\",                              selected_terms = c(\"calculator\", \"computer\"),                              height = 500,                              width = 900)   term_proportion_results$plot   term_proportion_results$table }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"TextAnalysisR: A text mining workflow tool — TextAnalysisR-package","title":"TextAnalysisR: A text mining workflow tool — TextAnalysisR-package","text":"'TextAnalysisR' provides supporting workflow tool text mining analysis. web app incorporates 'quanteda' (text preprocessing), 'stm' (structural topic modeling), 'ggraph', 'widyr' (network analysis). 'tidytext' implemented tidy non-tidy format objects. R Shiny web app available 'TextAnalysisR::TextAnalysisR.app()' 'https://textanalysisr.org'. Functions provided completing word-topic probabilities, document-topic probabilities, estimated effects covariates topic prevalence, network analysis, similar tasks available web app.","code":""},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"TextAnalysisR: A text mining workflow tool — TextAnalysisR-package","text":"Maintainer: Mikyung Shin shin.mikyung@gmail.com (ORCID)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR.app.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch and browse the TextAnalysisR app — TextAnalysisR.app","title":"Launch and browse the TextAnalysisR app — TextAnalysisR.app","text":"Launch browse TextAnalysisR app.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR.app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch and browse the TextAnalysisR app — TextAnalysisR.app","text":"","code":"TextAnalysisR.app()"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR.app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Launch and browse the TextAnalysisR app — TextAnalysisR.app","text":"","code":"if (interactive()) {   library(TextAnalysisR)   TextAnalysisR.app() }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_text_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Unite Text Columns — unite_text_cols","title":"Unite Text Columns — unite_text_cols","text":"function unites specified text columns data frame single column named \"united_texts\" retaining original columns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_text_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unite Text Columns — unite_text_cols","text":"","code":"unite_text_cols(df, listed_vars)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_text_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unite Text Columns — unite_text_cols","text":"df data frame contains text data. listed_vars character vector column names united \"united_texts\".","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_text_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unite Text Columns — unite_text_cols","text":"data frame new column \"united_texts\" created uniting specified variables.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_text_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unite Text Columns — unite_text_cols","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   united_tbl }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_correlation_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Word Correlation Networks — word_correlation_network","title":"Analyze and Visualize Word Correlation Networks — word_correlation_network","text":"function creates word correlation network based document-feature matrix (dfm).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_correlation_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Word Correlation Networks — word_correlation_network","text":"","code":"word_correlation_network(   dfm_object,   co_occur_n = 30,   corr_n = 0.4,   top_node_n = 40,   height = 1000,   width = 900 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_correlation_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Word Correlation Networks — word_correlation_network","text":"dfm_object quanteda document-feature matrix (dfm). co_occur_n Minimum number co-occurrences filtering terms (default 30). corr_n Minimum correlation value filtering terms (default 0.4). top_node_n Number top nodes display (default 40). height height resulting Plotly plot, pixels. Defaults 1000. width width resulting Plotly plot, pixels. Defaults 900.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_correlation_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Word Correlation Networks — word_correlation_network","text":"list containing Plotly object data frame results.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_correlation_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Word Correlation Networks — word_correlation_network","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   word_correlation_network_results <- TextAnalysisR::word_correlation_network(                                       dfm_object,                                       co_occur_n = 30,                                       corr_n = 0.4,                                       top_node_n = 40,                                       height = 1000,                                       width = 900)   word_correlation_network_results$plot   word_correlation_network_results$table   word_correlation_network_results$summary }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_co_occurrence_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","title":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","text":"function creates word co-occurrence network based document-feature matrix (dfm).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_co_occurrence_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","text":"","code":"word_co_occurrence_network(   dfm_object,   co_occur_n = 130,   top_node_n = 30,   height = 800,   width = 900 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_co_occurrence_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","text":"dfm_object quanteda document-feature matrix (dfm). co_occur_n Minimum number co-occurrences filtering terms (default 130). top_node_n Number top nodes display (default 30). height height resulting Plotly plot, pixels. Defaults 800. width width resulting Plotly plot, pixels. Defaults 900.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_co_occurrence_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","text":"list containing Plotly object data frame results.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/word_co_occurrence_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Word Co-occurrence Networks — word_co_occurrence_network","text":"","code":"if (interactive()) {   df <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_text_cols(df, listed_vars = c(\"title\", \"keyword\", \"abstract\"))   tokens <- TextAnalysisR::preprocess_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   word_co_occurrence_network_results <- TextAnalysisR::word_co_occurrence_network(                                         dfm_object,                                         co_occur_n = 130,                                         top_node_n = 30,                                         height = 800,                                         width = 900)   word_co_occurrence_network_results$plot   word_co_occurrence_network_results$table   word_co_occurrence_network_results$summary }"},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"textanalysisr-001-2023-10-18","dir":"Changelog","previous_headings":"","what":"TextAnalysisR 0.0.1 (2023-10-18)","title":"TextAnalysisR 0.0.1 (2023-10-18)","text":"CRAN Submission TextAnalysisR 0.0.1","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"textanalysisr-002-2024-12-05","dir":"Changelog","previous_headings":"","what":"TextAnalysisR 0.0.2 (2024-12-05)","title":"TextAnalysisR 0.0.2 (2024-12-05)","text":"Added reference : Shin, M., Ok, M. W., Choo, S., Hossain, G., Bryant, D. P., & Kang, E. (2023) DESCRIPTION. Quoted software package names DESCRIPTION field. Improved documentation follow CRAN policies.","code":""}]
