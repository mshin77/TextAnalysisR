[{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/cybersecurity.html","id":"api-key-storage","dir":"Articles","previous_headings":"","what":"API Key Storage","title":"Security","text":"App: Secure password field, session-storage Environment Variable: Encrypted (Advanced):","code":"Sys.setenv(OPENAI_API_KEY = \"sk-...\") keyring::key_set(\"openai_api\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/cybersecurity.html","id":"privacy","dir":"Articles","previous_headings":"","what":"Privacy","title":"Security","text":"100% local processing R package Optional local AI via Ollama HIPAA/FERPA compliant Works offline","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/articles/installation.html","id":"r-package","dir":"Articles","previous_headings":"","what":"R Package","title":"Installation","text":"Requirements: R >= 4.0, RStudio recommended","code":"install.packages(\"remotes\") remotes::install_github(\"mshin77/TextAnalysisR\") library(TextAnalysisR) run_app()"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/installation.html","id":"web-app","dir":"Articles","previous_headings":"","what":"Web App","title":"Installation","text":"Visit textanalysisr.org - installation needed. Note: Web version limited features (Python, AI, large files).","code":""},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/installation.html","id":"linguistic-analysis-spacy","dir":"Articles","previous_headings":"Optional Features","what":"Linguistic Analysis (spaCy)","title":"Installation","text":"lemmatization, POS tagging, named entity recognition:","code":"install.packages(\"spacyr\") spacyr::spacy_install()"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/installation.html","id":"python-features","dir":"Articles","previous_headings":"Optional Features","what":"Python Features","title":"Installation","text":"PDF tables, embeddings, AI-assisted analysis: Requires Python 3.9+ optionally Ollama local AI.","code":"setup_python_env()"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Lexical Analysis","text":"","code":"library(TextAnalysisR)  mydata <- SpecialEduTech united_tbl <- unite_cols(mydata, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- prep_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"word-frequency","dir":"Articles","previous_headings":"","what":"Word Frequency","title":"Lexical Analysis","text":"","code":"plot_word_frequency(dfm_object, top_n = 20)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"tf-idf","dir":"Articles","previous_headings":"Keyword Extraction","what":"TF-IDF","title":"Lexical Analysis","text":"Find distinctive words per document:","code":"keywords <- extract_keywords_tfidf(dfm_object, top_n = 10) plot_tfidf_keywords(keywords, n_docs = 5)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"keyness","dir":"Articles","previous_headings":"Keyword Extraction","what":"Keyness","title":"Lexical Analysis","text":"Compare word usage groups:","code":"keyness <- extract_keywords_keyness(   dfm_object,   target_group = \"Journal Article\",   reference_groups = \"Conference Paper\",   category_var = \"reference_type\" ) plot_keyness_keywords(keyness)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"co-occurrence","dir":"Articles","previous_headings":"Word Networks","what":"Co-occurrence","title":"Lexical Analysis","text":"","code":"plot_cooccurrence_network(dfm_object, min_count = 10)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/lexical_analysis.html","id":"correlation","dir":"Articles","previous_headings":"Word Networks","what":"Correlation","title":"Lexical Analysis","text":"","code":"plot_correlation_network(dfm_object, min_cor = 0.3)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/multimodal_analysis.html","id":"local-ollama","dir":"Articles","previous_headings":"Setup","what":"Local (Ollama)","title":"Multimodal Analysis","text":"","code":"# Install from https://ollama.ai ollama pull llava"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/multimodal_analysis.html","id":"cloud-openai","dir":"Articles","previous_headings":"Setup","what":"Cloud (OpenAI)","title":"Multimodal Analysis","text":"","code":"Sys.setenv(OPENAI_API_KEY = \"sk-...\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/multimodal_analysis.html","id":"usage","dir":"Articles","previous_headings":"","what":"Usage","title":"Multimodal Analysis","text":"","code":"library(TextAnalysisR)  # Extract PDF with images result <- extract_pdf_multimodal(   \"document.pdf\",   vision_provider = \"ollama\"  # or \"openai\" )  # Use in analysis tokens <- prep_texts(result$combined_text)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/multimodal_analysis.html","id":"smart-extraction","dir":"Articles","previous_headings":"","what":"Smart Extraction","title":"Multimodal Analysis","text":"Auto-detects document type:","code":"result <- extract_pdf_smart(\"paper.pdf\", doc_type = \"auto\")"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/preprocessing.html","id":"workflow","dir":"Articles","previous_headings":"","what":"Workflow","title":"Preprocessing","text":"","code":"library(TextAnalysisR)  # 1. Load data mydata <- SpecialEduTech  # 2. Combine text columns united_tbl <- unite_cols(mydata, listed_vars = c(\"title\", \"keyword\", \"abstract\"))  # 3. Tokenize and clean tokens <- prep_texts(   united_tbl,   text_field = \"united_texts\",   remove_punct = TRUE,   remove_numbers = TRUE )  # 4. Remove stopwords tokens_clean <- quanteda::tokens_remove(tokens, quanteda::stopwords(\"en\"))  # 5. Create document-feature matrix dfm_object <- quanteda::dfm(tokens_clean)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/preprocessing.html","id":"multi-word-expressions","dir":"Articles","previous_headings":"","what":"Multi-word Expressions","title":"Preprocessing","text":"Detect phrases like “machine learning”:","code":"tokens <- detect_multi_words(tokens, min_count = 10)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/preprocessing.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Preprocessing","text":"Lexical Analysis Semantic Analysis Topic Modeling","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"quick-setup","dir":"Articles","previous_headings":"","what":"Quick Setup","title":"Python Environment","text":"Uses conda available, otherwise virtualenv.","code":"library(TextAnalysisR) setup_python_env()"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"check-status","dir":"Articles","previous_headings":"","what":"Check Status","title":"Python Environment","text":"","code":"check_python_env()"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"another-python-already-initialized","dir":"Articles","previous_headings":"Common Issues","what":"“Another Python already initialized”","title":"Python Environment","text":"Set preferred environment .Rprofile: restart R.","code":"Sys.setenv(RETICULATE_PYTHON_ENV = \"textanalysisr-env\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"environment-in-onedrive","dir":"Articles","previous_headings":"Common Issues","what":"Environment in OneDrive","title":"Python Environment","text":"Avoid OneDrive paths. Use:","code":"setup_python_env(method = \"virtualenv\", envpath = \"C:/Python/envs\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"deep-learning-optional","dir":"Articles","previous_headings":"","what":"Deep Learning (Optional)","title":"Python Environment","text":"embeddings neural sentiment:","code":"pip install sentence-transformers transformers torch"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/python_environment.html","id":"diagnostics","dir":"Articles","previous_headings":"","what":"Diagnostics","title":"Python Environment","text":"","code":"library(reticulate) py_config() conda_list()"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/quickstart.html","id":"install","dir":"Articles","previous_headings":"","what":"Install","title":"Getting Started","text":"","code":"install.packages(\"remotes\") remotes::install_github(\"mshin77/TextAnalysisR\")"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/quickstart.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch App","title":"Getting Started","text":"visit textanalysisr.org web version.","code":"library(TextAnalysisR) run_app()"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/quickstart.html","id":"quick-example","dir":"Articles","previous_headings":"","what":"Quick Example","title":"Getting Started","text":"","code":"library(TextAnalysisR)  # Load data mydata <- SpecialEduTech  # Combine text columns united_tbl <- unite_cols(mydata, listed_vars = c(\"title\", \"keyword\", \"abstract\"))  # Preprocess tokens <- prep_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens)  # Visualize plot_word_frequency(dfm_object, top_n = 20)"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/quickstart.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Getting Started","text":"Installation - Full setup guide Preprocessing - Prepare text data Lexical Analysis - Word patterns Semantic Analysis - Meaning similarity Topic Modeling - Discover themes","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Semantic Analysis","text":"","code":"library(TextAnalysisR)  mydata <- SpecialEduTech united_tbl <- unite_cols(mydata, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- prep_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"document-similarity","dir":"Articles","previous_headings":"","what":"Document Similarity","title":"Semantic Analysis","text":"","code":"similarity <- semantic_similarity_analysis(   texts = united_tbl$united_texts,   method = \"cosine\" )"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"lexicon-based-no-python","dir":"Articles","previous_headings":"Sentiment Analysis","what":"Lexicon-based (no Python)","title":"Semantic Analysis","text":"","code":"sentiment <- sentiment_lexicon_analysis(dfm_object, lexicon = \"afinn\") plot_sentiment_distribution(sentiment$document_sentiment)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"neural-requires-python","dir":"Articles","previous_headings":"Sentiment Analysis","what":"Neural (requires Python)","title":"Semantic Analysis","text":"","code":"sentiment <- sentiment_embedding_analysis(united_tbl$united_texts)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"document-clustering","dir":"Articles","previous_headings":"","what":"Document Clustering","title":"Semantic Analysis","text":"","code":"clusters <- semantic_document_clustering(   texts = united_tbl$united_texts,   n_clusters = 5 )  # AI-generated labels (optional) labels <- generate_cluster_labels(   clusters$cluster_keywords,   provider = \"ollama\"  # or \"openai\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/semantic_analysis.html","id":"temporal-analysis","dir":"Articles","previous_headings":"","what":"Temporal Analysis","title":"Semantic Analysis","text":"Track themes time:","code":"temporal <- temporal_semantic_analysis(   texts = united_tbl$united_texts,   timestamps = united_tbl$year )"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Topic Modeling","text":"","code":"library(TextAnalysisR)  mydata <- SpecialEduTech united_tbl <- unite_cols(mydata, listed_vars = c(\"title\", \"keyword\", \"abstract\")) tokens <- prep_texts(united_tbl, text_field = \"united_texts\") dfm_object <- quanteda::dfm(tokens)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"find-optimal-topics","dir":"Articles","previous_headings":"","what":"Find Optimal Topics","title":"Topic Modeling","text":"","code":"find_optimal_k(dfm_object, topic_range = 5:30)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"stm-statistical","dir":"Articles","previous_headings":"","what":"STM (Statistical)","title":"Topic Modeling","text":"Works metadata like year document type:","code":"out <- quanteda::convert(dfm_object, to = \"stm\")  model <- stm::stm(   documents = out$documents,   vocab = out$vocab,   K = 15,   prevalence = ~ reference_type + s(year),   data = out$meta )  # View topics terms <- get_topic_terms(model, top_term_n = 10)"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"embedding-based-semantic","dir":"Articles","previous_headings":"","what":"Embedding-based (Semantic)","title":"Topic Modeling","text":"Captures meaning using neural networks:","code":"results <- fit_semantic_model(   texts = united_tbl$united_texts,   n_topics = 15 )"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"hybrid","dir":"Articles","previous_headings":"","what":"Hybrid","title":"Topic Modeling","text":"Combines statistical semantic approaches:","code":"results <- fit_hybrid_model(   texts = united_tbl$united_texts,   metadata = united_tbl[, c(\"reference_type\", \"year\")],   n_topics_stm = 15 )"},{"path":"https://mshin77.github.io/TextAnalysisR/articles/topic_modeling.html","id":"ai-topic-labels","dir":"Articles","previous_headings":"","what":"AI Topic Labels","title":"Topic Modeling","text":"","code":"labels <- generate_topic_labels(   terms,   model = \"gpt-4o-mini\",   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\") )"},{"path":[]},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/articles/web_accessibility.html","id":"visual-features","dir":"Articles","previous_headings":"","what":"Visual Features","title":"Accessibility","text":"Dark mode toggle High contrast (4.5:1 ratio) 200% zoom support Reduced motion option","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/articles/web_accessibility.html","id":"screen-reader-support","dir":"Articles","previous_headings":"","what":"Screen Reader Support","title":"Accessibility","text":"Descriptive button labels Chart text descriptions Status announcements","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/articles/web_accessibility.html","id":"language-support","dir":"Articles","previous_headings":"","what":"Language Support","title":"Accessibility","text":"100+ languages via Google Translate Auto-detected text--speech","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mikyung Shin. Author, maintainer.            Illinois State University","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Shin, M. (2025). TextAnalysisR: Text mining workflow tool (Version 0.0.3) [R package]. https://github.com/mshin77/TextAnalysisR","code":"@Manual{,   title = {TextAnalysisR: Text mining workflow tool},   author = {Mikyung Shin},   year = {2025},   note = {R package version 0.0.3},   url = {https://mshin77.github.io/TextAnalysisR}, }"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Text Mining Workflow Tool","text":"development version GitHub :","code":"install.packages(\"devtools\") devtools::install_github(\"mshin77/TextAnalysisR\")"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"load-the-textanalysisr-package","dir":"","previous_headings":"","what":"Load the TextAnalysisR Package","title":"Text Mining Workflow Tool","text":"","code":"library(TextAnalysisR)"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"alternatively-launch-and-browse-the-shiny-app","dir":"","previous_headings":"","what":"Alternatively, Launch and Browse the Shiny App","title":"Text Mining Workflow Tool","text":"Access web app https://www.textanalysisr.org. Launch browse app local computer:","code":"run_app()"},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Text Mining Workflow Tool","text":"See Quick Start tutorials.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Text Mining Workflow Tool","text":"Shin, M. (2025). TextAnalysisR: text mining workflow tool (R package version 0.0.3) [Computer software]. https://mshin77.github.io/TextAnalysisR Shin, M. (2025). TextAnalysisR: text mining workflow tool [Web application]. https://www.textanalysisr.org","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":null,"dir":"Reference","previous_headings":"","what":"Acronym List — acronym","title":"Acronym List — acronym","text":"dataset containing common acronyms used text processing","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/acronym.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Acronym List — acronym","text":"character vector acronyms","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_document_clustering.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Document Clustering — analyze_document_clustering","title":"Analyze Document Clustering — analyze_document_clustering","text":"Complete document clustering analysis dimensionality reduction optional clustering","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_document_clustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Document Clustering — analyze_document_clustering","text":"","code":"analyze_document_clustering(   feature_matrix,   method = \"UMAP\",   clustering_method = \"none\",   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_document_clustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Document Clustering — analyze_document_clustering","text":"feature_matrix Feature matrix (documents x features) method Dimensionality reduction method (\"PCA\", \"t-SNE\", \"UMAP\") clustering_method Clustering method (\"none\", \"kmeans\", \"hierarchical\", \"dbscan\", \"hdbscan\") ... Additional parameters methods","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_document_clustering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Document Clustering — analyze_document_clustering","text":"List containing coordinates, clusters, method info, quality metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_semantic_evolution.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Semantic Evolution — analyze_semantic_evolution","title":"Analyze Semantic Evolution — analyze_semantic_evolution","text":"Analyzes semantic evolution patterns temporal results","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_semantic_evolution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Semantic Evolution — analyze_semantic_evolution","text":"","code":"analyze_semantic_evolution(temporal_results, verbose = FALSE, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_semantic_evolution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Semantic Evolution — analyze_semantic_evolution","text":"temporal_results Temporal analysis results verbose Logical indicating whether print progress messages ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_semantic_evolution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Semantic Evolution — analyze_semantic_evolution","text":"List containing evolution analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Text Sentiment — analyze_sentiment","title":"Analyze Text Sentiment — analyze_sentiment","text":"Performs sentiment analysis text data using syuzhet package. Returns sentiment scores classifications.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Text Sentiment — analyze_sentiment","text":"","code":"analyze_sentiment(texts, method = \"syuzhet\", doc_ids = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Text Sentiment — analyze_sentiment","text":"texts Character vector texts analyze method Sentiment analysis method: \"syuzhet\", \"bing\", \"afinn\", \"nrc\" (default: \"syuzhet\") doc_ids Optional character vector document identifiers (default: NULL)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Text Sentiment — analyze_sentiment","text":"data frame columns: document Document identifier text Original text sentiment_score Numeric sentiment score sentiment Classification: \"positive\", \"negative\", \"neutral\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze Text Sentiment — analyze_sentiment","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(   \"This research shows promising results for students.\",   \"The intervention had no significant effect.\",   \"Students struggled with the complex material.\" ) results <- analyze_sentiment(texts) print(results) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_topic_evolution.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Semantic Evolution — analyze_topic_evolution","title":"Analyze Semantic Evolution — analyze_topic_evolution","text":"Analyzes semantic patterns evolve time.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_topic_evolution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Semantic Evolution — analyze_topic_evolution","text":"","code":"analyze_topic_evolution(temporal_results, verbose = TRUE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_topic_evolution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Semantic Evolution — analyze_topic_evolution","text":"temporal_results Results temporal analysis. verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/analyze_topic_evolution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Semantic Evolution — analyze_topic_evolution","text":"Evolution patterns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Standard Plotly Layout — apply_standard_plotly_layout","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"Applies consistent layout styling plotly plots following TextAnalysisR design standards. ensures plots uniform fonts, colors, margins, interactive features.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"","code":"apply_standard_plotly_layout(   plot,   title = NULL,   xaxis_title = NULL,   yaxis_title = NULL,   margin = list(t = 60, b = 80, l = 80, r = 40),   show_legend = FALSE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"plot plotly plot object title Plot title text (optional) xaxis_title X-axis title (optional) yaxis_title Y-axis title (optional) margin List margins: list(t, b, l, r) pixels (default: list(t = 60, b = 80, l = 80, r = 40)) show_legend Logical, whether show legend (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"plotly plot object standardized layout","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"Design standards applied: Title: 20px Roboto, #0c1f4a Axis titles: 18px Roboto, #0c1f4a Axis labels: 18px Roboto, #3B3B3B Hover tooltips: 16px Roboto WCAG AA compliant colors","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/apply_standard_plotly_layout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Standard Plotly Layout — apply_standard_plotly_layout","text":"","code":"if (FALSE) { # \\dontrun{ library(plotly) p <- plot_ly(x = 1:10, y = rnorm(10), type = \"scatter\", mode = \"markers\") p %>% apply_standard_plotly_layout(   title = \"My Plot\",   xaxis_title = \"X Values\",   yaxis_title = \"Y Values\" ) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_assignment_consistency.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Assignment Consistency — calculate_assignment_consistency","title":"Calculate Assignment Consistency — calculate_assignment_consistency","text":"Calculates consistency two sets assignments","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_assignment_consistency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Assignment Consistency — calculate_assignment_consistency","text":"","code":"calculate_assignment_consistency(assignments1, assignments2, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_assignment_consistency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Assignment Consistency — calculate_assignment_consistency","text":"assignments1 First set assignments assignments2 Second set assignments ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_assignment_consistency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Assignment Consistency — calculate_assignment_consistency","text":"List containing consistency metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_coherence.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Semantic Coherence — calculate_coherence","title":"Validate Semantic Coherence — calculate_coherence","text":"Validates semantic coherence topic assignments.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_coherence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Semantic Coherence — calculate_coherence","text":"","code":"calculate_coherence(embeddings, topic_assignments)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_coherence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Semantic Coherence — calculate_coherence","text":"embeddings Document embeddings. topic_assignments Topic assignments.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_coherence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Semantic Coherence — calculate_coherence","text":"Coherence metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_consistency.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Assignment Consistency — calculate_consistency","title":"Calculate Assignment Consistency — calculate_consistency","text":"Calculates consistency different assignment methods.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_consistency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Assignment Consistency — calculate_consistency","text":"","code":"calculate_consistency(semantic_assignments, stm_assignments)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_consistency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Assignment Consistency — calculate_consistency","text":"semantic_assignments Semantic topic assignments. stm_assignments STM topic assignments.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_consistency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Assignment Consistency — calculate_consistency","text":"Consistency metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Web Accessibility Utility Functions — calculate_contrast_ratio","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"Functions ensuring WCAG 2.1 Level AA compliance Shiny application Calculates contrast ratio two colors according WCAG 2.1 standards using relative luminance formula W3C guidelines. Used verify text/background color combinations meet accessibility requirements.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"","code":"calculate_contrast_ratio(foreground, background)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"foreground Foreground color (hex format, e.g., \"#111827\") background Background color (hex format, e.g., \"#ffffff\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"Numeric contrast ratio (1-21)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"wcag-level-aa-compliance","dir":"Reference","previous_headings":"","what":"WCAG 2.1 Level AA Compliance","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"package follows Web Content Accessibility Guidelines (WCAG) 2.1 Level AA: 1.1.1 Non-text Content (Level ): Alt text images visualizations 1.4.3 Contrast Minimum (Level AA): 4.5:1 ratio normal text, 3:1 large text/UI 2.1.1 Keyboard (Level ): Full keyboard navigation support 2.4.1 Bypass Blocks (Level ): Skip navigation links 3.1.1 Language Page (Level ): Page language identification 4.1.2 Name, Role, Value (Level ): ARIA labels roles Calculate Color Contrast Ratio","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"wcag-requirements","dir":"Reference","previous_headings":"","what":"WCAG Requirements","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"Normal text: Minimum 4.5:1 (Level AA) Large text (18pt+ 14pt+ bold): Minimum 3:1 (Level AA) UI components graphics: Minimum 3:1 (Level AA)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_contrast_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Web Accessibility Utility Functions — calculate_contrast_ratio","text":"","code":"if (FALSE) { # \\dontrun{ calculate_contrast_ratio(\"#111827\", \"#ffffff\")  # Returns ~16:1 (Pass) calculate_contrast_ratio(\"#6b7280\", \"#4a5568\")  # Returns ~2.8:1 (Fail) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_cosine_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Cosine Similarity Matrix — calculate_cosine_similarity","title":"Calculate Cosine Similarity Matrix — calculate_cosine_similarity","text":"Calculates cosine similarity pairs rows matrix.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_cosine_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Cosine Similarity Matrix — calculate_cosine_similarity","text":"","code":"calculate_cosine_similarity(matrix_data)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_cosine_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Cosine Similarity Matrix — calculate_cosine_similarity","text":"matrix_data numeric matrix rows represent documents/observations","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_cosine_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Cosine Similarity Matrix — calculate_cosine_similarity","text":"square similarity matrix values -1 1","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_document_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Document Similarity — calculate_document_similarity","title":"Calculate Document Similarity — calculate_document_similarity","text":"Calculates similarity documents using traditional NLP methods modern embedding-based approaches. Comprehensive metrics automatically computed unless disabled.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_document_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Document Similarity — calculate_document_similarity","text":"","code":"calculate_document_similarity(   texts,   document_feature_type = \"words\",   semantic_ngram_range = 2,   similarity_method = \"cosine\",   use_embeddings = FALSE,   embedding_model = \"all-MiniLM-L6-v2\",   calculate_metrics = TRUE,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_document_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Document Similarity — calculate_document_similarity","text":"texts character vector texts compare. document_feature_type Feature extraction type: \"words\", \"ngrams\", \"embeddings\", \"topics\". semantic_ngram_range Integer, n-gram range ngram features (default: 2). similarity_method Similarity calculation method: \"cosine\", \"jaccard\", \"euclidean\", \"manhattan\". use_embeddings Logical, use embedding-based similarity (default: FALSE). embedding_model Sentence transformer model name (default: \"-MiniLM-L6-v2\"). calculate_metrics Logical, compute comprehensive similarity metrics (default: TRUE). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_document_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Document Similarity — calculate_document_similarity","text":"list containing: similarity_matrix N x N similarity matrix feature_matrix Document feature matrix used calculation method_info Information method used metrics Comprehensive similarity metrics (calculate_metrics = TRUE) execution_time Time taken analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_document_similarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Document Similarity — calculate_document_similarity","text":"","code":"if (interactive()) {   texts <- c(     \"Assistive technology supports learning for students with disabilities.\",     \"Technology aids help disabled students with their education.\",     \"Machine learning algorithms improve predictive accuracy.\"   )    result <- calculate_document_similarity(     texts = texts,     document_feature_type = \"words\",     similarity_method = \"cosine\"   )    print(result$similarity_matrix)   print(result$metrics) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_eval_metrics_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Comprehensive Evaluation Metrics Calculator — calculate_eval_metrics_internal","title":"Comprehensive Evaluation Metrics Calculator — calculate_eval_metrics_internal","text":"Calculates comprehensive evaluation metrics topic models including neural coherence, LLM-based coherence, semantic diversity, topic stability measures.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_eval_metrics_internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comprehensive Evaluation Metrics Calculator — calculate_eval_metrics_internal","text":"","code":"calculate_eval_metrics_internal(result, texts, selected_metrics)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_eval_metrics_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comprehensive Evaluation Metrics Calculator — calculate_eval_metrics_internal","text":"result Topic modeling result object texts Original text documents selected_metrics Vector metrics calculate","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_eval_metrics_internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comprehensive Evaluation Metrics Calculator — calculate_eval_metrics_internal","text":"List containing calculated evaluation metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_keyword_stability.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Keyword Stability — calculate_keyword_stability","title":"Calculate Keyword Stability — calculate_keyword_stability","text":"Calculates stability two sets topic keywords.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_keyword_stability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Keyword Stability — calculate_keyword_stability","text":"","code":"calculate_keyword_stability(keywords1, keywords2)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_keyword_stability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Keyword Stability — calculate_keyword_stability","text":"keywords1 First set keywords. keywords2 Second set keywords.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_keyword_stability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Keyword Stability — calculate_keyword_stability","text":"Stability score.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Comprehensive Metrics — calculate_metrics","title":"Calculate Comprehensive Metrics — calculate_metrics","text":"Calculates comprehensive similarity metrics including statistical measures network properties. Internal function used document_similarity_analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Comprehensive Metrics — calculate_metrics","text":"","code":"calculate_metrics(similarity_matrix, labels = NULL, method_info = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Comprehensive Metrics — calculate_metrics","text":"similarity_matrix similarity matrix. labels Optional vector labels clustering metrics. method_info Optional method information.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Comprehensive Metrics — calculate_metrics","text":"list comprehensive metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_semantic_drift.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Semantic Drift — calculate_semantic_drift","title":"Calculate Semantic Drift — calculate_semantic_drift","text":"Calculates semantic drift across time periods","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_semantic_drift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Semantic Drift — calculate_semantic_drift","text":"","code":"calculate_semantic_drift(temporal_results, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_semantic_drift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Semantic Drift — calculate_semantic_drift","text":"temporal_results Temporal analysis results ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_semantic_drift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Semantic Drift — calculate_semantic_drift","text":"List containing drift metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_similarity_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Similarity Robust — calculate_similarity_robust","title":"Calculate Similarity Robust — calculate_similarity_robust","text":"Calculates document similarity fallback methods diagnostics. Attempts embeddings first, falls back Jaccard similarity needed.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_similarity_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Similarity Robust — calculate_similarity_robust","text":"","code":"calculate_similarity_robust(   texts,   method = \"embeddings\",   embedding_model = \"all-MiniLM-L6-v2\",   cache_embeddings = TRUE,   min_word_length = 3,   doc_names = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_similarity_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Similarity Robust — calculate_similarity_robust","text":"texts Character vector texts method Similarity method (\"embeddings\" \"jaccard\") embedding_model Model name embeddings (default: \"-MiniLM-L6-v2\") cache_embeddings Logical, cache embeddings (default: TRUE) min_word_length Minimum word length Jaccard (default: 3) doc_names Optional document names","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_similarity_robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Similarity Robust — calculate_similarity_robust","text":"List containing similarity matrix, method used, embeddings, diagnostics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_similarity_robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Similarity Robust — calculate_similarity_robust","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(   \"Assistive technology supports learning.\",   \"Technology helps students with disabilities.\",   \"Machine learning improves accuracy.\" )  result <- calculate_similarity_robust(texts) print(result$similarity_matrix) print(result$diagnostics) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_text_readability.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Text Readability — calculate_text_readability","title":"Calculate Text Readability — calculate_text_readability","text":"Calculates multiple readability metrics texts including Flesch Reading Ease, Flesch-Kincaid Grade Level, Gunning FOG index, others. Optionally includes lexical diversity metrics sentence statistics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_text_readability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Text Readability — calculate_text_readability","text":"","code":"calculate_text_readability(   texts,   metrics = c(\"flesch\", \"flesch_kincaid\", \"gunning_fog\"),   include_lexical_diversity = TRUE,   include_sentence_stats = TRUE,   dfm_for_lexdiv = NULL,   doc_names = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_text_readability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Text Readability — calculate_text_readability","text":"texts Character vector texts analyze metrics Character vector readability metrics calculate. Options: \"flesch\", \"flesch_kincaid\", \"gunning_fog\", \"smog\", \"ari\", \"coleman_liau\" include_lexical_diversity Logical, include TTR MTLD (default: TRUE) include_sentence_stats Logical, include average sentence length (default: TRUE) dfm_for_lexdiv Optional pre-computed DFM lexical diversity calculation doc_names Optional character vector document names","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_text_readability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Text Readability — calculate_text_readability","text":"data frame document names readability scores","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_text_readability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Text Readability — calculate_text_readability","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(   \"This is simple text.\",   \"This sentence contains more complex vocabulary and structure.\" ) readability <- calculate_text_readability(texts) print(readability) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Topic Probabilities — calculate_topic_probability","title":"Calculate Topic Probabilities — calculate_topic_probability","text":"Extracts summarizes topic probabilities (gamma values) STM model, returning formatted data table mean topic prevalence.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Topic Probabilities — calculate_topic_probability","text":"","code":"calculate_topic_probability(stm_model, top_n = 10, verbose = TRUE, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Topic Probabilities — calculate_topic_probability","text":"stm_model fitted STM model object stm::stm(). top_n Number top topics display prevalence (default: 10). verbose Logical, TRUE prints progress messages (default: TRUE). ... Additional arguments passed tidytext::tidy().","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Topic Probabilities — calculate_topic_probability","text":"DT::datatable showing topics mean gamma (prevalence) values, rounded 3 decimal places.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_probability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Topic Probabilities — calculate_topic_probability","text":"","code":"if (interactive()) {   data <- TextAnalysisR::SpecialEduTech   united <- unite_cols(data, c(\"title\", \"keyword\", \"abstract\"))   tokens <- prep_texts(united, text_field = \"united_texts\")   dfm_obj <- quanteda::dfm(tokens)   stm_data <- quanteda::convert(dfm_obj, to = \"stm\")    topic_model <- stm::stm(     documents = stm_data$documents,     vocab = stm_data$vocab,     K = 10,     verbose = FALSE   )    prob_table <- calculate_topic_probability(topic_model, top_n = 10)   print(prob_table) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_quality.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Semantic Topic Quality Metrics — calculate_topic_quality","title":"Calculate Semantic Topic Quality Metrics — calculate_topic_quality","text":"Internal function calculate quality metrics semantic topic modeling results.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_quality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Semantic Topic Quality Metrics — calculate_topic_quality","text":"","code":"calculate_topic_quality(   embeddings,   topic_assignments,   similarity_matrix = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_quality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Semantic Topic Quality Metrics — calculate_topic_quality","text":"embeddings Document embeddings matrix. topic_assignments Vector topic assignments. similarity_matrix Optional similarity matrix.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_quality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Semantic Topic Quality Metrics — calculate_topic_quality","text":"list quality metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_stability.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Topic Stability — calculate_topic_stability","title":"Calculate Topic Stability — calculate_topic_stability","text":"Calculates stability topics across time periods.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_stability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Topic Stability — calculate_topic_stability","text":"","code":"calculate_topic_stability(temporal_results)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_stability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Topic Stability — calculate_topic_stability","text":"temporal_results Results temporal analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_topic_stability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Topic Stability — calculate_topic_stability","text":"Stability metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"function analyzes visualizes word frequencies across continuous variable.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"","code":"calculate_word_frequency(   dfm_object,   continuous_variable,   selected_terms,   height = 500,   width = 900 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"dfm_object quanteda document-feature matrix (dfm). continuous_variable continuous variable metadata. selected_terms vector terms analyze trends . height height resulting Plotly plot, pixels (default: 500). width width resulting Plotly plot, pixels (default: 900).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"list containing Plotly objects tables results.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"function requires fitted STM model object quanteda dfm object. continuous variable column metadata dfm object. selected terms vector terms analyze trends . required packages 'htmltools', 'splines', 'broom' (plus additional ones loaded internally).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/calculate_word_frequency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Word Frequencies Across a Continuous Variable — calculate_word_frequency","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    word_freq_results <- TextAnalysisR::calculate_word_frequency(     dfm_object,     continuous_variable = \"year\",     selected_terms = c(\"calculator\", \"computer\"),     height = 500,     width = 900   )   print(word_freq_results$plot)   print(word_freq_results$table) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/call_ollama.html","id":null,"dir":"Reference","previous_headings":"","what":"Call Ollama for Text Generation — call_ollama","title":"Call Ollama for Text Generation — call_ollama","text":"Sends prompt Ollama returns generated text.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/call_ollama.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call Ollama for Text Generation — call_ollama","text":"","code":"call_ollama(   prompt,   model = \"phi3:mini\",   temperature = 0.3,   max_tokens = 512,   timeout = 60,   verbose = FALSE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/call_ollama.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call Ollama for Text Generation — call_ollama","text":"prompt Character string containing prompt. model Character string specifying Ollama model (default: \"phi3:mini\"). temperature Numeric value controlling randomness (default: 0.3). max_tokens Maximum number tokens generate (default: 512). timeout Timeout seconds request (default: 60). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/call_ollama.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call Ollama for Text Generation — call_ollama","text":"Character string generated text, NULL failed.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/call_ollama.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call Ollama for Text Generation — call_ollama","text":"","code":"if (FALSE) { # \\dontrun{ response <- call_ollama(   prompt = \"Summarize these keywords: machine learning, neural networks, AI\",   model = \"phi3:mini\" ) print(response) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_alt_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Alt Text Presence — check_alt_text","title":"Check Alt Text Presence — check_alt_text","text":"Validates images visualizations alternative text descriptions. Required WCAG 1.1.1 (Non-text Content). Note: Decorative images use empty alt text (alt=\"\") indicate ignored assistive technology.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_alt_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Alt Text Presence — check_alt_text","text":"","code":"check_alt_text(alt_text, element_type = \"image\", decorative = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_alt_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Alt Text Presence — check_alt_text","text":"alt_text Alternative text description element_type Type element (e.g., \"plot\", \"image\", \"icon\") decorative Logical, TRUE element purely decorative","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_alt_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Alt Text Presence — check_alt_text","text":"Logical TRUE valid, FALSE warning missing/inadequate","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_alt_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Alt Text Presence — check_alt_text","text":"","code":"if (FALSE) { # \\dontrun{ check_alt_text(\"Bar chart showing word frequency\", \"plot\")  # TRUE check_alt_text(\"\", \"plot\")  # FALSE (informative content needs alt text) check_alt_text(\"\", \"icon\", decorative = TRUE)  # TRUE (decorative is OK) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Feature Status — check_feature","title":"Check Feature Status — check_feature","text":"Checks specific optional feature available current environment.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Feature Status — check_feature","text":"","code":"check_feature(feature)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Feature Status — check_feature","text":"feature Character: \"python\", \"ollama\", \"langgraph\", \"pdf_tables\", \"embeddings\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_feature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Feature Status — check_feature","text":"Logical TRUE feature available","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_feature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Feature Status — check_feature","text":"","code":"if (check_feature(\"ollama\")) {   # Use AI-powered labeling }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_multimodal_prerequisites.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Multimodal Prerequisites — check_multimodal_prerequisites","title":"Check Multimodal Prerequisites — check_multimodal_prerequisites","text":"Checks prerequisites multimodal PDF extraction returns detailed status setup instructions.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_multimodal_prerequisites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Multimodal Prerequisites — check_multimodal_prerequisites","text":"","code":"check_multimodal_prerequisites(   vision_provider = \"ollama\",   vision_model = NULL,   api_key = NULL,   envname = \"langgraph-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_multimodal_prerequisites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Multimodal Prerequisites — check_multimodal_prerequisites","text":"vision_provider Character: \"ollama\" \"openai\" vision_model Character: Model name (optional) api_key Character: API key OpenAI (using openai provider) envname Character: Python environment name","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_multimodal_prerequisites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Multimodal Prerequisites — check_multimodal_prerequisites","text":"List : ready: Logical - TRUE prerequisites met missing: Character vector missing components instructions: Character - Detailed setup instructions details: List component-specific status","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_ollama.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if Ollama is Available — check_ollama","title":"Check if Ollama is Available — check_ollama","text":"Checks Ollama installed running local machine.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_ollama.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if Ollama is Available — check_ollama","text":"","code":"check_ollama(verbose = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_ollama.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if Ollama is Available — check_ollama","text":"verbose Logical, TRUE, prints status messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_ollama.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if Ollama is Available — check_ollama","text":"Logical indicating whether Ollama available.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_ollama.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if Ollama is Available — check_ollama","text":"","code":"if (FALSE) { # \\dontrun{ if (check_ollama()) {   message(\"Ollama is ready!\") } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_python_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Python Environment Status — check_python_env","title":"Check Python Environment Status — check_python_env","text":"Checks Python environment available properly configured.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_python_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Python Environment Status — check_python_env","text":"","code":"check_python_env(envname = \"textanalysisr-env\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_python_env.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Python Environment Status — check_python_env","text":"envname Character string name virtual environment (default: \"textanalysisr-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_python_env.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Python Environment Status — check_python_env","text":"List status information: available: Logical, TRUE environment exists active: Logical, TRUE environment currently active packages: List installed package versions","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_python_env.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Python Environment Status — check_python_env","text":"","code":"if (FALSE) { # \\dontrun{ status <- check_python_env() print(status) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_rate_limit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Rate Limit — check_rate_limit","title":"Check Rate Limit — check_rate_limit","text":"Check Rate Limit","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_rate_limit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Rate Limit — check_rate_limit","text":"","code":"check_rate_limit(   session_token,   user_requests,   max_requests = 100,   window_seconds = 3600 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_rate_limit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Rate Limit — check_rate_limit","text":"session_token Shiny session token user_requests Reactive value storing request history max_requests Maximum requests allowed time window window_seconds Time window seconds (default: 3600 = 1 hour)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_rate_limit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Rate Limit — check_rate_limit","text":"TRUE within limit, stops error exceeded","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_vision_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Vision Model Availability — check_vision_models","title":"Check Vision Model Availability — check_vision_models","text":"Check required vision models available multimodal processing.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_vision_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Vision Model Availability — check_vision_models","text":"","code":"check_vision_models(provider = \"ollama\", api_key = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_vision_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Vision Model Availability — check_vision_models","text":"provider Character: \"ollama\" \"openai\" api_key Character: API key (OpenAI)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_vision_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Vision Model Availability — check_vision_models","text":"List availability status recommendations","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_vision_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Vision Model Availability — check_vision_models","text":"","code":"if (FALSE) { # \\dontrun{ # Check Ollama vision models status <- check_vision_models(\"ollama\") print(status$message)  # Check OpenAI access status <- check_vision_models(\"openai\", api_key = Sys.getenv(\"OPENAI_API_KEY\")) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_wcag_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Check WCAG Contrast Compliance — check_wcag_contrast","title":"Check WCAG Contrast Compliance — check_wcag_contrast","text":"Validates color combination meets WCAG 2.1 Level AA contrast requirements.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_wcag_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check WCAG Contrast Compliance — check_wcag_contrast","text":"","code":"check_wcag_contrast(foreground, background, large_text = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_wcag_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check WCAG Contrast Compliance — check_wcag_contrast","text":"foreground Foreground color (hex format) background Background color (hex format) large_text Logical, TRUE text large (18pt+ 14pt+ bold)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_wcag_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check WCAG Contrast Compliance — check_wcag_contrast","text":"Logical TRUE compliant, FALSE ","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_wcag_contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check WCAG Contrast Compliance — check_wcag_contrast","text":"","code":"if (FALSE) { # \\dontrun{ check_wcag_contrast(\"#111827\", \"#ffffff\")  # TRUE (16:1 ratio) check_wcag_contrast(\"#6b7280\", \"#4a5568\")  # FALSE (2.8:1 ratio) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_web_deployment.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Deployment Environment — check_web_deployment","title":"Check Deployment Environment — check_web_deployment","text":"Detects whether app running web server (shinyapps.io, Posit Connect) versus locally via run_app().","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_web_deployment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Deployment Environment — check_web_deployment","text":"","code":"check_web_deployment()"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_web_deployment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Deployment Environment — check_web_deployment","text":"Logical TRUE running web server, FALSE local","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/check_web_deployment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Deployment Environment — check_web_deployment","text":"","code":"if (check_web_deployment()) {   message(\"Running on web - some features disabled\") }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cluster_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding-based Document Clustering — cluster_embeddings","title":"Embedding-based Document Clustering — cluster_embeddings","text":"function performs clustering analysis using various methods, ordered simple comprehensive: k-means (simplest), hierarchical (intermediate), UMAP+DBSCAN (comprehensive).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cluster_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding-based Document Clustering — cluster_embeddings","text":"","code":"cluster_embeddings(   data_matrix,   method = \"kmeans\",   n_clusters = 0,   umap_neighbors = 15,   umap_min_dist = 0.1,   umap_n_components = 10,   umap_metric = \"cosine\",   dbscan_eps = 0,   dbscan_min_samples = 5,   seed = 123,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cluster_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding-based Document Clustering — cluster_embeddings","text":"data_matrix numeric matrix rows represent documents columns represent features. method clustering method. Options: \"kmeans\", \"hierarchical\", \"umap_dbscan\". n_clusters number clusters (k-means hierarchical). 0, optimal number determined automatically. umap_neighbors number neighbors UMAP (default: 15). umap_min_dist minimum distance UMAP (default: 0.1). umap_n_components number UMAP components (default: 10). umap_metric metric UMAP (default: \"cosine\"). dbscan_eps eps parameter DBSCAN. 0, optimal value determined automatically. dbscan_min_samples minimum samples DBSCAN (default: 5). seed Random seed reproducibility (default: 123). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cluster_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embedding-based Document Clustering — cluster_embeddings","text":"list containing cluster assignments, method used, quality metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cluster_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding-based Document Clustering — cluster_embeddings","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    data_matrix <- as.matrix(dfm_object)    kmeans_result <- TextAnalysisR::cluster_embeddings(     data_matrix,     method = \"kmeans\",     n_clusters = 5   )   print(kmeans_result)    hierarchical_result <- TextAnalysisR::cluster_embeddings(     data_matrix,     method = \"hierarchical\",     n_clusters = 5   )   print(hierarchical_result)    umap_dbscan_result <- TextAnalysisR::cluster_embeddings(     data_matrix,     method = \"umap_dbscan\",     umap_neighbors = 15,     umap_min_dist = 0.1   )   print(umap_dbscan_result) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_analysis_datatable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Formatted Analysis Data Table — create_analysis_datatable","title":"Create Formatted Analysis Data Table — create_analysis_datatable","text":"Creates consistently formatted DT::datatable analysis results export buttons optional numeric formatting.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_analysis_datatable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Formatted Analysis Data Table — create_analysis_datatable","text":"","code":"create_analysis_datatable(   data,   colnames = NULL,   numeric_cols = NULL,   digits = 3,   export_formats = c(\"copy\", \"csv\", \"excel\", \"pdf\", \"print\"),   page_length = 25,   font_size = \"16px\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_analysis_datatable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Formatted Analysis Data Table — create_analysis_datatable","text":"data Data frame display colnames Optional character vector column names display numeric_cols Optional character vector numeric columns round digits Number digits rounding numeric columns (default: 3) export_formats Character vector export formats (default: c('copy', 'csv', 'excel', 'pdf', 'print')) page_length Number rows per page (default: 25) font_size Font size table cells (default: \"16px\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_analysis_datatable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Formatted Analysis Data Table — create_analysis_datatable","text":"DT::datatable object","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_analysis_datatable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Formatted Analysis Data Table — create_analysis_datatable","text":"","code":"if (FALSE) { # \\dontrun{ df <- data.frame(term = c(\"word1\", \"word2\"), score = c(0.123456, 0.789012)) create_analysis_datatable(df, numeric_cols = \"score\", digits = 3) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_label_selection_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Label Selection UI Data — create_label_selection_data","title":"Create Label Selection UI Data — create_label_selection_data","text":"Creates structured list rendering label selection UI Shiny.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_label_selection_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Label Selection UI Data — create_label_selection_data","text":"","code":"create_label_selection_data(label_candidates)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_label_selection_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Label Selection UI Data — create_label_selection_data","text":"label_candidates List generate_topic_labels_langgraph()","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_label_selection_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Label Selection UI Data — create_label_selection_data","text":"List topic objects, : topic_number: Integer top_terms: Character vector candidates: List candidate objects","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_label_selection_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Label Selection UI Data — create_label_selection_data","text":"","code":"if (FALSE) { # \\dontrun{ result <- generate_topic_labels_langgraph(...) ui_data <- create_label_selection_data(result$label_candidates) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_message_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Message Data Table — create_message_table","title":"Create Message Data Table — create_message_table","text":"Creates formatted DT::datatable displaying informational message. Useful showing status messages place empty tables.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_message_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Message Data Table — create_message_table","text":"","code":"create_message_table(message, font_size = \"16px\", color = \"#6c757d\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_message_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Message Data Table — create_message_table","text":"message Character string message display font_size Font size (default: \"16px\") color Text color (default: \"#6c757d\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_message_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Message Data Table — create_message_table","text":"DT::datatable object","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_message_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Message Data Table — create_message_table","text":"","code":"if (FALSE) { # \\dontrun{ create_message_table(\"No data available. Please run analysis first.\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_sr_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Screen Reader Text — create_sr_text","title":"Create Screen Reader Text — create_sr_text","text":"Generates visually hidden text screen readers (WCAG 4.1.2).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_sr_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Screen Reader Text — create_sr_text","text":"","code":"create_sr_text(text)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_sr_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Screen Reader Text — create_sr_text","text":"text Text read screen readers","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_sr_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Screen Reader Text — create_sr_text","text":"HTML span sr-class","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_sr_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Screen Reader Text — create_sr_text","text":"","code":"if (FALSE) { # \\dontrun{ create_sr_text(\"Loading results, please wait\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_standard_ggplot_theme.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","title":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","text":"Returns standardized ggplot2 theme matching TextAnalysisR design standards.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_standard_ggplot_theme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","text":"","code":"create_standard_ggplot_theme(base_size = 14)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_standard_ggplot_theme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","text":"base_size Base font size (default: 14)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_standard_ggplot_theme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","text":"ggplot2 theme object","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/create_standard_ggplot_theme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Standard ggplot2 Theme — create_standard_ggplot_theme","text":"","code":"if (FALSE) { # \\dontrun{ library(ggplot2) ggplot(mtcars, aes(mpg, wt)) +   geom_point() +   create_standard_ggplot_theme() } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cross_analysis_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross Analysis Validation — cross_analysis_validation","title":"Cross Analysis Validation — cross_analysis_validation","text":"Performs cross-validation text analysis results","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cross_analysis_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross Analysis Validation — cross_analysis_validation","text":"","code":"cross_analysis_validation(results, verbose = FALSE, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cross_analysis_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross Analysis Validation — cross_analysis_validation","text":"results Analysis results object validate verbose Logical indicating whether print progress messages ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/cross_analysis_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross Analysis Validation — cross_analysis_validation","text":"List containing validation status metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_multi_words.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Multi-Word Expressions — detect_multi_words","title":"Detect Multi-Word Expressions — detect_multi_words","text":"function detects multi-word expressions (collocations) specified sizes appear least specified number times provided tokens.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_multi_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Multi-Word Expressions — detect_multi_words","text":"","code":"detect_multi_words(tokens, size = 2:5, min_count = 2)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_multi_words.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Multi-Word Expressions — detect_multi_words","text":"tokens tokens object quanteda package. size numeric vector specifying sizes collocations detect (default: 2:5). min_count minimum number occurrences collocation considered (default: 2).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_multi_words.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Multi-Word Expressions — detect_multi_words","text":"character vector detected collocations.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_multi_words.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Multi-Word Expressions — detect_multi_words","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    collocations <- TextAnalysisR::detect_multi_words(tokens, size = 2:5, min_count = 2)   print(collocations) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect PDF Content Type — detect_pdf_content_type","title":"Detect PDF Content Type — detect_pdf_content_type","text":"Analyzes PDF determine contains readable text.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect PDF Content Type — detect_pdf_content_type","text":"","code":"detect_pdf_content_type(file_path)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect PDF Content Type — detect_pdf_content_type","text":"file_path Character string path PDF file","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect PDF Content Type — detect_pdf_content_type","text":"Character string: \"text\" \"unknown\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect PDF Content Type — detect_pdf_content_type","text":"Attempts text extraction using pdftools. Returns \"text\" successful, \"unknown\" extraction fails PDF empty. table extraction PDFs, use extract_tables_from_pdf_py.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect PDF Content Type — detect_pdf_content_type","text":"","code":"if (FALSE) { # \\dontrun{ pdf_path <- \"path/to/document.pdf\" content_type <- detect_pdf_content_type(pdf_path) print(content_type) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect PDF Content Type using Python — detect_pdf_content_type_py","title":"Detect PDF Content Type using Python — detect_pdf_content_type_py","text":"Analyzes PDF determine contains primarily tabular data text.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect PDF Content Type using Python — detect_pdf_content_type_py","text":"","code":"detect_pdf_content_type_py(file_path, envname = \"textanalysisr-env\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect PDF Content Type using Python — detect_pdf_content_type_py","text":"file_path Character string path PDF file envname Character string, name Python virtual environment (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect PDF Content Type using Python — detect_pdf_content_type_py","text":"Character string: \"tabular\", \"text\", \"unknown\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/detect_pdf_content_type_py.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect PDF Content Type using Python — detect_pdf_content_type_py","text":"","code":"if (FALSE) { # \\dontrun{ setup_langgraph_env()  pdf_path <- \"path/to/document.pdf\" content_type <- detect_pdf_content_type_py(pdf_path) print(content_type) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Dictionary List 1 — dictionary_list_1","title":"Dictionary List 1 — dictionary_list_1","text":"dataset containing dictionary terms text analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dictionary List 1 — dictionary_list_1","text":"character vector dictionary terms","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Dictionary List 2 — dictionary_list_2","title":"Dictionary List 2 — dictionary_list_2","text":"dataset containing additional dictionary terms text analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/dictionary_list_2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dictionary List 2 — dictionary_list_2","text":"character vector dictionary terms","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/export_document_clustering.html","id":null,"dir":"Reference","previous_headings":"","what":"Export Document Clustering Analysis — export_document_clustering","title":"Export Document Clustering Analysis — export_document_clustering","text":"Export document clustering analysis results CSV","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/export_document_clustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export Document Clustering Analysis — export_document_clustering","text":"","code":"export_document_clustering(   coordinates,   clusters = NULL,   labels = NULL,   doc_ids = NULL,   file_path )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/export_document_clustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export Document Clustering Analysis — export_document_clustering","text":"coordinates Document coordinates clusters Cluster assignments (optional) labels Cluster labels (optional) doc_ids Document IDs file_path Path save CSV file","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_keyness.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","title":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","text":"Extracts distinctive keywords comparing document groups using log-likelihood ratio (G-squared).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_keyness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","text":"","code":"extract_keywords_keyness(dfm, target, top_n = 20, measure = \"lr\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_keyness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","text":"dfm quanteda dfm object target Target document indices logical vector top_n Number top keywords extract (default: 20) measure Keyness measure: \"lr\" (log-likelihood) \"chi2\" (default: \"lr\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_keyness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","text":"Data frame columns: Keyword, Keyness_Score","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_keyness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Keywords Using Statistical Keyness — extract_keywords_keyness","text":"","code":"if (FALSE) { # \\dontrun{ library(quanteda) corp <- corpus(c(\"positive text\", \"negative text\", \"positive words\")) dfm_obj <- dfm(tokens(corp)) # Compare first document vs rest keywords <- extract_keywords_keyness(dfm_obj, target = 1) print(keywords) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_tfidf.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","title":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","text":"Extracts top keywords document-feature matrix using TF-IDF weighting.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_tfidf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","text":"","code":"extract_keywords_tfidf(dfm, top_n = 20, normalize = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_tfidf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","text":"dfm quanteda dfm object top_n Number top keywords extract (default: 20) normalize Logical, whether normalize TF-IDF scores 0-1 range (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_tfidf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","text":"Data frame columns: Keyword, TF_IDF_Score, Frequency","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_keywords_tfidf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Keywords Using TF-IDF — extract_keywords_tfidf","text":"","code":"if (FALSE) { # \\dontrun{ library(quanteda) corp <- corpus(c(\"text analysis\", \"data mining\", \"text mining\")) dfm_obj <- dfm(tokens(corp)) keywords <- extract_keywords_tfidf(dfm_obj, top_n = 5) print(keywords) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"Extract text visual content PDFs, converting everything text downstream analysis existing workflow.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"","code":"extract_pdf_multimodal(   file_path,   vision_provider = \"ollama\",   vision_model = NULL,   api_key = NULL,   describe_images = TRUE,   envname = \"langgraph-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"file_path Character string path PDF file vision_provider Character: \"ollama\" (local, default) \"openai\" (cloud) vision_model Character: Model name Ollama: \"llava\", \"llava:13b\", \"bakllava\" OpenAI: \"gpt-4-vision-preview\", \"gpt-4o\" api_key Character: OpenAI API key (required vision_provider=\"openai\") describe_images Logical: Convert images text descriptions (default: TRUE) envname Character: Python environment name (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"List : success: Logical combined_text: Character string content text analysis text_content: List text chunks image_descriptions: List image descriptions num_images: Integer count processed images vision_provider: Character indicating provider used message: Character status message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"Workflow Integration: Extracts text using Marker (preserves equations, tables, structure) Detects images/charts/diagrams PDF Uses vision LLM describe visual content text Merges text + descriptions → single text corpus Feed existing text analysis pipeline Vision Provider Options: Ollama (Default - Local & Free): Privacy: Everything runs locally Cost: Free Setup: Requires Ollama installed + vision model pulled Models: llava, bakllava, llava-phi3 OpenAI (Optional - Cloud): Privacy: Data sent OpenAI Cost: Paid (user's API key) Setup: Just provide API key Models: gpt-4-vision-preview, gpt-4o","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_multimodal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract PDF with Multimodal Analysis — extract_pdf_multimodal","text":"","code":"if (FALSE) { # \\dontrun{ # Local analysis with Ollama (free, private) result <- extract_pdf_multimodal(\"research_paper.pdf\")  # Access combined text for analysis text_for_analysis <- result$combined_text  # Use in existing workflow corpus <- prep_texts(text_for_analysis) topics <- fit_semantic_model(corpus, k = 5)  # Optional: Use OpenAI for better accuracy result <- extract_pdf_multimodal(   \"paper.pdf\",   vision_provider = \"openai\",   vision_model = \"gpt-4o\",   api_key = Sys.getenv(\"OPENAI_API_KEY\") ) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_smart.html","id":null,"dir":"Reference","previous_headings":"","what":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","title":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","text":"Automatically detects document type chooses best extraction method: Academic papers → Nougat (equations) Documents visuals → Multimodal extraction General documents → Marker","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_smart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","text":"","code":"extract_pdf_smart(   file_path,   doc_type = \"auto\",   vision_provider = \"ollama\",   vision_model = NULL,   api_key = NULL,   envname = \"langgraph-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_smart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","text":"file_path Character string path PDF file doc_type Character: \"auto\" (default), \"academic\", \"general\" vision_provider Character: \"ollama\" (default) \"openai\" vision_model Character: Model name vision analysis api_key Character: API key cloud providers envname Character: Python environment name","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_smart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","text":"List extracted content ready text analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_pdf_smart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smart PDF Extraction with Auto-Detection — extract_pdf_smart","text":"","code":"if (FALSE) { # \\dontrun{ # Auto-detect and extract result <- extract_pdf_smart(\"document.pdf\")  # Feed to text analysis corpus <- prep_texts(result$combined_text) topics <- fit_semantic_model(corpus, k = 10)  # Force academic extraction (with equations) result <- extract_pdf_smart(\"paper.pdf\", doc_type = \"academic\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"Extracts tabular data PDF using pdfplumber (Python). Java required - pure Python solution.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"","code":"extract_tables_from_pdf_py(   file_path,   pages = NULL,   envname = \"textanalysisr-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"file_path Character string path PDF file pages Integer vector page numbers process (NULL = pages) envname Character string, name Python virtual environment (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"Data frame extracted table data Returns NULL tables found extraction fails","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"Uses pdfplumber Python library reticulate. Works complex table layouts without Java dependency.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_tables_from_pdf_py.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Tables from PDF using Python — extract_tables_from_pdf_py","text":"","code":"if (FALSE) { # \\dontrun{ setup_langgraph_env()  pdf_path <- \"path/to/table_document.pdf\" table_data <- extract_tables_from_pdf_py(pdf_path) head(table_data) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Text from PDF — extract_text_from_pdf","title":"Extract Text from PDF — extract_text_from_pdf","text":"Extracts text content PDF file using pdftools package.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Text from PDF — extract_text_from_pdf","text":"","code":"extract_text_from_pdf(file_path)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Text from PDF — extract_text_from_pdf","text":"file_path Character string path PDF file","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Text from PDF — extract_text_from_pdf","text":"Data frame columns: page (integer), text (character) Returns NULL extraction fails PDF empty","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Text from PDF — extract_text_from_pdf","text":"Uses pdftools::pdf_text() extract text page. Preserves page structure cleans whitespace. Works best text-based PDFs (scanned images).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Text from PDF — extract_text_from_pdf","text":"","code":"if (FALSE) { # \\dontrun{ pdf_path <- \"path/to/document.pdf\" text_data <- extract_text_from_pdf(pdf_path) head(text_data) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Text from PDF using Python — extract_text_from_pdf_py","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"Extracts text content PDF file using pdfplumber (Python). Java required - uses Python environment.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"","code":"extract_text_from_pdf_py(file_path, envname = \"textanalysisr-env\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"file_path Character string path PDF file envname Character string, name Python virtual environment (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"Data frame columns: page (integer), text (character) Returns NULL extraction fails PDF empty","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"Uses pdfplumber Python library reticulate. Requires Python environment setup. See setup_langgraph_env().","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/extract_text_from_pdf_py.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Text from PDF using Python — extract_text_from_pdf_py","text":"","code":"if (FALSE) { # \\dontrun{ setup_langgraph_env()  pdf_path <- \"path/to/document.pdf\" text_data <- extract_text_from_pdf_py(pdf_path) head(text_data) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_optimal_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Optimal Number of Topics — find_optimal_k","title":"Find Optimal Number of Topics — find_optimal_k","text":"Searches optimal number topics (K) using stm::searchK. Produces diagnostic plots help select best K value.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_optimal_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Optimal Number of Topics — find_optimal_k","text":"","code":"find_optimal_k(   dfm_object,   topic_range,   max.em.its = 75,   categorical_var = NULL,   continuous_var = NULL,   height = 600,   width = 800,   verbose = TRUE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_optimal_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Optimal Number of Topics — find_optimal_k","text":"dfm_object quanteda dfm object used topic modeling. topic_range vector K values test (e.g., 2:10). max.em.Maximum number EM iterations (default: 75). categorical_var Optional categorical variable(s) prevalence. continuous_var Optional continuous variable(s) prevalence. height Plot height pixels (default: 600). width Plot width pixels (default: 800). verbose Logical indicating whether print progress (default: TRUE). ... Additional arguments passed stm::searchK.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_optimal_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Optimal Number of Topics — find_optimal_k","text":"list containing search results diagnostic plots.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_topic_matches.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Similar Topics — find_topic_matches","title":"Find Similar Topics — find_topic_matches","text":"function finds similar topics given query using semantic similarity analysis. works semantic topic models traditional STM models creating topic representations using transformer embeddings calculating cosine similarity scores.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_topic_matches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Similar Topics — find_topic_matches","text":"","code":"find_topic_matches(   topic_model,   query,   top_n = 10,   method = \"cosine\",   embedding_model = \"all-MiniLM-L6-v2\",   include_terms = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_topic_matches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Similar Topics — find_topic_matches","text":"topic_model topic model object (semantic topic model STM model). query character string representing query topic. top_n number similar topics return (default: 10). method similarity method: \"cosine\", \"euclidean\", \"embedding\". embedding_model embedding model use query encoding (default: \"-MiniLM-L6-v2\"). include_terms Logical, whether include topic terms similarity calculation (default: TRUE).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_topic_matches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Similar Topics — find_topic_matches","text":"list containing similar topics similarity scores.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/find_topic_matches.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find Similar Topics — find_topic_matches","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )   texts <- united_tbl$united_texts    topic_model <- TextAnalysisR::fit_embedding_topics(     texts = texts,     method = \"semantic_style\",     n_topics = 8   )    similar_topics <- TextAnalysisR::find_similar_topics(     topic_model = topic_model,     query = \"mathematical learning\",     top_n = 5   )    print(similar_topics) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_embedding_topics.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding-based Topic Modeling — fit_embedding_topics","title":"Embedding-based Topic Modeling — fit_embedding_topics","text":"function performs embedding-based topic modeling using transformer embeddings specialized clustering techniques. primary method uses BERTopic library, combines transformer embeddings UMAP dimensionality reduction HDBSCAN clustering optimal topic discovery. approach creates semantically coherent topics compared traditional methods leveraging deep learning embeddings.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_embedding_topics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding-based Topic Modeling — fit_embedding_topics","text":"","code":"fit_embedding_topics(   texts,   method = \"umap_hdbscan\",   n_topics = 10,   embedding_model = \"all-MiniLM-L6-v2\",   clustering_method = \"kmeans\",   similarity_threshold = 0.7,   min_topic_size = 3,   umap_neighbors = 15,   umap_min_dist = 0,   umap_n_components = 5,   representation_method = \"c-tfidf\",   diversity = 0.5,   reduce_outliers = TRUE,   seed = 123,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_embedding_topics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding-based Topic Modeling — fit_embedding_topics","text":"texts character vector texts analyze. method topic modeling method: \"umap_hdbscan\" (uses BERTopic), \"embedding_clustering\", \"hierarchical_semantic\". n_topics number topics identify. UMAP+HDBSCAN, use NULL \"auto\" automatic determination, specify integer. embedding_model embedding model use (default: \"-MiniLM-L6-v2\"). clustering_method clustering method embedding-based approach: \"kmeans\", \"hierarchical\", \"dbscan\", \"hdbscan\". similarity_threshold similarity threshold topic assignment (default: 0.7). min_topic_size minimum number documents per topic (default: 3). umap_neighbors number neighbors UMAP dimensionality reduction (default: 15). umap_min_dist minimum distance UMAP (default: 0.0). Use 0.0 tight, well-separated clusters. Use 0.1+ visualization purposes. Range: 0.0-0.99. umap_n_components number UMAP components (default: 5). representation_method method topic representation: \"c-tfidf\", \"tfidf\", \"mmr\", \"frequency\" (default: \"c-tfidf\"). diversity Topic diversity parameter 0 1 (default: 0.5). reduce_outliers Logical, TRUE, reduces outliers HDBSCAN clustering (default: TRUE). seed Random seed reproducibility (default: 123). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_embedding_topics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embedding-based Topic Modeling — fit_embedding_topics","text":"list containing topic assignments, topic keywords, quality metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_embedding_topics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding-based Topic Modeling — fit_embedding_topics","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )   texts <- united_tbl$united_texts    # Embedding-based topic modeling (powered by BERTopic)   result <- TextAnalysisR::fit_embedding_topics(     texts = texts,     method = \"umap_hdbscan\",     n_topics = 8,     min_topic_size = 3   )    print(result$topic_assignments)   print(result$topic_keywords) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Hybrid Topic Model — fit_hybrid_model","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"Fits hybrid topic model combining STM embedding-based methods. function integrates structural topic modeling (STM) semantic embeddings enhanced topic discovery. STM component provides statistical rigor covariate modeling capabilities, embedding component adds semantic coherence. Effect Estimation: Covariate effects topic prevalence can estimated using STM component via stm::estimateEffect(). embedding component provides semantically meaningful topic representations support direct covariate modeling. hybrid approach combines best worlds: statistical inference STM semantic quality embeddings.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"","code":"fit_hybrid_model(   texts,   metadata = NULL,   n_topics_stm = 10,   embedding_model = \"all-MiniLM-L6-v2\",   stm_prevalence = NULL,   stm_init_type = \"Spectral\",   alignment_method = \"cosine\",   verbose = TRUE,   seed = 123 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"texts character vector texts analyze. metadata Optional data frame document metadata STM covariate modeling. n_topics_stm Number topics STM (default: 10). embedding_model Embedding model name (default: \"-MiniLM-L6-v2\"). stm_prevalence Formula STM prevalence covariates (e.g., ~ category + s(year, df=3)). stm_init_type STM initialization type (default: \"Spectral\"). alignment_method Method aligning STM embedding topics (default: \"cosine\"). verbose Logical, TRUE, prints progress messages. seed Random seed reproducibility.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"list containing: stm_result: STM model output (use effect estimation) embedding_result: embedding-based topic model output alignment: Alignment metrics two models combined_topics: Integrated topic representations metadata: Metadata used modeling (needed effect estimation)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"covariate effect estimation, use stm::estimateEffect() stm_result$model component. metadata must include covariates specified stm_prevalence.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_hybrid_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Hybrid Topic Model — fit_hybrid_model","text":"","code":"if (FALSE) { # \\dontrun{   texts <- c(\"Computer-assisted instruction improves math skills for students with disabilities\",              \"Assistive technology supports reading comprehension for learning disabled students\",              \"Mobile devices enhance communication for students with autism spectrum disorder\")    hybrid_model <- fit_hybrid_model(     texts = texts,     n_topics_stm = 3,     verbose = TRUE   ) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_semantic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Semantic Model — fit_semantic_model","title":"Fit Semantic Model — fit_semantic_model","text":"Performs comprehensive semantic analysis including similarity, dimensionality reduction, clustering. high-level wrapper function.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_semantic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Semantic Model — fit_semantic_model","text":"","code":"fit_semantic_model(   texts,   analysis_types = c(\"similarity\", \"dimensionality_reduction\", \"clustering\"),   document_feature_type = \"embeddings\",   similarity_method = \"cosine\",   use_embeddings = TRUE,   embedding_model = \"all-MiniLM-L6-v2\",   dimred_method = \"UMAP\",   clustering_method = \"umap_dbscan\",   n_components = 2,   n_clusters = 5,   seed = 123,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_semantic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Semantic Model — fit_semantic_model","text":"texts character vector texts analyze. analysis_types Types analysis perform: \"similarity\", \"dimensionality_reduction\", \"clustering\". document_feature_type Feature extraction type (default: \"embeddings\"). similarity_method Similarity calculation method (default: \"cosine\"). use_embeddings Logical, use embedding-based approaches (default: TRUE). embedding_model Sentence transformer model name (default: \"-MiniLM-L6-v2\"). dimred_method Dimensionality reduction method: \"PCA\", \"t-SNE\", \"UMAP\" (default: \"UMAP\"). clustering_method Clustering method: \"kmeans\", \"hierarchical\", \"umap_dbscan\" (default: \"umap_dbscan\"). n_components Number dimensions reduction (default: 2). n_clusters Number clusters (default: 5). seed Random seed reproducibility (default: 123). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_semantic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Semantic Model — fit_semantic_model","text":"list containing results requested analyses.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_semantic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Semantic Model — fit_semantic_model","text":"","code":"if (interactive()) {   texts <- c(     \"Assistive technology supports learning.\",     \"Technology aids students with disabilities.\",     \"Machine learning improves predictions.\"   )    results <- fit_semantic_model(     texts = texts,     analysis_types = c(\"similarity\", \"clustering\")   )    print(results) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_temporal_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Temporal Topic Model — fit_temporal_model","title":"Fit Temporal Topic Model — fit_temporal_model","text":"Analyzes topics evolve time fitting topic models different time periods tracking semantic changes.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_temporal_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Temporal Topic Model — fit_temporal_model","text":"","code":"fit_temporal_model(   texts,   dates,   time_windows = \"yearly\",   embeddings = NULL,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_temporal_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Temporal Topic Model — fit_temporal_model","text":"texts character vector text documents analyze. dates vector dates corresponding document (converted Date). time_windows Time grouping strategy: \"yearly\", \"monthly\", \"quarterly\" (default: \"yearly\"). embeddings Optional pre-computed embeddings matrix. NULL, embeddings generated. verbose Logical indicating whether print progress messages (default: TRUE).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/fit_temporal_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Temporal Topic Model — fit_temporal_model","text":"list containing temporal analysis results topic evolution patterns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/format_label_candidates.html","id":null,"dir":"Reference","previous_headings":"","what":"Format Label Candidates for Display — format_label_candidates","title":"Format Label Candidates for Display — format_label_candidates","text":"Helper function format LangGraph label candidates display Shiny UI.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/format_label_candidates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format Label Candidates for Display — format_label_candidates","text":"","code":"format_label_candidates(label_candidates)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/format_label_candidates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format Label Candidates for Display — format_label_candidates","text":"label_candidates List label candidate objects generate_topic_labels_langgraph()","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/format_label_candidates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format Label Candidates for Display — format_label_candidates","text":"Data frame columns: topic_index: Integer, topic number top_terms: Character, comma-separated top terms label: Character, suggested label reasoning: Character, LLM explanation candidate_number: Integer, candidate rank (1-3)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/format_label_candidates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format Label Candidates for Display — format_label_candidates","text":"","code":"if (FALSE) { # \\dontrun{ result <- generate_topic_labels_langgraph(...) df <- format_label_candidates(result$label_candidates) print(df) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_aria_label.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate ARIA Label — generate_aria_label","title":"Generate ARIA Label — generate_aria_label","text":"Creates accessible ARIA label UI elements.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_aria_label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate ARIA Label — generate_aria_label","text":"","code":"generate_aria_label(element_type, action, context = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_aria_label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate ARIA Label — generate_aria_label","text":"element_type Type element (e.g., \"button\", \"input\", \"plot\") action Action purpose (e.g., \"analyze\", \"download\", \"visualize\") context Additional context (optional)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_aria_label.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate ARIA Label — generate_aria_label","text":"Character string ARIA label","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_aria_label.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate ARIA Label — generate_aria_label","text":"","code":"if (FALSE) { # \\dontrun{ generate_aria_label(\"button\", \"analyze\", \"readability\") # Returns: \"Analyze readability button\" } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Cluster Labels with AI — generate_cluster_labels","title":"Generate Cluster Labels with AI — generate_cluster_labels","text":"Generates descriptive labels clusters using either Ollama (local, default) OpenAI's API. running locally, Ollama preferred privacy cost-free operation.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Cluster Labels with AI — generate_cluster_labels","text":"","code":"generate_cluster_labels(   cluster_keywords,   provider = \"auto\",   model = NULL,   temperature = 0.3,   max_tokens = 50,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Cluster Labels with AI — generate_cluster_labels","text":"cluster_keywords List keywords cluster. provider AI provider use: \"auto\" (default), \"ollama\", \"openai\". \"auto\" use Ollama available, otherwise OpenAI. model Model name. Ollama (default: \"phi3:mini\"). OpenAI (default: \"gpt-3.5-turbo\"). temperature Temperature parameter (default: 0.3). max_tokens Maximum tokens response (default: 50). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Cluster Labels with AI — generate_cluster_labels","text":"list generated labels.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Cluster Labels with AI — generate_cluster_labels","text":"","code":"if (FALSE) { # \\dontrun{ keywords <- list(\"1\" = c(\"machine\", \"learning\", \"neural\"), \"2\" = c(\"data\", \"analysis\")) labels_ollama <- generate_cluster_labels(keywords, provider = \"ollama\") labels_openai <- generate_cluster_labels(keywords, provider = \"openai\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels_auto.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Cluster Labels — generate_cluster_labels_auto","title":"Generate Cluster Labels — generate_cluster_labels_auto","text":"Generate descriptive labels document clusters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels_auto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Cluster Labels — generate_cluster_labels_auto","text":"","code":"generate_cluster_labels_auto(   feature_matrix,   clusters,   method = \"tfidf\",   n_terms = 3 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels_auto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Cluster Labels — generate_cluster_labels_auto","text":"feature_matrix Feature matrix used clustering clusters Cluster assignments method Label generation method (\"tfidf\", \"representative\", \"frequent\") n_terms Number terms per label","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_cluster_labels_auto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Cluster Labels — generate_cluster_labels_auto","text":"Named list cluster labels","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Embeddings — generate_embeddings","title":"Generate Embeddings — generate_embeddings","text":"Generates embeddings texts using sentence transformers.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Embeddings — generate_embeddings","text":"","code":"generate_embeddings(texts, model = \"all-MiniLM-L6-v2\", verbose = TRUE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Embeddings — generate_embeddings","text":"texts character vector texts. model Sentence transformer model name (default: \"-MiniLM-L6-v2\"). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Embeddings — generate_embeddings","text":"matrix embeddings.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_semantic_topic_keywords.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Semantic Topic Keywords (c-TF-IDF) — generate_semantic_topic_keywords","title":"Generate Semantic Topic Keywords (c-TF-IDF) — generate_semantic_topic_keywords","text":"Generate keywords topics using c-TF-IDF (class-based TF-IDF), similar BERTopic. method treats documents topic single document calculates TF-IDF scores relative topics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_semantic_topic_keywords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Semantic Topic Keywords (c-TF-IDF) — generate_semantic_topic_keywords","text":"","code":"generate_semantic_topic_keywords(   texts,   topic_assignments,   n_keywords = 10,   method = \"c-tfidf\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_semantic_topic_keywords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Semantic Topic Keywords (c-TF-IDF) — generate_semantic_topic_keywords","text":"texts character vector texts. topic_assignments vector topic assignments. n_keywords number keywords extract per topic (default: 10). method representation method: \"c-tfidf\" (default), \"tfidf\", \"mmr\", \"frequency\".","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_semantic_topic_keywords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Semantic Topic Keywords (c-TF-IDF) — generate_semantic_topic_keywords","text":"list keywords topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_keywords.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Topic Keywords — generate_topic_keywords","title":"Generate Topic Keywords — generate_topic_keywords","text":"Internal function generate keywords topics using TF-IDF analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_keywords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Topic Keywords — generate_topic_keywords","text":"","code":"generate_topic_keywords(texts, topic_assignments, n_keywords = 10)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_keywords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Topic Keywords — generate_topic_keywords","text":"texts character vector texts. topic_assignments vector topic assignments. n_keywords number keywords extract per topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_keywords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Topic Keywords — generate_topic_keywords","text":"list keywords topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","title":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","text":"function generates descriptive labels topic based top terms using OpenAI's ChatCompletion API.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","text":"","code":"generate_topic_labels(   top_topic_terms,   model = \"gpt-3.5-turbo\",   system = NULL,   user = NULL,   temperature = 0.5,   openai_api_key = NULL,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","text":"top_topic_terms data frame containing top terms topic. model character string specifying OpenAI model use (default: \"gpt-3.5-turbo\"). system character string containing system prompt OpenAI API. NULL, function uses default system prompt. user character string containing user prompt OpenAI API. NULL, function uses default user prompt. temperature numeric value controlling randomness output (default: 0.5). openai_api_key character string containing OpenAI API key. NULL, function attempts load key OPENAI_API_KEY environment variable .env file working directory. verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","text":"data frame containing top terms topic along generated labels.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Topic Labels Using OpenAI's API — generate_topic_labels","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    out <- quanteda::convert(dfm_object, to = \"stm\")  stm_15 <- stm::stm(   data = out$meta,   documents = out$documents,   vocab = out$vocab,   max.em.its = 75,   init.type = \"Spectral\",   K = 15,   prevalence = ~ reference_type + s(year),   verbose = TRUE)  top_topic_terms <- TextAnalysisR::get_topic_terms(   stm_model = stm_15,   top_term_n = 10,   verbose = TRUE   )  top_labeled_topic_terms <- TextAnalysisR::generate_topic_labels(   top_topic_terms,   model = \"gpt-3.5-turbo\",   temperature = 0.5,   openai_api_key = \"your_openai_api_key\",   verbose = TRUE) print(top_labeled_topic_terms)  top_labeled_topic_terms <- TextAnalysisR::generate_topic_labels(   top_topic_terms,   model = \"gpt-3.5-turbo\",   temperature = 0.5,   verbose = TRUE) print(top_labeled_topic_terms) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"Uses LangGraph workflow generate multiple label candidates topics using local LLM (Ollama). Provides human---loop review suggestions.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"","code":"generate_topic_labels_langgraph(   topic_terms,   num_topics,   ollama_model = \"llama3\",   ollama_base_url = \"http://localhost:11434\",   envname = \"textanalysisr-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"topic_terms List character vectors, vector contains top terms topic (STM topic model) num_topics Integer, number topics ollama_model Character string, name Ollama model use (default: \"llama3\") ollama_base_url Character string, base URL Ollama API (default: \"http://localhost:11434\") envname Character string, name Python virtual environment (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"List : success: Logical, TRUE workflow completed successfully label_candidates: List label candidate objects topic validation_metrics: Validation metrics (available) error: Error message (failed)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"function: Initializes LangGraph Python environment Calls Python workflow generate label candidates Returns structured results display Shiny UI Allows human review selection labels workflow uses StateGraph nodes : Label generation (LLM) Validation (LLM) Conditional revision based quality metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/generate_topic_labels_langgraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Topic Labels with LLM Assistance — generate_topic_labels_langgraph","text":"","code":"if (FALSE) { # \\dontrun{ topic_terms <- list(   c(\"education\", \"student\", \"learning\", \"teacher\", \"school\"),   c(\"health\", \"medical\", \"patient\", \"doctor\", \"treatment\"),   c(\"environment\", \"climate\", \"carbon\", \"emissions\", \"energy\") )  result <- generate_topic_labels_langgraph(   topic_terms = topic_terms,   num_topics = 3,   ollama_model = \"llama3\" )  if (result$success) {   print(result$label_candidates) } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"Returns first non-NULL DFM priority fallback chain. Useful multiple DFM processing stages exist need processed available version.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"","code":"get_available_dfm(   dfm_lemma = NULL,   dfm_outcome = NULL,   dfm_final = NULL,   dfm_init = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"dfm_lemma Optional lemmatized DFM (highest priority) dfm_outcome Optional preprocessed DFM (medium priority) dfm_final Optional final processed DFM (medium-low priority) dfm_init Optional initial DFM (lowest priority)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"first non-NULL DFM priority chain, NULL NULL","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"Priority order (highest lowest): dfm_lemma - Lemmatized tokens (processed) dfm_outcome - Preprocessed tokens dfm_final - Final processed version dfm_init - Initial unprocessed tokens","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_available_dfm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Available Document-Feature Matrix with Fallback — get_available_dfm","text":"","code":"if (FALSE) { # \\dontrun{ dfm1 <- quanteda::dfm(quanteda::tokens(\"assistive technology supports learning\")) result <- get_available_dfm(dfm_init = dfm1) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_dfm_setup_instructions.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","title":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","text":"Generates standardized text instructions creating DFM. Used console output verbatim text displays.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_dfm_setup_instructions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","text":"","code":"get_dfm_setup_instructions(feature_name = \"this feature\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_dfm_setup_instructions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","text":"feature_name Name feature requiring DFM (default: \"feature\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_dfm_setup_instructions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","text":"Character vector instruction lines","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_dfm_setup_instructions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate DFM Setup Instructions Text — get_dfm_setup_instructions","text":"","code":"if (FALSE) { # \\dontrun{ output$instructions <- renderPrint({   cat(get_dfm_setup_instructions(\"keyword extraction\"), sep = \"\\n\") }) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_feature_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Feature Status — get_feature_status","title":"Get Feature Status — get_feature_status","text":"Returns availability status optional features.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_feature_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Feature Status — get_feature_status","text":"","code":"get_feature_status()"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_feature_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Feature Status — get_feature_status","text":"Named list feature availability","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_feature_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Feature Status — get_feature_status","text":"","code":"status <- get_feature_status() print(status) #> $python #> [1] FALSE #>  #> $ollama #> [1] FALSE #>  #> $langgraph #> [1] FALSE #>  #> $pdf_tables #> [1] FALSE #>  #> $embeddings #> [1] TRUE #>  #> $sentiment_deep #> [1] TRUE #>  #> $web #> [1] FALSE #>  #> $local #> [1] TRUE #>"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_plotly_hover_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","title":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","text":"Returns standardized hover label styling plotly plots.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_plotly_hover_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","text":"","code":"get_plotly_hover_config(bgcolor = \"#ffffff\", fontcolor = \"#0c1f4a\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_plotly_hover_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","text":"bgcolor Background color (default: \"#ffffff\") fontcolor Font color (default: \"#0c1f4a\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_plotly_hover_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","text":"list hover label configuration parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_plotly_hover_config.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Standard Plotly Hover Label Configuration — get_plotly_hover_config","text":"","code":"if (FALSE) { # \\dontrun{ hover_config <- get_plotly_hover_config() plot_ly(..., hoverlabel = hover_config) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_recommended_ollama_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Recommended Ollama Model — get_recommended_ollama_model","title":"Get Recommended Ollama Model — get_recommended_ollama_model","text":"Returns recommended Ollama model based available.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_recommended_ollama_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Recommended Ollama Model — get_recommended_ollama_model","text":"","code":"get_recommended_ollama_model(   preferred_models = c(\"phi3:mini\", \"llama3.1:8b\", \"mistral:7b\", \"tinyllama\"),   verbose = FALSE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_recommended_ollama_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Recommended Ollama Model — get_recommended_ollama_model","text":"preferred_models Character vector preferred models priority order. verbose Logical, TRUE, prints status messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_recommended_ollama_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Recommended Ollama Model — get_recommended_ollama_model","text":"Character string recommended model, NULL none available.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_recommended_ollama_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Recommended Ollama Model — get_recommended_ollama_model","text":"","code":"if (FALSE) { # \\dontrun{ model <- get_recommended_ollama_model() print(model) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_color.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Sentiment Color Gradient — get_sentiment_color","title":"Generate Sentiment Color Gradient — get_sentiment_color","text":"Generates color based sentiment score using gradient red (negative) gray (neutral) green (positive).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_color.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Sentiment Color Gradient — get_sentiment_color","text":"","code":"get_sentiment_color(score)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_color.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Sentiment Color Gradient — get_sentiment_color","text":"score Numeric sentiment score (typically -1 1)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_color.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Sentiment Color Gradient — get_sentiment_color","text":"Hex color string","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_color.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Sentiment Color Gradient — get_sentiment_color","text":"","code":"get_sentiment_color(-0.8)  # Red #> [1] \"#A35A44\" get_sentiment_color(0)     # Gray #> [1] \"#4BB543\" get_sentiment_color(0.8)   # Green #> [1] \"#1CB875\""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Sentiment Color Palette — get_sentiment_colors","title":"Get Sentiment Color Palette — get_sentiment_colors","text":"Returns standardized color mapping sentiment analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Sentiment Color Palette — get_sentiment_colors","text":"","code":"get_sentiment_colors()"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_sentiment_colors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Sentiment Color Palette — get_sentiment_colors","text":"Named vector colors","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_topic_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Top Terms for Each Topic — get_topic_terms","title":"Select Top Terms for Each Topic — get_topic_terms","text":"function selects top terms topic based word probability distribution (beta).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_topic_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Top Terms for Each Topic — get_topic_terms","text":"","code":"get_topic_terms(stm_model, top_term_n = 10, verbose = TRUE, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_topic_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Top Terms for Each Topic — get_topic_terms","text":"stm_model STM model object. top_term_n number top terms display topic (default: 10). verbose Logical, TRUE, prints progress messages. ... arguments passed tidytext::tidy.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_topic_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Top Terms for Each Topic — get_topic_terms","text":"data frame containing top terms topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/get_topic_terms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Top Terms for Each Topic — get_topic_terms","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    stm_15 <- TextAnalysisR::create_stm_model(   dfm_object,   topic_n = 15,   max.em.its = 75,   categorical_var = \"reference_type\",   continuous_var = \"year\",   verbose = TRUE   )    out <- quanteda::convert(dfm_object, to = \"stm\")  stm_15 <- stm::stm(   data = out$meta,   documents = out$documents,   vocab = out$vocab,   max.em.its = 75,   init.type = \"Spectral\",   K = 15,   prevalence = ~ reference_type + s(year),   verbose = TRUE)  top_topic_terms <- TextAnalysisR::get_topic_terms(   stm_model = stm_15,   top_term_n = 10,   verbose = TRUE   ) print(top_topic_terms) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/identify_topic_trends.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Topic Trends — identify_topic_trends","title":"Identify Topic Trends — identify_topic_trends","text":"Identifies trending topics temporal results","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/identify_topic_trends.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Topic Trends — identify_topic_trends","text":"","code":"identify_topic_trends(temporal_results, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/identify_topic_trends.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Topic Trends — identify_topic_trends","text":"temporal_results Temporal analysis results ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/identify_topic_trends.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Topic Trends — identify_topic_trends","text":"List containing identified trends","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/import_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Files — import_files","title":"Process Files — import_files","text":"function processes different types files text input based dataset choice.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/import_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Files — import_files","text":"","code":"import_files(dataset_choice, file_info = NULL, text_input = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/import_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Files — import_files","text":"dataset_choice character string indicating dataset choice. file_info data frame containing file information column named 'filepath' (default: NULL). text_input character string containing text input (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/import_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Files — import_files","text":"data frame containing processed data.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/import_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Files — import_files","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech   mydata <- TextAnalysisR::import_files(dataset_choice = \"Upload an Example Dataset\")   head(mydata)    file_info <- data.frame(filepath = \"inst/extdata/SpecialEduTech.xlsx\")   mydata <- TextAnalysisR::import_files(dataset_choice = \"Upload Your File\",                                           file_info = file_info)   head(mydata)     text_input <- paste(\"Virtual manipulatives for algebra instruction\",                       \"manipulatives mathematics learning disability\",                       \"This study examined virtual manipulatives effects on\",                       \"students with learning disabilities\")   mydata <- TextAnalysisR::import_files(dataset_choice = \"Copy and Paste Text\",                                           text_input = text_input)   head(mydata) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/init_langgraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize LangGraph for Current Session — init_langgraph","title":"Initialize LangGraph for Current Session — init_langgraph","text":"Initializes LangGraph/LangChain/Ollama modules current R session. Use LangGraph workflows. PDF/embeddings load automatically.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/init_langgraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize LangGraph for Current Session — init_langgraph","text":"","code":"init_langgraph(envname = \"textanalysisr-env\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/init_langgraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize LangGraph for Current Session — init_langgraph","text":"envname Character string name virtual environment (default: \"textanalysisr-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/init_langgraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize LangGraph for Current Session — init_langgraph","text":"Invisible list LangGraph/LangChain/Ollama modules","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/init_langgraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize LangGraph for Current Session — init_langgraph","text":"","code":"if (FALSE) { # \\dontrun{ lg <- init_langgraph() } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_diversity_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexical Diversity Analysis — lexical_diversity_analysis","title":"Lexical Diversity Analysis — lexical_diversity_analysis","text":"Calculates lexical diversity metrics measure vocabulary richness. MTLD MATTR stable text-length independent.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_diversity_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexical Diversity Analysis — lexical_diversity_analysis","text":"","code":"lexical_diversity_analysis(dfm_object, measures = \"all\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_diversity_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexical Diversity Analysis — lexical_diversity_analysis","text":"dfm_object document-feature matrix quanteda measures Character vector measures calculate. Options: \"\", \"MTLD\" (recommended), \"MATTR\" (recommended), \"MSTTR\", \"TTR\", \"CTTR\", \"Maas\", \"K\", \"D\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_diversity_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lexical Diversity Analysis — lexical_diversity_analysis","text":"list lexical_diversity (data frame) summary_stats","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_diversity_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lexical Diversity Analysis — lexical_diversity_analysis","text":"","code":"if (FALSE) { # \\dontrun{ data(SpecialEduTech) texts <- SpecialEduTech$abstract[1:10] corp <- quanteda::corpus(texts) toks <- quanteda::tokens(corp) dfm_obj <- quanteda::dfm(toks) lex_div <- lexical_diversity_analysis(dfm_obj) print(lex_div) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_frequency_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexical Frequency Analysis — lexical_frequency_analysis","title":"Lexical Frequency Analysis — lexical_frequency_analysis","text":"Wrapper function plot_word_frequency lexical analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_frequency_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexical Frequency Analysis — lexical_frequency_analysis","text":"","code":"lexical_frequency_analysis(...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/lexical_frequency_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexical Frequency Analysis — lexical_frequency_analysis","text":"... Arguments passed plot_word_frequency","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/list_ollama_models.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available Ollama Models — list_ollama_models","title":"List Available Ollama Models — list_ollama_models","text":"Lists models currently installed Ollama.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/list_ollama_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available Ollama Models — list_ollama_models","text":"","code":"list_ollama_models(verbose = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/list_ollama_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Available Ollama Models — list_ollama_models","text":"verbose Logical, TRUE, prints status messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/list_ollama_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Available Ollama Models — list_ollama_models","text":"Character vector model names, NULL Ollama unavailable.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/list_ollama_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available Ollama Models — list_ollama_models","text":"","code":"if (FALSE) { # \\dontrun{ models <- list_ollama_models() print(models) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/log_security_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Security Event — log_security_event","title":"Log Security Event — log_security_event","text":"Log Security Event","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/log_security_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Security Event — log_security_event","text":"","code":"log_security_event(event_type, details, session_info, level = \"INFO\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/log_security_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Security Event — log_security_event","text":"event_type Type security event details Additional details event session_info Shiny session object level Log level (INFO, WARNING, ERROR)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_cooccurrence_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","title":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","text":"function creates word co-occurrence network based document-feature matrix (dfm).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_cooccurrence_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","text":"","code":"plot_cooccurrence_network(   dfm_object,   doc_var = NULL,   co_occur_n = 50,   top_node_n = 30,   nrows = 1,   height = 800,   width = 900,   category = NULL,   use_category_specific = FALSE,   category_params = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_cooccurrence_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","text":"dfm_object quanteda document-feature matrix (dfm). doc_var document-level metadata variable (default: NULL). co_occur_n Minimum number co-occurrences filtering terms (default: 50). top_node_n Number top nodes display (default: 30). nrows Number rows display table (default: 1). height height resulting Plotly plot, pixels (default: 800). width width resulting Plotly plot, pixels (default: 900). category optional category filter data (default: NULL). use_category_specific Logical; TRUE, uses category-specific parameters (default: FALSE). category_params named list parameters category level (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_cooccurrence_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","text":"list containing Plotly plot, data frame network layout, igraph graph object.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_cooccurrence_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Word Co-occurrence Networks — plot_cooccurrence_network","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    # Overall   word_co_occurrence_network_results <- TextAnalysisR::plot_cooccurrence_network(                                         dfm_object,                                         doc_var = \"reference_type\",                                         co_occur_n = 30,                                         top_node_n = 0,                                         nrows = 1,                                         height = 800,                                         width = 900)    print(word_co_occurrence_network_results$plot)   print(word_co_occurrence_network_results$table)   print(word_co_occurrence_network_results$summary)    # Journal article  category_params <- list(   \"journal_article\" = list(co_occur_n = 80, top_node_n = 20),   \"thesis\" = list(co_occur_n = 30, top_node_n = 20) )   word_co_occurrence_category <- TextAnalysisR::plot_cooccurrence_network(   dfm_object,   doc_var = \"reference_type\",   use_category_specific = TRUE,   category_params = category_params)   print(word_co_occurrence_category$journal_article$plot)  print(word_co_occurrence_category$journal_article$table)  print(word_co_occurrence_category$journal_article$summary)   # Thesis  print(word_co_occurrence_category$thesis$plot)  print(word_co_occurrence_category$thesis$table)  print(word_co_occurrence_category$thesis$summary)  }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_correlation_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","title":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","text":"function creates word correlation network based document-feature matrix (dfm).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_correlation_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","text":"","code":"plot_correlation_network(   dfm_object,   doc_var = NULL,   common_term_n = 130,   corr_n = 0.4,   top_node_n = 40,   nrows = 1,   height = 1000,   width = 900,   use_category_specific = FALSE,   category_params = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_correlation_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","text":"dfm_object quanteda document-feature matrix (dfm). doc_var document-level metadata variable (default: NULL). common_term_n Minimum number common terms filtering terms (default: 30). corr_n Minimum correlation value filtering terms (default: 0.4). top_node_n Number top nodes display (default: 40). nrows Number rows display table (default: 1). height height resulting Plotly plot, pixels (default: 1000). width width resulting Plotly plot, pixels (default: 900). use_category_specific Logical; TRUE, uses category-specific parameters (default: FALSE). category_params named list parameters category level (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_correlation_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","text":"list containing Plotly plot, data frame network layout, igraph graph object.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_correlation_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze and Visualize Word Correlation Networks — plot_correlation_network","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    # Overall   word_correlation_network_results <- TextAnalysisR::plot_correlation_network(                                         dfm_object,                                         doc_var = \"reference_type\",                                         common_term_n = 30,                                         corr_n = 0.4,                                         top_node_n = 0,                                         nrows = 1,                                         height = 800,                                         width = 900)    print(word_correlation_network_results$plot)   print(word_correlation_network_results$table)   print(word_correlation_network_results$summary)    # Journal article  category_params <- list(    \"journal_article\" = list(common_term_n = 30, corr_n = 0.4, top_node_n = 20),    \"thesis\" = list(common_term_n = 20, corr_n = 0.4, top_node_n = 20) )   word_correlation_category <- TextAnalysisR::plot_correlation_network(    dfm_object,    doc_var = \"reference_type\",    use_category_specific = TRUE,    category_params = category_params)   print(word_correlation_category$journal_article$plot)  print(word_correlation_category$journal_article$table)  print(word_correlation_category$journal_article$summary)   # Thesis  print(word_correlation_category$thesis$plot)  print(word_correlation_category$thesis$table)  print(word_correlation_category$thesis$summary)  }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_document_sentiment_trajectory.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Document Sentiment Trajectory — plot_document_sentiment_trajectory","title":"Plot Document Sentiment Trajectory — plot_document_sentiment_trajectory","text":"Creates line chart showing sentiment scores across documents color gradient.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_document_sentiment_trajectory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Document Sentiment Trajectory — plot_document_sentiment_trajectory","text":"","code":"plot_document_sentiment_trajectory(   sentiment_data,   top_n = NULL,   doc_ids = NULL,   text_preview = NULL,   title = \"Document Sentiment Scores\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_document_sentiment_trajectory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Document Sentiment Trajectory — plot_document_sentiment_trajectory","text":"sentiment_data Data frame analyze_sentiment() sentiment_score column top_n Number documents display (default: NULL ) doc_ids Optional vector custom document IDs display (default: NULL) text_preview Optional vector text snippets tooltips (default: NULL) title Plot title (default: \"Document Sentiment Scores\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_document_sentiment_trajectory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Document Sentiment Trajectory — plot_document_sentiment_trajectory","text":"plotly line chart color gradient","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_emotion_radar.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Emotion Radar Chart — plot_emotion_radar","title":"Plot Emotion Radar Chart — plot_emotion_radar","text":"Creates polar/radar chart NRC emotion analysis optional grouping.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_emotion_radar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Emotion Radar Chart — plot_emotion_radar","text":"","code":"plot_emotion_radar(   emotion_data,   group_var = NULL,   normalize = FALSE,   title = \"Emotion Analysis\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_emotion_radar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Emotion Radar Chart — plot_emotion_radar","text":"emotion_data Data frame emotion scores (columns: emotion, total_score) group_var Optional grouping variable column name overlaid radars (default: NULL) normalize Logical, whether normalize scores 0-100 scale (default: FALSE) title Plot title (default: \"Emotion Analysis\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_emotion_radar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Emotion Radar Chart — plot_emotion_radar","text":"plotly polar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Error Plot for Plotly — plot_error","title":"Create Error Plot for Plotly — plot_error","text":"Creates plotly error/status plot message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Error Plot for Plotly — plot_error","text":"","code":"plot_error(message, color = \"#ef4444\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Error Plot for Plotly — plot_error","text":"message message display color Color text (default: \"#ef4444\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Error Plot for Plotly — plot_error","text":"plotly plot object displaying message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyness_keywords.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Statistical Keyness — plot_keyness_keywords","title":"Plot Statistical Keyness — plot_keyness_keywords","text":"Creates horizontal bar plot distinctive keywords keyness score.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyness_keywords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Statistical Keyness — plot_keyness_keywords","text":"","code":"plot_keyness_keywords(keyness_data, title = NULL, group_label = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyness_keywords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Statistical Keyness — plot_keyness_keywords","text":"keyness_data Data frame extract_keywords_keyness() title Plot title (default: \"Top Keywords Keyness (G-squared)\") group_label Optional label target group (default: NULL)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyness_keywords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Statistical Keyness — plot_keyness_keywords","text":"plotly bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyword_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Keyword Comparison (TF-IDF vs Frequency) — plot_keyword_comparison","title":"Plot Keyword Comparison (TF-IDF vs Frequency) — plot_keyword_comparison","text":"Creates grouped bar plot comparing TF-IDF scores term frequencies.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyword_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Keyword Comparison (TF-IDF vs Frequency) — plot_keyword_comparison","text":"","code":"plot_keyword_comparison(   tfidf_data,   top_n = 10,   title = NULL,   normalized = FALSE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyword_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Keyword Comparison (TF-IDF vs Frequency) — plot_keyword_comparison","text":"tfidf_data Data frame extract_keywords_tfidf() top_n Number keywords display (default: 10) title Plot title (default: auto-generated) normalized Logical, whether TF-IDF scores normalized (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_keyword_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Keyword Comparison (TF-IDF vs Frequency) — plot_keyword_comparison","text":"plotly grouped bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_lexical_diversity_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","title":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","text":"Creates boxplot showing distribution lexical diversity metric.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_lexical_diversity_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","text":"","code":"plot_lexical_diversity_distribution(lexdiv_data, metric, title = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_lexical_diversity_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","text":"lexdiv_data Data frame lexical_diversity_analysis() metric Metric plot. Recommended: \"MTLD\" \"MATTR\" (text-length independent) title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_lexical_diversity_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","text":"plotly boxplot","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_lexical_diversity_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Lexical Diversity Distribution — plot_lexical_diversity_distribution","text":"","code":"if (FALSE) { # \\dontrun{ data(SpecialEduTech) texts <- SpecialEduTech$abstract[1:10] corp <- quanteda::corpus(texts) toks <- quanteda::tokens(corp) dfm_obj <- quanteda::dfm(toks) result <- lexical_diversity_analysis(dfm_obj) plot <- plot_lexical_diversity_distribution(result$lexical_diversity, \"MTLD\") print(plot) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Readability by Group — plot_readability_by_group","title":"Plot Readability by Group — plot_readability_by_group","text":"Creates grouped boxplots comparing readability across categories.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Readability by Group — plot_readability_by_group","text":"","code":"plot_readability_by_group(readability_data, metric, group_var, title = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Readability by Group — plot_readability_by_group","text":"readability_data Data frame calculate_text_readability() metric Metric plot group_var Name grouping variable column title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_by_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Readability by Group — plot_readability_by_group","text":"plotly boxplot","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Readability Distribution — plot_readability_distribution","title":"Plot Readability Distribution — plot_readability_distribution","text":"Creates boxplot showing overall distribution readability metric.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Readability Distribution — plot_readability_distribution","text":"","code":"plot_readability_distribution(readability_data, metric, title = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Readability Distribution — plot_readability_distribution","text":"readability_data Data frame calculate_text_readability() metric Metric plot (e.g., \"flesch\", \"flesch_kincaid\", \"gunning_fog\") title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Readability Distribution — plot_readability_distribution","text":"plotly boxplot","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_readability_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Readability Distribution — plot_readability_distribution","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(\"Simple text.\", \"More complex sentence structure here.\") readability <- calculate_text_readability(texts) plot <- plot_readability_distribution(readability, \"flesch\") print(plot) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_semantic_viz.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Semantic Analysis Visualization — plot_semantic_viz","title":"Plot Semantic Analysis Visualization — plot_semantic_viz","text":"Creates interactive visualizations semantic analysis results including similarity heatmaps, dimensionality reduction plots, clustering visualizations.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_semantic_viz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Semantic Analysis Visualization — plot_semantic_viz","text":"","code":"plot_semantic_viz(   analysis_result = NULL,   plot_type = \"similarity\",   data_labels = NULL,   color_by = NULL,   height = 600,   width = 800,   title = NULL,   coords = NULL,   clusters = NULL,   hover_text = NULL,   hover_config = NULL,   cluster_colors = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_semantic_viz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Semantic Analysis Visualization — plot_semantic_viz","text":"analysis_result list containing semantic analysis results functions like semantic_similarity_analysis(), semantic_document_clustering(), reduce_dimensions(). plot_type Type visualization: \"similarity\" heatmap, \"dimensionality_reduction\" scatter plot, \"clustering\" cluster visualization (default: \"similarity\"). data_labels Optional character vector labels data points (default: NULL). color_by Optional variable color points scatter plots (default: NULL). height height resulting Plotly plot, pixels (default: 600). width width resulting Plotly plot, pixels (default: 800). title Optional custom title plot (default: NULL). coords Optional pre-computed coordinates dimensionality reduction plots (default: NULL). clusters Optional cluster assignments vector (default: NULL). hover_text Optional custom hover text points (default: NULL). hover_config Optional hover configuration list (default: NULL). cluster_colors Optional color palette clusters (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_semantic_viz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Semantic Analysis Visualization — plot_semantic_viz","text":"plotly object showing specified visualization.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_semantic_viz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Semantic Analysis Visualization — plot_semantic_viz","text":"","code":"if (interactive()) {   texts <- c(\"machine learning\", \"deep learning\", \"artificial intelligence\")   result <- semantic_similarity_analysis(texts)   plot <- plot_semantic_viz(result, plot_type = \"similarity\")   print(plot) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_by_category.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Sentiment by Category — plot_sentiment_by_category","title":"Plot Sentiment by Category — plot_sentiment_by_category","text":"Creates grouped stacked bar plot showing sentiment distribution across categories.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_by_category.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Sentiment by Category — plot_sentiment_by_category","text":"","code":"plot_sentiment_by_category(   sentiment_data,   category_var,   plot_type = \"bar\",   title = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_by_category.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Sentiment by Category — plot_sentiment_by_category","text":"sentiment_data Data frame 'sentiment' column category_var Name category variable column plot_type Type plot: \"bar\" \"stacked\" (default: \"bar\") title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_by_category.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Sentiment by Category — plot_sentiment_by_category","text":"plotly grouped/stacked bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_by_category.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Sentiment by Category — plot_sentiment_by_category","text":"","code":"if (FALSE) { # \\dontrun{ data <- data.frame(   text = c(\"Good\", \"Bad\", \"Okay\", \"Great\", \"Poor\"),   category = c(\"A\", \"A\", \"B\", \"B\", \"B\") ) data <- cbind(data, analyze_sentiment(data$text)) plot <- plot_sentiment_by_category(data, \"category\") print(plot) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Sentiment Distribution — plot_sentiment_distribution","title":"Plot Sentiment Distribution — plot_sentiment_distribution","text":"Creates bar plot showing distribution sentiment classifications.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Sentiment Distribution — plot_sentiment_distribution","text":"","code":"plot_sentiment_distribution(sentiment_data, title = \"Sentiment Distribution\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Sentiment Distribution — plot_sentiment_distribution","text":"sentiment_data Data frame analyze_sentiment() 'sentiment' column title Plot title (default: \"Sentiment Distribution\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Sentiment Distribution — plot_sentiment_distribution","text":"plotly bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_sentiment_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Sentiment Distribution — plot_sentiment_distribution","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(\"Great results!\", \"Poor performance\", \"Okay outcome\") sentiment_data <- analyze_sentiment(texts) plot <- plot_sentiment_distribution(sentiment_data) print(plot) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_tfidf_keywords.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot TF-IDF Keywords — plot_tfidf_keywords","title":"Plot TF-IDF Keywords — plot_tfidf_keywords","text":"Creates horizontal bar plot top keywords TF-IDF score.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_tfidf_keywords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot TF-IDF Keywords — plot_tfidf_keywords","text":"","code":"plot_tfidf_keywords(tfidf_data, title = NULL, normalized = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_tfidf_keywords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot TF-IDF Keywords — plot_tfidf_keywords","text":"tfidf_data Data frame extract_keywords_tfidf() title Plot title (default: \"Top Keywords TF-IDF Score\") normalized Logical, whether scores normalized (label) (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_tfidf_keywords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot TF-IDF Keywords — plot_tfidf_keywords","text":"plotly bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Topic Effects for Categorical Variables — plot_topic_effects_categorical","title":"Plot Topic Effects for Categorical Variables — plot_topic_effects_categorical","text":"Creates faceted plot showing categorical variables affect topic proportions.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Topic Effects for Categorical Variables — plot_topic_effects_categorical","text":"","code":"plot_topic_effects_categorical(   effects_data,   ncol = 2,   height = 800,   width = 1000,   title = \"Category Effects\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Topic Effects for Categorical Variables — plot_topic_effects_categorical","text":"effects_data Data frame columns: topic, value, proportion, lower, upper ncol Number columns faceting (default: 2) height Plot height pixels (default: 800) width Plot width pixels (default: 1000) title Plot title (default: \"Category Effects\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Topic Effects for Categorical Variables — plot_topic_effects_categorical","text":"plotly object","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Topic Effects for Continuous Variables — plot_topic_effects_continuous","title":"Plot Topic Effects for Continuous Variables — plot_topic_effects_continuous","text":"Creates faceted plot showing continuous variables affect topic proportions.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Topic Effects for Continuous Variables — plot_topic_effects_continuous","text":"","code":"plot_topic_effects_continuous(   effects_data,   ncol = 2,   height = 800,   width = 1000,   title = \"Continuous Variable Effects\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Topic Effects for Continuous Variables — plot_topic_effects_continuous","text":"effects_data Data frame columns: topic, value, proportion, lower, upper ncol Number columns faceting (default: 2) height Plot height pixels (default: 800) width Plot width pixels (default: 1000) title Plot title (default: \"Continuous Variable Effects\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_effects_continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Topic Effects for Continuous Variables — plot_topic_effects_continuous","text":"plotly object","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","title":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","text":"function generates bar plot showing prevalence topic across documents.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","text":"","code":"plot_topic_probability(   stm_model = NULL,   gamma_data = NULL,   top_n = 10,   height = 800,   width = 1000,   topic_labels = NULL,   colors = NULL,   verbose = TRUE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","text":"stm_model fitted STM model object. stm_model fitted Structural Topic Model created using stm::stm(). gamma_data Optional pre-computed gamma data frame (default: NULL). provided, used instead stm_model. top_n number topics display, ordered mean prevalence. height height resulting Plotly plot, pixels (default: 800). width width resulting Plotly plot, pixels (default: 1000). topic_labels Optional topic labels (default: NULL). colors Optional color palette topics (default: NULL). verbose Logical, TRUE, prints progress messages. ... arguments passed tidytext::tidy.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","text":"ggplot object showing bar plot topic prevalence. Topics ordered mean gamma value (average prevalence across documents).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_topic_probability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Per-Document Per-Topic Probabilities — plot_topic_probability","text":"","code":"if (interactive()) {  mydata <- TextAnalysisR::SpecialEduTech   united_tbl <- TextAnalysisR::unite_cols(    mydata,    listed_vars = c(\"title\", \"keyword\", \"abstract\")  )   tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")   dfm_object <- quanteda::dfm(tokens)   out <- quanteda::convert(dfm_object, to = \"stm\")  stm_15 <- stm::stm(   data = out$meta,   documents = out$documents,   vocab = out$vocab,   max.em.its = 75,   init.type = \"Spectral\",   K = 15,   prevalence = ~ reference_type + s(year),   verbose = TRUE)  topic_probability_plot <- TextAnalysisR::plot_topic_probability(  stm_model = stm_15,  top_n = 10,  height = 800,  width = 1000,  verbose = TRUE)  print(topic_probability_plot) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_readability_documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Top Documents by Readability — plot_top_readability_documents","title":"Plot Top Documents by Readability — plot_top_readability_documents","text":"Creates bar plot documents ranked readability metric.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_readability_documents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Top Documents by Readability — plot_top_readability_documents","text":"","code":"plot_top_readability_documents(   readability_data,   metric,   top_n = 15,   order = \"highest\",   title = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_readability_documents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Top Documents by Readability — plot_top_readability_documents","text":"readability_data Data frame calculate_text_readability() metric Metric plot top_n Number documents show (default: 15) order Direction: \"highest\" \"lowest\" (default: \"highest\") title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_readability_documents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Top Documents by Readability — plot_top_readability_documents","text":"plotly bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_sentiment_documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Top Documents by Sentiment Score — plot_top_sentiment_documents","title":"Plot Top Documents by Sentiment Score — plot_top_sentiment_documents","text":"Creates bar plot documents highest/lowest sentiment scores.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_sentiment_documents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Top Documents by Sentiment Score — plot_top_sentiment_documents","text":"","code":"plot_top_sentiment_documents(   sentiment_data,   top_n = 15,   order = \"highest\",   title = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_sentiment_documents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Top Documents by Sentiment Score — plot_top_sentiment_documents","text":"sentiment_data Data frame analyze_sentiment() top_n Number documents show (default: 15) order Direction: \"highest\" \"lowest\" (default: \"highest\") title Plot title (default: auto-generated)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_top_sentiment_documents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Top Documents by Sentiment Score — plot_top_sentiment_documents","text":"plotly bar chart","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Word Frequency — plot_word_frequency","title":"Plot Word Frequency — plot_word_frequency","text":"Creates bar plot showing frequent words document-feature matrix (dfm).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Word Frequency — plot_word_frequency","text":"","code":"plot_word_frequency(dfm_object, n = 20, height = NULL, width = NULL, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Word Frequency — plot_word_frequency","text":"dfm_object document-feature matrix created quanteda::dfm(). n number top words display (default: 20). height height resulting Plotly plot, pixels (default: 800). width width resulting Plotly plot, pixels (default: 1000). ... Additional arguments passed plotly::ggplotly().","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Word Frequency — plot_word_frequency","text":"plotly object showing word frequency.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_frequency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Word Frequency — plot_word_frequency","text":"","code":"if (interactive()) {   texts <- c(\"mathematics technology\", \"education technology\", \"learning support\")   dfm <- quanteda::dfm(quanteda::tokens(texts))   plot <- plot_word_frequency(dfm, n = 5)   print(plot) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Word Probabilities by Topic — plot_word_probability","title":"Plot Word Probabilities by Topic — plot_word_probability","text":"Creates faceted bar plot showing top terms probabilities (beta values) topic topic model.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Word Probabilities by Topic — plot_word_probability","text":"","code":"plot_word_probability(   top_topic_terms,   topic_label = NULL,   ncol = 3,   height = 1200,   width = 800,   ylab = \"Word probability\",   title = NULL,   colors = NULL,   measure_label = \"Beta\",   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Word Probabilities by Topic — plot_word_probability","text":"top_topic_terms data frame containing topic terms columns: topic, term, beta. Typically created using get_topic_terms() similar functions. topic_label Optional topic labels. Can either named vector mapping topic numbers labels, character string specifying column name top_topic_terms (default: NULL). ncol Number columns facet wrap layout (default: 3). height height resulting Plotly plot, pixels (default: 1200). width width resulting Plotly plot, pixels (default: 800). ylab Y-axis label (default: \"Word probability\"). title Plot title (default: NULL auto-generated title). colors Color palette topics (default: NULL auto-generated colors). measure_label Label probability measure (default: \"Beta\"). ... Additional arguments passed plotly::ggplotly().","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Word Probabilities by Topic — plot_word_probability","text":"plotly object showing word probabilities faceted topic.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/plot_word_probability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Word Probabilities by Topic — plot_word_probability","text":"","code":"if (interactive()) {   top_terms <- data.frame(     topic = rep(1:2, each = 5),     term = c(\"learning\", \"student\", \"education\", \"school\", \"teacher\",              \"technology\", \"computer\", \"digital\", \"software\", \"system\"),     beta = c(0.05, 0.04, 0.03, 0.02, 0.01, 0.06, 0.05, 0.04, 0.03, 0.02)   )   plot <- plot_word_probability(top_terms)   print(plot) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/prep_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Text Data — prep_texts","title":"Preprocess Text Data — prep_texts","text":"Preprocesses text data following complete workflow implemented Shiny application: Constructing corpus united texts Tokenizing text words configurable options Converting lowercase acronym preservation option Applying character length filtering Optional multi-word expression detection compound term creation Stopword removal lemmatization capabilities function serves foundation subsequent text analysis workflows.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/prep_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Text Data — prep_texts","text":"","code":"prep_texts(   united_tbl,   text_field = \"united_texts\",   min_char = 2,   lowercase = TRUE,   remove_punct = TRUE,   remove_symbols = TRUE,   remove_numbers = TRUE,   remove_url = TRUE,   remove_separators = TRUE,   split_hyphens = TRUE,   split_tags = TRUE,   include_docvars = TRUE,   keep_acronyms = FALSE,   padding = FALSE,   verbose = FALSE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/prep_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Text Data — prep_texts","text":"united_tbl data frame contains text data. text_field name column contains text data. min_char minimum number characters token included (default: 2). lowercase Logical; convert tokens lowercase (default: TRUE). Recommended text analysis tasks. remove_punct Logical; remove punctuation text (default: TRUE). remove_symbols Logical; remove symbols text (default: TRUE). remove_numbers Logical; remove numbers text (default: TRUE). remove_url Logical; remove URLs text (default: TRUE). remove_separators Logical; remove separators text (default: TRUE). split_hyphens Logical; split hyphenated words separate tokens (default: TRUE). split_tags Logical; split tags separate tokens (default: TRUE). include_docvars Logical; include document variables tokens object (default: TRUE). keep_acronyms Logical; keep acronyms text (default: FALSE). padding Logical; add padding tokens object (default: FALSE). verbose Logical; print verbose output (default: FALSE). ... Additional arguments passed quanteda::tokens.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/prep_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Text Data — prep_texts","text":"tokens object contains preprocessed text data.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/prep_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess Text Data — prep_texts","text":"","code":"if (interactive()) { mydata <- TextAnalysisR::SpecialEduTech  united_tbl <- TextAnalysisR::unite_cols(   mydata,   listed_vars = c(\"title\", \"keyword\", \"abstract\") )  tokens <- TextAnalysisR::prep_texts(united_tbl,                                          text_field = \"united_texts\",                                          min_char = 2,                                          lowercase = TRUE,                                          remove_punct = TRUE,                                          remove_symbols = TRUE,                                          remove_numbers = TRUE,                                          remove_url = TRUE,                                          remove_separators = TRUE,                                          split_hyphens = TRUE,                                          split_tags = TRUE,                                          include_docvars = TRUE,                                          keep_acronyms = FALSE,                                          padding = FALSE,                                          verbose = FALSE) print(tokens) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Process PDF File — process_pdf_file","title":"Process PDF File — process_pdf_file","text":"Main function process PDF files - extracts text content using pdftools. table extraction, use process_pdf_file_py.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process PDF File — process_pdf_file","text":"","code":"process_pdf_file(file_path, content_type = \"auto\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process PDF File — process_pdf_file","text":"file_path Character string path PDF file content_type Character string: \"auto\" \"text\" (default: \"auto\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process PDF File — process_pdf_file","text":"List : data: Data frame extracted content type: Character string indicating content type (\"text\" \"error\") success: Logical indicating success message: Character string status message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process PDF File — process_pdf_file","text":"function extracts text content PDFs using pdftools package. Works best text-based PDFs (scanned images). PDFs containing tables complex layouts, use Python-based process_pdf_file_py provides better table extraction.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process PDF File — process_pdf_file","text":"","code":"if (FALSE) { # \\dontrun{ pdf_path <- \"path/to/document.pdf\" result <- process_pdf_file(pdf_path)  if (result$success) {   print(head(result$data)) } else {   print(result$message) } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Process PDF File using Python — process_pdf_file_py","title":"Process PDF File using Python — process_pdf_file_py","text":"Main function process PDF files using pdfplumber (Python). Automatically detects content type extracts data accordingly. Java required.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process PDF File using Python — process_pdf_file_py","text":"","code":"process_pdf_file_py(   file_path,   content_type = \"auto\",   envname = \"textanalysisr-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process PDF File using Python — process_pdf_file_py","text":"file_path Character string path PDF file content_type Character string: \"auto\", \"text\", \"tabular\" \"auto\", detect content type automatically envname Character string, name Python virtual environment (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process PDF File using Python — process_pdf_file_py","text":"List : data: Data frame extracted content type: Character string indicating content type success: Logical indicating success message: Character string status message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process PDF File using Python — process_pdf_file_py","text":"function uses Python's pdfplumber library : Handles text tables Java dependency Better accuracy tabulizer complex tables Uses Python environment LangGraph","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_file_py.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process PDF File using Python — process_pdf_file_py","text":"","code":"if (FALSE) { # \\dontrun{ setup_langgraph_env()  pdf_path <- \"path/to/document.pdf\" result <- process_pdf_file_py(pdf_path)  if (result$success) {   print(head(result$data)) } else {   print(result$message) } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_unified.html","id":null,"dir":"Reference","previous_headings":"","what":"Process PDF File (Unified Entry Point) — process_pdf_unified","title":"Process PDF File (Unified Entry Point) — process_pdf_unified","text":"Unified PDF processing automatic fallback: Multimodal (Python + Vision) 2. Python pdfplumber 3. R pdftools","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_unified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process PDF File (Unified Entry Point) — process_pdf_unified","text":"","code":"process_pdf_unified(   file_path,   use_multimodal = FALSE,   vision_provider = \"ollama\",   vision_model = NULL,   api_key = NULL,   describe_images = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_unified.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process PDF File (Unified Entry Point) — process_pdf_unified","text":"file_path Character string path PDF file use_multimodal Logical, enable multimodal extraction vision_provider Character, \"ollama\" \"openai\" vision_model Character, model name api_key Character, OpenAI API key (using OpenAI) describe_images Logical, generate image descriptions","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/process_pdf_unified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process PDF File (Unified Entry Point) — process_pdf_unified","text":"List: success, data, type, method, message","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/reduce_dimensions.html","id":null,"dir":"Reference","previous_headings":"","what":"Dimensionality Reduction Analysis — reduce_dimensions","title":"Dimensionality Reduction Analysis — reduce_dimensions","text":"function performs dimensionality reduction using various methods including PCA, t-SNE, UMAP. efficiency consistency, PCA preprocessing always performed first, t-SNE/UMAP use PCA results input. follows best practices high-dimensional data analysis.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/reduce_dimensions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dimensionality Reduction Analysis — reduce_dimensions","text":"","code":"reduce_dimensions(   data_matrix,   method = \"PCA\",   n_components = 2,   pca_dims = 50,   tsne_perplexity = 30,   tsne_max_iter = 1000,   umap_neighbors = 15,   umap_min_dist = 0.1,   umap_metric = \"cosine\",   seed = 123,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/reduce_dimensions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dimensionality Reduction Analysis — reduce_dimensions","text":"data_matrix numeric matrix rows represent documents columns represent features. method dimensionality reduction method. Options: \"PCA\", \"t-SNE\", \"UMAP\". n_components number components/dimensions reduce (default: 2). pca_dims number dimensions PCA preprocessing (default: 50). tsne_perplexity perplexity parameter t-SNE (default: 30). tsne_max_iter maximum number iterations t-SNE (default: 1000). umap_neighbors number neighbors UMAP (default: 15). umap_min_dist minimum distance UMAP (default: 0.1). umap_metric metric UMAP (default: \"cosine\"). seed Random seed reproducibility (default: 123). verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/reduce_dimensions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dimensionality Reduction Analysis — reduce_dimensions","text":"list containing reduced dimensions, method used, additional metadata.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/reduce_dimensions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dimensionality Reduction Analysis — reduce_dimensions","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    tokens <- TextAnalysisR::prep_texts(united_tbl, text_field = \"united_texts\")    dfm_object <- quanteda::dfm(tokens)    data_matrix <- as.matrix(dfm_object)    pca_result <- TextAnalysisR::reduce_dimensions(     data_matrix,     method = \"PCA\"   )   print(pca_result)    tsne_result <- TextAnalysisR::reduce_dimensions(     data_matrix,     method = \"t-SNE\"   )   print(tsne_result)    umap_result <- TextAnalysisR::reduce_dimensions(     data_matrix,     method = \"UMAP\"   )   print(umap_result) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_notification_by_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Notification by ID — remove_notification_by_id","title":"Remove Notification by ID — remove_notification_by_id","text":"Removes notification specific ID.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_notification_by_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Notification by ID — remove_notification_by_id","text":"","code":"remove_notification_by_id(id)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_notification_by_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Notification by ID — remove_notification_by_id","text":"id notification ID remove","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/remove_notification_by_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Notification by ID — remove_notification_by_id","text":"Removes Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/require_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Require Feature — require_feature","title":"Require Feature — require_feature","text":"Checks feature availability shows notification unavailable.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/require_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Require Feature — require_feature","text":"","code":"require_feature(feature, session = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/require_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Require Feature — require_feature","text":"feature Character: feature name check session Shiny session object (optional)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/require_feature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Require Feature — require_feature","text":"Logical TRUE available, FALSE ","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/require_feature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Require Feature — require_feature","text":"","code":"if (FALSE) { # \\dontrun{ if (!require_feature(\"embeddings\", session)) return() } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch and browse the TextAnalysisR app — run_app","title":"Launch and browse the TextAnalysisR app — run_app","text":"Launch browse TextAnalysisR app.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch and browse the TextAnalysisR app — run_app","text":"","code":"run_app()"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch and browse the TextAnalysisR app — run_app","text":"return value, called side effects (launching Shiny app)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Launch and browse the TextAnalysisR app — run_app","text":"","code":"if (interactive()) {   library(TextAnalysisR)   run_app() }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_contrastive_topics_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Contrastive Learning Topic Modeling — run_contrastive_topics_internal","title":"Contrastive Learning Topic Modeling — run_contrastive_topics_internal","text":"Implements contrastive learning approaches topic modeling improve topic separation discriminability.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_contrastive_topics_internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contrastive Learning Topic Modeling — run_contrastive_topics_internal","text":"","code":"run_contrastive_topics_internal(   texts,   n_topics = 10,   temperature = 0.1,   negative_sampling_rate = 5,   embedding_model = \"all-MiniLM-L6-v2\",   seed = 123 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_contrastive_topics_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contrastive Learning Topic Modeling — run_contrastive_topics_internal","text":"texts Character vector documents n_topics Number topics discover temperature Temperature parameter contrastive learning negative_sampling_rate Rate negative sampling embedding_model Transformer model embeddings seed Random seed reproducibility","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_contrastive_topics_internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contrastive Learning Topic Modeling — run_contrastive_topics_internal","text":"List containing contrastive topic model metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_neural_topics_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural Topic Modeling — run_neural_topics_internal","title":"Neural Topic Modeling — run_neural_topics_internal","text":"Implements neural topic modeling using deep learning architectures improved topic discovery representation learning.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_neural_topics_internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural Topic Modeling — run_neural_topics_internal","text":"","code":"run_neural_topics_internal(   texts,   n_topics = 10,   hidden_layers = 2,   hidden_units = 100,   dropout_rate = 0.2,   embedding_model = \"all-MiniLM-L6-v2\",   seed = 123 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_neural_topics_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural Topic Modeling — run_neural_topics_internal","text":"texts Character vector documents n_topics Number topics discover hidden_layers Number hidden layers neural network hidden_units Number units per hidden layer dropout_rate Dropout rate regularization embedding_model Transformer model initial embeddings seed Random seed reproducibility","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_neural_topics_internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural Topic Modeling — run_neural_topics_internal","text":"List containing neural topic model diagnostics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":null,"dir":"Reference","previous_headings":"","what":"RAG-Enhanced Semantic Search — run_rag_search","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"Uses LangGraph multi-agent workflow Retrieval Augmented Generation. Provides question-answering document corpus source attribution.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"","code":"run_rag_search(   query,   documents,   ollama_model = \"llama3\",   ollama_base_url = \"http://localhost:11434\",   embedding_model = \"nomic-embed-text\",   top_k = 5,   envname = \"textanalysisr-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"query Character string, user question documents Character vector, corpus search ollama_model Character string, LLM model (default: \"llama3\") ollama_base_url Character string, Ollama API endpoint embedding_model Character string, embedding model (default: \"nomic-embed-text\") top_k Integer, number documents retrieve (default: 5) envname Character string, Python environment name","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"List : success: Logical answer: Generated answer confidence: Confidence score (0-1) sources: Vector source document IDs retrieved_docs: Retrieved document chunks scores: Similarity scores","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"Multi-agent workflow: Retrieval Agent: Find relevant documents via embeddings Generation Agent: Create answer context Validation Agent: Assess answer quality Conditional retry confidence < 0.4 Requires Ollama embedding model:","code":"ollama pull llama3 ollama pull nomic-embed-text"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_rag_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RAG-Enhanced Semantic Search — run_rag_search","text":"","code":"if (FALSE) { # \\dontrun{ documents <- c(   \"Assistive technology helps students with disabilities access curriculum.\",   \"Universal Design for Learning provides multiple means of engagement.\",   \"Response to Intervention uses tiered support systems.\" )  result <- run_rag_search(   query = \"How does assistive technology support learning?\",   documents = documents )  if (result$success) {   cat(\"Answer:\", result$answer, \"\\n\")   cat(\"Confidence:\", result$confidence, \"\\n\")   cat(\"Sources:\", paste(result$sources, collapse = \", \"), \"\\n\") } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_temporal_topics_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Dynamic Topic Modeling — run_temporal_topics_internal","title":"Temporal Dynamic Topic Modeling — run_temporal_topics_internal","text":"Analyzes topic evolution time periods using dynamic modeling approaches track concept emergence, evolution, decline.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_temporal_topics_internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Dynamic Topic Modeling — run_temporal_topics_internal","text":"","code":"run_temporal_topics_internal(   texts,   metadata = NULL,   n_topics = 10,   temporal_unit = \"year\",   temporal_window = 3,   detect_evolution = TRUE,   embedding_model = \"all-MiniLM-L6-v2\",   seed = 123 )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_temporal_topics_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Dynamic Topic Modeling — run_temporal_topics_internal","text":"texts Character vector documents metadata Data frame containing temporal information n_topics Number topics discover temporal_unit Unit temporal analysis (\"year\", \"quarter\", \"month\") temporal_window Size temporal window analysis detect_evolution Whether detect topic evolution patterns embedding_model Transformer model embeddings seed Random seed reproducibility","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_temporal_topics_internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Dynamic Topic Modeling — run_temporal_topics_internal","text":"List containing temporal topic model evolution analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_text_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete Text Mining Workflow — run_text_workflow","title":"Complete Text Mining Workflow — run_text_workflow","text":"function provides complete text mining workflow follows sequence Shiny application: file processing → text uniting → preprocessing → DFM creation → analysis. serves convenience function users want execute entire pipeline programmatically.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_text_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complete Text Mining Workflow — run_text_workflow","text":"","code":"run_text_workflow(   dataset_choice,   file_info = NULL,   text_input = NULL,   listed_vars,   min_char = 2,   remove_punct = TRUE,   remove_symbols = TRUE,   remove_numbers = TRUE,   remove_url = TRUE,   detect_compounds = FALSE,   compound_size = 2:3,   compound_min_count = 2,   verbose = TRUE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_text_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complete Text Mining Workflow — run_text_workflow","text":"dataset_choice character string indicating dataset choice: \"Upload Example Dataset\", \"Upload File\", \"Copy Paste Text\". file_info data frame containing file information (file upload). text_input character string containing text input (copy-paste). listed_vars character vector column names unite text. min_char minimum number characters tokens (default: 2). remove_punct Logical; remove punctuation (default: TRUE). remove_symbols Logical; remove symbols (default: TRUE). remove_numbers Logical; remove numbers (default: TRUE). remove_url Logical; remove URLs (default: TRUE). detect_compounds Logical; detect multi-word expressions (default: FALSE). compound_size Size range compound detection (default: 2:3). compound_min_count Minimum count compounds (default: 2). verbose Logical; print progress messages (default: TRUE).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_text_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complete Text Mining Workflow — run_text_workflow","text":"list containing processed data, tokens, DFM, metadata.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/run_text_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complete Text Mining Workflow — run_text_workflow","text":"","code":"if (interactive()) {   # Using example dataset   workflow_result <- TextAnalysisR::run_text_workflow(     dataset_choice = \"Upload an Example Dataset\",     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )    # Using file upload   file_info <- data.frame(filepath = \"path/to/your/file.xlsx\")   workflow_result <- TextAnalysisR::run_text_workflow(     dataset_choice = \"Upload Your File\",     file_info = file_info,     listed_vars = c(\"column1\", \"column2\")   )    # Using copy-paste text   workflow_result <- TextAnalysisR::run_text_workflow(     dataset_choice = \"Copy and Paste Text\",     text_input = \"Your text content here\",     listed_vars = \"text\"   ) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sanitize_text_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Sanitize Text Input — sanitize_text_input","title":"Sanitize Text Input — sanitize_text_input","text":"Sanitize Text Input","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sanitize_text_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sanitize Text Input — sanitize_text_input","text":"","code":"sanitize_text_input(text)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sanitize_text_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sanitize Text Input — sanitize_text_input","text":"text Text input user","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sanitize_text_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sanitize Text Input — sanitize_text_input","text":"Sanitized text","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_cooccurrence_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Word Co-occurrence Network — semantic_cooccurrence_network","title":"Compute Word Co-occurrence Network — semantic_cooccurrence_network","text":"Computes word co-occurrence networks community detection network metrics. Supports multiple feature spaces: unigrams, n-grams, embeddings. Based proven implementation intuitive network visualization.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_cooccurrence_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Word Co-occurrence Network — semantic_cooccurrence_network","text":"","code":"semantic_cooccurrence_network(   dfm_object,   doc_var = NULL,   co_occur_n = 10,   top_node_n = 30,   node_label_size = 14,   pattern = NULL,   showlegend = TRUE,   seed = NULL,   feature_type = \"words\",   ngram_range = 2,   texts = NULL,   embeddings = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_cooccurrence_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Word Co-occurrence Network — semantic_cooccurrence_network","text":"dfm_object quanteda document-feature matrix (dfm). doc_var document-level metadata variable categories (default: NULL). co_occur_n Minimum co-occurrence count (default: 10). top_node_n Number top nodes display based degree centrality (default: 30). node_label_size Font size node labels (default: 14). pattern Regex pattern filter specific words (default: NULL). showlegend Whether show community legend (default: TRUE). seed Random seed reproducible layout (default: NULL). feature_type Feature space: \"words\", \"ngrams\", \"embeddings\" (default: \"words\"). ngram_range N-gram size feature_type = \"ngrams\" (default: 2). texts Optional character vector texts n-gram creation (default: NULL). embeddings Optional embedding matrix embedding-based networks (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_cooccurrence_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Word Co-occurrence Network — semantic_cooccurrence_network","text":"list containing plot, table, nodes, edges, stats","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_correlation_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Word Correlation Network — semantic_correlation_network","title":"Compute Word Correlation Network — semantic_correlation_network","text":"Computes word correlation networks community detection network metrics. Supports multiple feature spaces: unigrams, n-grams, embeddings. Based proven implementation intuitive network visualization.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_correlation_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Word Correlation Network — semantic_correlation_network","text":"","code":"semantic_correlation_network(   dfm_object,   doc_var = NULL,   common_term_n = 20,   corr_n = 0.4,   top_node_n = 30,   node_label_size = 14,   pattern = NULL,   showlegend = TRUE,   seed = NULL,   feature_type = \"words\",   ngram_range = 2,   texts = NULL,   embeddings = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_correlation_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Word Correlation Network — semantic_correlation_network","text":"dfm_object quanteda document-feature matrix (dfm). doc_var document-level metadata variable categories (default: NULL). common_term_n Minimum term frequency include (default: 20). corr_n Minimum correlation threshold (default: 0.4). top_node_n Number top nodes display (default: 30). node_label_size Font size node labels (default: 14). pattern Regex pattern filter specific words (default: NULL). showlegend Whether show community legend (default: TRUE). seed Random seed reproducible layout (default: NULL). feature_type Feature space: \"words\", \"ngrams\", \"embeddings\" (default: \"words\"). ngram_range N-gram size feature_type = \"ngrams\" (default: 2). texts Optional character vector texts n-gram creation (default: NULL). embeddings Optional embedding matrix embedding-based networks (default: NULL).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_correlation_network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Word Correlation Network — semantic_correlation_network","text":"list containing plot, table, nodes, edges, stats","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_document_clustering.html","id":null,"dir":"Reference","previous_headings":"","what":"Semantic Document Clustering — semantic_document_clustering","title":"Semantic Document Clustering — semantic_document_clustering","text":"Creates unified visualization document clustering optional clustering","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_document_clustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Semantic Document Clustering — semantic_document_clustering","text":"","code":"semantic_document_clustering(embeddings, method = \"UMAP\", clusters = NULL, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_document_clustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Semantic Document Clustering — semantic_document_clustering","text":"embeddings Document embeddings matrix method Dimensionality reduction method (\"PCA\", \"t-SNE\", \"UMAP\") clusters Optional cluster assignments ... Additional arguments","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_similarity_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Semantic Similarity Analysis — semantic_similarity_analysis","title":"Semantic Similarity Analysis — semantic_similarity_analysis","text":"Wrapper calculate_document_similarity","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_similarity_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Semantic Similarity Analysis — semantic_similarity_analysis","text":"","code":"semantic_similarity_analysis(...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_similarity_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Semantic Similarity Analysis — semantic_similarity_analysis","text":"... Arguments passed calculate_document_similarity","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/semantic_similarity_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Semantic Similarity Analysis — semantic_similarity_analysis","text":"Similarity analysis results","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_embedding_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","title":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","text":"Performs sentiment analysis using transformer-based embeddings neural models. approach uses pre-trained language models contextual sentiment detection without requiring sentiment lexicons. Particularly effective handling: Complex contextual sentiment Implicit sentiment sarcasm Domain-specific sentiment Negation intensifiers (automatically handled model)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_embedding_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","text":"","code":"sentiment_embedding_analysis(   texts,   embeddings = NULL,   model_name = \"distilbert-base-uncased-finetuned-sst-2-english\",   doc_names = NULL,   use_gpu = FALSE )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_embedding_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","text":"texts Character vector texts analyze embeddings Optional pre-computed embedding matrix (generate_embeddings) model_name Sentiment model name (default: \"distilbert-base-uncased-finetuned-sst-2-english\") doc_names Optional document names/IDs use_gpu Whether use GPU available (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_embedding_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","text":"list containing: document_sentiment Data frame document-level sentiment scores classifications emotion_scores NULL (emotion detection currently supported embeddings) summary_stats Summary statistics including document counts average scores model_used Name transformer model used feature_type \"embeddings\"","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_embedding_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding-based Sentiment Analysis — sentiment_embedding_analysis","text":"","code":"if (FALSE) { # \\dontrun{ texts <- c(   \"The results significantly improved student outcomes.\",   \"The intervention showed no clear benefit.\",   \"Students reported difficulty with the material.\" ) result <- sentiment_embedding_analysis(texts) print(result$document_sentiment) print(result$summary_stats) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_lexicon_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","title":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","text":"Performs lexicon-based sentiment analysis DFM object using tidytext lexicons. Supports AFINN, Bing, NRC lexicons comprehensive scoring emotion analysis. Now supports n-grams improved negation intensifier handling.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_lexicon_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","text":"","code":"sentiment_lexicon_analysis(   dfm_object,   lexicon = \"afinn\",   texts_df = NULL,   feature_type = \"words\",   ngram_range = 2,   texts = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_lexicon_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","text":"dfm_object quanteda DFM object (unigram n-gram) lexicon Lexicon use: \"afinn\", \"bing\", \"nrc\" (default: \"afinn\") texts_df Optional data frame original texts metadata (default: NULL) feature_type Feature space: \"words\" (unigrams) \"ngrams\" (default: \"words\") ngram_range N-gram size feature_type = \"ngrams\" (default: 2 bigrams) texts Optional character vector texts n-gram creation (default: NULL)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_lexicon_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","text":"list containing: document_sentiment Data frame sentiment scores per document emotion_scores Data frame emotion scores (NRC ) summary_stats List summary statistics feature_type Feature type used analysis","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/sentiment_lexicon_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze Sentiment Using Tidytext Lexicons — sentiment_lexicon_analysis","text":"","code":"if (FALSE) { # \\dontrun{ corp <- quanteda::corpus(c(\"I love this!\", \"I hate that\", \"It's okay\")) dfm_obj <- quanteda::dfm(quanteda::tokens(corp)) results <- sentiment_lexicon_analysis(dfm_obj, lexicon = \"afinn\") print(results$document_sentiment)  texts <- c(\"not good at all\", \"very happy indeed\") results_ngram <- sentiment_lexicon_analysis(   dfm_obj,   lexicon = \"bing\",   feature_type = \"ngrams\",   ngram_range = 2,   texts = texts ) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup Python Environment — setup_python_env","title":"Setup Python Environment — setup_python_env","text":"Intelligently sets Python virtual environment required packages. Detects existing Python installations guides users Python missing.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup Python Environment — setup_python_env","text":"","code":"setup_python_env(envname = \"textanalysisr-env\", force = FALSE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup Python Environment — setup_python_env","text":"envname Character string name virtual environment (default: \"textanalysisr-env\") force Logical, whether recreate environment exists (default: FALSE)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup Python Environment — setup_python_env","text":"Invisible TRUE successful, stops error message failed","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setup Python Environment — setup_python_env","text":"function: Automatically detects Python already installed Offers install Miniconda Python found Creates isolated virtual environment (modify system Python) Installs 6 core packages (minimal installation): langchain-core (core LangChain functionality) langchain-ollama (Ollama integration) langgraph (workflow graphs) langgraph-checkpoint (workflow state management) ollama (Ollama client) pdfplumber (PDF table extraction) Dependencies installed automatically pip Avoids heavy packages (marker-pdf, nougat-ocr, torch) virtual environment approach means: conflicts Python projects Easy remove (just delete environment) System Python remains untouched Much smaller download (~100MB vs 5GB+) setup, restart R session activate enhanced features.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/setup_python_env.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup Python Environment — setup_python_env","text":"","code":"if (FALSE) { # \\dontrun{ # First time setup (auto-detects Python) setup_python_env()  # Recreate environment setup_python_env(force = TRUE) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_completion_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Completion Notification — show_completion_notification","title":"Show Completion Notification — show_completion_notification","text":"Displays temporary success notification task completes.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_completion_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Completion Notification — show_completion_notification","text":"","code":"show_completion_notification(message, duration = 5)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_completion_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Completion Notification — show_completion_notification","text":"message completion message display duration Duration seconds (default: 5)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_completion_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Completion Notification — show_completion_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_instructions_modal.html","id":null,"dir":"Reference","previous_headings":"","what":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","title":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","text":"Displays modal dialog console-style instructions creating DFM. Uses verbatimTextOutput formatting.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_instructions_modal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","text":"","code":"show_dfm_instructions_modal(   output_id,   feature_name = \"this feature\",   session = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_instructions_modal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","text":"output_id Shiny output ID verbatimTextOutput feature_name Name feature requiring DFM (default: \"feature\") session Shiny session object (default: getDefaultReactiveDomain())","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_instructions_modal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","text":"Displays Shiny modal dialog. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_instructions_modal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show DFM Setup Instructions Modal — show_dfm_instructions_modal","text":"","code":"if (FALSE) { # \\dontrun{ output$dfm_instructions <- renderPrint({   cat(get_dfm_setup_instructions(\"keywords\"), sep = \"\\n\") })  show_dfm_instructions_modal(\"dfm_instructions\", \"keywords\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_required_modal.html","id":null,"dir":"Reference","previous_headings":"","what":"Show DFM Requirement Modal — show_dfm_required_modal","title":"Show DFM Requirement Modal — show_dfm_required_modal","text":"Displays standardized modal dialog informing users need complete preprocessing steps using feature requires document-feature matrix.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_required_modal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show DFM Requirement Modal — show_dfm_required_modal","text":"","code":"show_dfm_required_modal(   feature_name = \"this feature\",   additional_message = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_required_modal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show DFM Requirement Modal — show_dfm_required_modal","text":"feature_name Name feature requiring DFM (e.g., \"topic modeling\", \"keyword extraction\") additional_message Optional additional message display (default: NULL)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_required_modal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show DFM Requirement Modal — show_dfm_required_modal","text":"Displays Shiny modal dialog. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_dfm_required_modal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show DFM Requirement Modal — show_dfm_required_modal","text":"","code":"if (FALSE) { # \\dontrun{ if (is.null(dfm_init())) {   show_dfm_required_modal(\"topic modeling\")   return(NULL) } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_error_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Error Notification — show_error_notification","title":"Show Error Notification — show_error_notification","text":"Displays error notification user.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_error_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Error Notification — show_error_notification","text":"","code":"show_error_notification(message, duration = 7)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_error_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Error Notification — show_error_notification","text":"message error message display duration Duration seconds (default: 7)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_error_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Error Notification — show_error_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Guide Modal Dialog from HTML File — show_guide_modal","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"Loads displays modal dialog guide content HTML file. function designed Shiny applications display help documentation stored external HTML files, reducing server.R file size improving maintainability.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"","code":"show_guide_modal(guide_name, title, size = \"l\")"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"guide_name Name guide file (without .html extension). Files located inst/TextAnalysisR.app/markdown/guides/ title Modal dialog title display size Size modal dialog (default: \"l\" large). Options: \"s\" (small), \"m\" (medium), \"l\" (large)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"Displays Shiny modal dialog. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"Guide HTML files placed : inst/TextAnalysisR.app/markdown/guides/<guide_name>.html function look guide file installed package location. file found, displays error message modal.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_guide_modal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Guide Modal Dialog from HTML File — show_guide_modal","text":"","code":"if (FALSE) { # \\dontrun{ observeEvent(input$showDimRedInfo, {   show_guide_modal(\"dimensionality_reduction_guide\", \"Dimensionality Reduction Guide\") })  observeEvent(input$showClusteringInfo, {   show_guide_modal(\"clustering_guide\", \"Document Clustering Guide\") }) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_loading_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Loading/Progress Notification — show_loading_notification","title":"Show Loading/Progress Notification — show_loading_notification","text":"Displays persistent loading notification specific ID can removed later.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_loading_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Loading/Progress Notification — show_loading_notification","text":"","code":"show_loading_notification(message, id = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_loading_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Loading/Progress Notification — show_loading_notification","text":"message loading message display id Notification ID later removal (optional)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_loading_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Loading/Progress Notification — show_loading_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_dfm_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show No DFM Notification — show_no_dfm_notification","title":"Show No DFM Notification — show_no_dfm_notification","text":"Displays standardized error notification DFM required available. Shorter alternative modal dialog simple error messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_dfm_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show No DFM Notification — show_no_dfm_notification","text":"","code":"show_no_dfm_notification(feature_name = \"this feature\", duration = 7)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_dfm_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show No DFM Notification — show_no_dfm_notification","text":"feature_name Name feature requiring DFM (default: \"feature\") duration Duration seconds (default: 7)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_dfm_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show No DFM Notification — show_no_dfm_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_feature_matrix_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Feature Matrix Notification — show_no_feature_matrix_notification","title":"Show Feature Matrix Notification — show_no_feature_matrix_notification","text":"Displays error notification feature matrix required available. Similar show_no_dfm_notification uses \"feature matrix\" terminology.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_feature_matrix_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Feature Matrix Notification — show_no_feature_matrix_notification","text":"","code":"show_no_feature_matrix_notification(duration = 7)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_feature_matrix_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Feature Matrix Notification — show_no_feature_matrix_notification","text":"duration Duration seconds (default: 7)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_no_feature_matrix_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Feature Matrix Notification — show_no_feature_matrix_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_required_modal.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","title":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","text":"Displays simple modal indicating preprocessing required. Lightweight alternative detailed steps needed.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_required_modal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","text":"","code":"show_preprocessing_required_modal(   message = \"Please complete preprocessing steps first.\",   title = \"Preprocessing Required\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_required_modal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","text":"message Custom message (default: \"Please complete preprocessing steps first.\") title Modal title (default: \"Preprocessing Required\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_required_modal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","text":"Displays Shiny modal dialog. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_required_modal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Generic Preprocessing Required Modal — show_preprocessing_required_modal","text":"","code":"if (FALSE) { # \\dontrun{ if (!preprocessing_complete()) {   show_preprocessing_required_modal()   return() } } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_steps_modal.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","title":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","text":"Displays modal dialog listing required preprocessing steps feature. Generic version works feature requiring preprocessing.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_steps_modal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","text":"","code":"show_preprocessing_steps_modal(   title = \"Preprocessing Required\",   message,   required_steps,   optional_steps = NULL,   additional_note = NULL )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_steps_modal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","text":"title Modal title (default: \"Preprocessing Required\") message Main message display required_steps Character vector required preprocessing steps optional_steps Character vector optional preprocessing steps (default: NULL) additional_note Optional additional note display (default: NULL)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_steps_modal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","text":"Displays Shiny modal dialog. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_preprocessing_steps_modal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Preprocessing Steps Modal — show_preprocessing_steps_modal","text":"","code":"if (FALSE) { # \\dontrun{ show_preprocessing_steps_modal(   message = \"Please complete preprocessing to generate tokens.\",   required_steps = c(\"Step 1: Unite Texts\", \"Step 4: Document-Feature Matrix\"),   optional_steps = c(\"Steps 2, 3, 5, and 6\") ) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_unite_texts_required_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Unite Texts Required Notification — show_unite_texts_required_notification","title":"Show Unite Texts Required Notification — show_unite_texts_required_notification","text":"Displays error notification Step 1 (Unite Texts) required.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_unite_texts_required_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Unite Texts Required Notification — show_unite_texts_required_notification","text":"","code":"show_unite_texts_required_notification(duration = 5)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_unite_texts_required_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Unite Texts Required Notification — show_unite_texts_required_notification","text":"duration Duration seconds (default: 5)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_unite_texts_required_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Unite Texts Required Notification — show_unite_texts_required_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_warning_notification.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Warning Notification — show_warning_notification","title":"Show Warning Notification — show_warning_notification","text":"Displays warning notification user.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_warning_notification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Warning Notification — show_warning_notification","text":"","code":"show_warning_notification(message, duration = 5)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_warning_notification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Warning Notification — show_warning_notification","text":"message warning message display duration Duration seconds (default: 5)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_warning_notification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Warning Notification — show_warning_notification","text":"Displays Shiny notification. Returns NULL invisibly.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_web_banner.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Web Deployment Banner — show_web_banner","title":"Show Web Deployment Banner — show_web_banner","text":"Creates Shiny UI banner web deployments showing feature limitations.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_web_banner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Web Deployment Banner — show_web_banner","text":"","code":"show_web_banner(disabled = NULL)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_web_banner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show Web Deployment Banner — show_web_banner","text":"disabled Character vector disabled feature names (optional)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_web_banner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Web Deployment Banner — show_web_banner","text":"shiny tagList UI element (NULL local)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/show_web_banner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Web Deployment Banner — show_web_banner","text":"","code":"if (FALSE) { # \\dontrun{ output$banner <- renderUI({ show_web_banner() }) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":null,"dir":"Reference","previous_headings":"","what":"Special education technology bibliographic data — SpecialEduTech","title":"Special education technology bibliographic data — SpecialEduTech","text":"Contains bibliographic data journal articles dissertations use technology teaching mathematics students disabilities.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Special education technology bibliographic data — SpecialEduTech","text":"","code":"SpecialEduTech"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Special education technology bibliographic data — SpecialEduTech","text":"object class tbl_df (inherits tbl, data.frame) 490 rows 6 columns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/SpecialEduTech.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Special education technology bibliographic data — SpecialEduTech","text":"","code":"SpecialEduTech #> # A tibble: 490 × 6 #>    reference_type  author                            year title keyword abstract #>    <chr>           <chr>                            <dbl> <chr> <chr>   <chr>    #>  1 journal_article Block, G. H.                      1980 Dysc… Arithm… Notes t… #>  2 thesis          Bukatman, K. L.                   1981 The … locus … This st… #>  3 journal_article Watkins, M. W., & Webb, C.        1981 Comp… Comput… Results… #>  4 journal_article Chaffin, J. D.                    1982 Arc-… Comput… The Arc… #>  5 journal_article Chaffin, J. D., Maxwell, B., & …  1982 ARC-… Electr… This ar… #>  6 thesis          Golden, C. K.                     1982 The … NA      The pur… #>  7 journal_article Neal, D.                          1982 A re… tradit… Discuss… #>  8 thesis          Englebert, B. B.                  1983 A st… microc… The pur… #>  9 thesis          Foster, K.                        1983 The … comput… The eff… #> 10 journal_article Pommer, L. T.                     1983 Usin… Comput… The art… #> # ℹ 480 more rows"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":null,"dir":"Reference","previous_headings":"","what":"An example structure of a structural topic model — stm_15","title":"An example structure of a structural topic model — stm_15","text":"Contains 15 topics, topic prevalences, etc. stm::stm.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An example structure of a structural topic model — stm_15","text":"","code":"stm_15"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An example structure of a structural topic model — stm_15","text":"object class STM length 11.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stm_15.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An example structure of a structural topic model — stm_15","text":"","code":"stm_15 #> A topic model with 15 topics, 488 documents and a 4511 word dictionary."},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Stopwords List — stopwords_list","title":"Stopwords List — stopwords_list","text":"dataset containing stopwords text preprocessing","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/stopwords_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stopwords List — stopwords_list","text":"character vector stopwords","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/temporal_semantic_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Semantic Analysis — temporal_semantic_analysis","title":"Temporal Semantic Analysis — temporal_semantic_analysis","text":"Analyzes semantic patterns time","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/temporal_semantic_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Semantic Analysis — temporal_semantic_analysis","text":"","code":"temporal_semantic_analysis(   texts,   dates,   time_windows = \"month\",   embeddings = NULL,   verbose = FALSE,   ... )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/temporal_semantic_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Semantic Analysis — temporal_semantic_analysis","text":"texts Character vector texts analyze dates Date vector corresponding texts time_windows Time window size grouping (default: \"month\") embeddings Optional pre-computed embeddings verbose Logical indicating whether print progress messages ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/temporal_semantic_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Semantic Analysis — temporal_semantic_analysis","text":"List containing temporal analysis results","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"TextAnalysisR: Text Mining Workflow Tool — TextAnalysisR-package","title":"TextAnalysisR: Text Mining Workflow Tool — TextAnalysisR-package","text":"Comprehensive toolkit text mining natural language processing interactive 'Shiny' interface. Import documents multiple formats (PDF, DOCX, XLSX, CSV, TXT), preprocess 'quanteda', perform topic modeling ('stm'), semantic analysis, sentiment analysis, network visualization. Features AI-assisted workflows via 'LangGraph', WCAG 2.1 AA accessibility, multi-language support, enterprise security production deployment.","code":""},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/reference/TextAnalysisR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"TextAnalysisR: Text Mining Workflow Tool — TextAnalysisR-package","text":"Maintainer: Mikyung Shin shin.mikyung@gmail.com (ORCID) (Illinois State University)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Unite Text Columns — unite_cols","title":"Unite Text Columns — unite_cols","text":"function unites specified text columns data frame single column named \"united_texts\" retaining original columns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unite Text Columns — unite_cols","text":"","code":"unite_cols(df, listed_vars)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unite Text Columns — unite_cols","text":"df data frame contains text data. listed_vars character vector column names united \"united_texts\".","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unite Text Columns — unite_cols","text":"data frame new column \"united_texts\" created uniting specified variables.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/unite_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unite Text Columns — unite_cols","text":"","code":"if (interactive()) {   mydata <- TextAnalysisR::SpecialEduTech    united_tbl <- TextAnalysisR::unite_cols(     mydata,     listed_vars = c(\"title\", \"keyword\", \"abstract\")   )   print(united_tbl) }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate OpenAI API Key Format — validate_api_key","title":"Validate OpenAI API Key Format — validate_api_key","text":"Validates OpenAI API key format according NIST IA-5(1) authenticator management. Checks key prefix, length, basic format requirements.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate OpenAI API Key Format — validate_api_key","text":"","code":"validate_api_key(api_key, strict = TRUE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate OpenAI API Key Format — validate_api_key","text":"api_key Character string containing API key strict Logical, TRUE performs additional validation checks","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate OpenAI API Key Format — validate_api_key","text":"Logical TRUE valid, FALSE warnings invalid","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":"nist-compliance","dir":"Reference","previous_headings":"","what":"NIST Compliance","title":"Validate OpenAI API Key Format — validate_api_key","text":"Implements NIST IA-5(1): Authenticator Management - Password-Based Authentication. Validates format, length, character composition prevent weak malformed keys.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_api_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate OpenAI API Key Format — validate_api_key","text":"","code":"if (FALSE) { # \\dontrun{ validate_api_key(\"sk-proj...\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Column Name — validate_column_name","title":"Validate Column Name — validate_column_name","text":"Validates column names prevent code injection formula construction. Ensures column names follow R naming conventions contain malicious patterns.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Column Name — validate_column_name","text":"","code":"validate_column_name(col_name)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Column Name — validate_column_name","text":"col_name Character string containing column name","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Column Name — validate_column_name","text":"TRUE valid, stops error invalid","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":"security","dir":"Reference","previous_headings":"","what":"Security","title":"Validate Column Name — validate_column_name","text":"Protects formula injection attacks malicious column names execute arbitrary code used model formulas. Part NIST SI-10 input validation.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_column_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Column Name — validate_column_name","text":"","code":"if (FALSE) { # \\dontrun{ validate_column_name(\"age\") validate_column_name(\"my_variable\") } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_cross_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Analysis Validation — validate_cross_models","title":"Cross-Analysis Validation — validate_cross_models","text":"Performs cross-validation different analysis types (STM, semantic, clustering).","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_cross_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Analysis Validation — validate_cross_models","text":"","code":"validate_cross_models(semantic_results, stm_results = NULL, verbose = TRUE)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_cross_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Analysis Validation — validate_cross_models","text":"semantic_results Results semantic analysis. stm_results Optional STM results comparison. verbose Logical, TRUE, prints progress messages.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_cross_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Analysis Validation — validate_cross_models","text":"list containing cross-validation metrics.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_file_upload.html","id":null,"dir":"Reference","previous_headings":"","what":"Cybersecurity Utility Functions — validate_file_upload","title":"Cybersecurity Utility Functions — validate_file_upload","text":"Functions input validation, sanitization, security logging","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_file_upload.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cybersecurity Utility Functions — validate_file_upload","text":"","code":"validate_file_upload(file_info)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_file_upload.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cybersecurity Utility Functions — validate_file_upload","text":"file_info File info object Shiny fileInput","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_file_upload.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cybersecurity Utility Functions — validate_file_upload","text":"TRUE valid, stops error message invalid","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_file_upload.html","id":"nist-compliance","dir":"Reference","previous_headings":"","what":"NIST Compliance","title":"Cybersecurity Utility Functions — validate_file_upload","text":"package follows NIST security standards (based NIST SP 800-53): SC-8: Transmission Confidentiality Integrity (HTTPS encryption) SC-28: Protection Information Rest (secure API key storage) IA-5: Authenticator Management (API key validation format checking) AC-3: Access Enforcement (rate limiting, input validation, file type restrictions) SI-10: Information Input Validation (malicious content detection) AU-2: Audit Events (security logging monitoring) Validate File Upload","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_keyboard_navigation.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Keyboard Navigation — validate_keyboard_navigation","title":"Validate Keyboard Navigation — validate_keyboard_navigation","text":"Checks interactive elements proper tabindex keyboard handlers. Used WCAG 2.1.1 (Keyboard) compliance.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_keyboard_navigation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Keyboard Navigation — validate_keyboard_navigation","text":"","code":"validate_keyboard_navigation(tabindex = 0)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_keyboard_navigation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Keyboard Navigation — validate_keyboard_navigation","text":"tabindex Integer, tab order (-1 tab, 0 natural order, 1+ specific order)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_keyboard_navigation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Keyboard Navigation — validate_keyboard_navigation","text":"Logical TRUE valid, FALSE warning invalid","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_keyboard_navigation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Keyboard Navigation — validate_keyboard_navigation","text":"","code":"if (FALSE) { # \\dontrun{ validate_keyboard_navigation(0)   # TRUE validate_keyboard_navigation(999) # FALSE (too high) } # }"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_semantic_coherence.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Semantic Coherence — validate_semantic_coherence","title":"Validate Semantic Coherence — validate_semantic_coherence","text":"Validates semantic coherence topic assignments","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_semantic_coherence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Semantic Coherence — validate_semantic_coherence","text":"","code":"validate_semantic_coherence(embeddings, topic_assignments, ...)"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_semantic_coherence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Semantic Coherence — validate_semantic_coherence","text":"embeddings Document embeddings matrix topic_assignments Vector topic assignments documents ... Additional parameters","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_semantic_coherence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Semantic Coherence — validate_semantic_coherence","text":"List containing coherence score metrics","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"Uses LangGraph workflow validate user-selected topic labels using LLM.","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"","code":"validate_topic_labels_langgraph(   user_labels,   topic_terms,   ollama_model = \"llama3\",   ollama_base_url = \"http://localhost:11434\",   envname = \"textanalysisr-env\" )"},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"user_labels Character vector user-selected labels topic topic_terms List character vectors top terms topic ollama_model Character string, Ollama model name (default: \"llama3\") ollama_base_url Character string, Ollama API URL (default: \"http://localhost:11434\") envname Character string, Python virtual environment name (default: \"langgraph-env\")","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"List : success: Logical, TRUE validation completed validation_metrics: List coherence distinctiveness scores error: Error message (failed)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"Validation metrics include: coherence_scores: well labels match term distributions (0-10 scale) distinctiveness_scores: unique/specific labels (0-10 scale) overall_quality: Average coherence distinctiveness","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/reference/validate_topic_labels_langgraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate User-Selected Topic Labels — validate_topic_labels_langgraph","text":"","code":"if (FALSE) { # \\dontrun{ user_labels <- c(\"Education Policy\", \"Healthcare Services\", \"Climate Action\") topic_terms <- list(   c(\"education\", \"student\", \"learning\"),   c(\"health\", \"medical\", \"patient\"),   c(\"environment\", \"climate\", \"carbon\") )  validation <- validate_topic_labels_langgraph(   user_labels = user_labels,   topic_terms = topic_terms )  print(validation$validation_metrics$overall_quality) } # }"},{"path":[]},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"new-features-0-0-3","dir":"Changelog","previous_headings":"","what":"New Features","title":"TextAnalysisR 0.0.3 (2025-11-29)","text":"Interactive Shiny web app point--click interface Multi-format file import (PDF, DOCX, XLSX, CSV, TXT) Semantic analysis neural network embeddings Hybrid topic modeling (STM + BERTopic) OpenAI integration AI-generated topic labels","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"accessibility-0-0-3","dir":"Changelog","previous_headings":"","what":"Accessibility","title":"TextAnalysisR 0.0.3 (2025-11-29)","text":"WCAG 2.1 Level AA compliant Dark mode high contrast Keyboard navigation screen reader support Multi-language support (100+ languages)","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"security-0-0-3","dir":"Changelog","previous_headings":"","what":"Security","title":"TextAnalysisR 0.0.3 (2025-11-29)","text":"Session-based rate limiting Input validation sanitization API key protection Security event logging","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"textanalysisr-002-2024-12-05","dir":"Changelog","previous_headings":"","what":"TextAnalysisR 0.0.2 (2024-12-05)","title":"TextAnalysisR 0.0.2 (2024-12-05)","text":"Improved documentation Enhanced DESCRIPTION metadata CRAN policy compliance updates","code":""},{"path":"https://mshin77.github.io/TextAnalysisR/news/index.html","id":"textanalysisr-001-2023-10-18","dir":"Changelog","previous_headings":"","what":"TextAnalysisR 0.0.1 (2023-10-18)","title":"TextAnalysisR 0.0.1 (2023-10-18)","text":"Initial CRAN release Core text mining functionality STM topic modeling Text preprocessing capabilities Basic Shiny application","code":""}]
