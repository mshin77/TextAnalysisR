<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Semantic Analysis • TextAnalysisR</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semantic Analysis">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">TextAnalysisR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/quickstart.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/installation.html">Installation</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/preprocessing.html">Preprocessing</a></li>
    <li><a class="dropdown-item" href="../articles/lexical_analysis.html">Lexical Analysis</a></li>
    <li><a class="dropdown-item" href="../articles/semantic_analysis.html">Semantic Analysis</a></li>
    <li><a class="dropdown-item" href="../articles/topic_modeling.html">Topic Modeling</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/ai_integration.html">AI Integration</a></li>
    <li><a class="dropdown-item" href="../articles/python_environment.html">Python Environment</a></li>
    <li><a class="dropdown-item" href="../articles/multimodal_analysis.html">Multimodal Analysis</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/function_index.html">Function Index</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mshin77/TextAnalysisR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Semantic Analysis</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mshin77/TextAnalysisR/blob/HEAD/vignettes/semantic_analysis.Rmd" class="external-link"><code>vignettes/semantic_analysis.Rmd</code></a></small>
      <div class="d-none name"><code>semantic_analysis.Rmd</code></div>
    </div>

    
    
<p>Semantic analysis finds patterns of meaning using embeddings and
neural networks.</p>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mshin77.github.io/TextAnalysisR">TextAnalysisR</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">mydata</span> <span class="op">&lt;-</span> <span class="va">SpecialEduTech</span></span>
<span><span class="va">united_tbl</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/unite_cols.html">unite_cols</a></span><span class="op">(</span><span class="va">mydata</span>, listed_vars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"title"</span>, <span class="st">"keyword"</span>, <span class="st">"abstract"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tokens</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prep_texts.html">prep_texts</a></span><span class="op">(</span><span class="va">united_tbl</span>, text_field <span class="op">=</span> <span class="st">"united_texts"</span><span class="op">)</span></span>
<span><span class="va">dfm_object</span> <span class="op">&lt;-</span> <span class="fu">quanteda</span><span class="fu">::</span><span class="fu"><a href="https://quanteda.io/reference/dfm.html" class="external-link">dfm</a></span><span class="op">(</span><span class="va">tokens</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="document-similarity">Document Similarity<a class="anchor" aria-label="anchor" href="#document-similarity"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">similarity</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/semantic_similarity_analysis.html">semantic_similarity_analysis</a></span><span class="op">(</span></span>
<span>  texts <span class="op">=</span> <span class="va">united_tbl</span><span class="op">$</span><span class="va">united_texts</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"cosine"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<hr>
<details><summary><strong>Similarity Methods</strong>
</summary><p>Semantic analysis measures document similarity using different
approaches to capture meaning, from simple vocabulary matching to deep
neural representations.</p>
<p><strong>Methods:</strong></p>
<table class="table">
<colgroup>
<col width="25%">
<col width="41%">
<col width="32%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Description</th>
<th>Best For</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Words</td>
<td>Lexical analysis using word frequency vectors (bag-of-words)</td>
<td>Finding documents with shared terminology</td>
</tr>
<tr class="even">
<td>N-grams</td>
<td>Phrase-based analysis capturing word sequences</td>
<td>Detecting similar phraseology</td>
</tr>
<tr class="odd">
<td>Embeddings</td>
<td>Deep semantic analysis using transformer models</td>
<td>Conceptual similarity, handles synonyms</td>
</tr>
</tbody>
</table>
<p><strong>Usage:</strong> Choose method based on your analysis goals.
Words and n-grams are faster and interpretable. Embeddings capture
deeper meaning but require more computation. All methods use cosine
similarity for comparison.</p>
<p><strong>Learn More:</strong> <a href="https://www.sbert.net/" class="external-link">Sentence Transformers
Documentation</a></p>
</details><hr>
</div>
<div class="section level2">
<h2 id="sentiment-analysis">Sentiment Analysis<a class="anchor" aria-label="anchor" href="#sentiment-analysis"></a>
</h2>
<div class="section level3">
<h3 id="lexicon-based-no-python">Lexicon-based (no Python)<a class="anchor" aria-label="anchor" href="#lexicon-based-no-python"></a>
</h3>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sentiment</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sentiment_lexicon_analysis.html">sentiment_lexicon_analysis</a></span><span class="op">(</span><span class="va">dfm_object</span>, lexicon <span class="op">=</span> <span class="st">"afinn"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_sentiment_distribution.html">plot_sentiment_distribution</a></span><span class="op">(</span><span class="va">sentiment</span><span class="op">$</span><span class="va">document_sentiment</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="neural-requires-python">Neural (requires Python)<a class="anchor" aria-label="anchor" href="#neural-requires-python"></a>
</h3>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sentiment</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sentiment_embedding_analysis.html">sentiment_embedding_analysis</a></span><span class="op">(</span><span class="va">united_tbl</span><span class="op">$</span><span class="va">united_texts</span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="document-clustering">Document Clustering<a class="anchor" aria-label="anchor" href="#document-clustering"></a>
</h2>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">clusters</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/semantic_document_clustering.html">semantic_document_clustering</a></span><span class="op">(</span></span>
<span>  texts <span class="op">=</span> <span class="va">united_tbl</span><span class="op">$</span><span class="va">united_texts</span>,</span>
<span>  n_clusters <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  reduce_outliers <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="ai-suggested-cluster-labels">AI-Suggested Cluster Labels<a class="anchor" aria-label="anchor" href="#ai-suggested-cluster-labels"></a>
</h3>
<p>The AI generates suggested names for each cluster. You maintain full
control:</p>
<ul>
<li>Review generated labels before applying</li>
<li>Edit labels directly in the interface</li>
<li>Regenerate with different parameters if needed</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># AI suggests, human reviews and decides</span></span>
<span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/generate_cluster_labels.html">generate_cluster_labels</a></span><span class="op">(</span></span>
<span>  <span class="va">clusters</span><span class="op">$</span><span class="va">cluster_keywords</span>,</span>
<span>  provider <span class="op">=</span> <span class="st">"ollama"</span>  <span class="co"># or "openai"</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Review and edit before final use</span></span></code></pre></div>
<hr>
<details><summary><strong>Clustering Algorithms</strong>
</summary><p>Clustering groups documents with similar semantic content into
categories. Documents within a cluster are more similar to each other
than to documents in other clusters.</p>
<p><strong>Algorithms:</strong></p>
<table class="table">
<colgroup>
<col width="32%">
<col width="38%">
<col width="29%">
</colgroup>
<thead><tr class="header">
<th>Algorithm</th>
<th>Description</th>
<th>Use Case</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>K-means</td>
<td>Creates K spherical clusters</td>
<td>Fast, simple, requires specifying K</td>
</tr>
<tr class="even">
<td>Hierarchical</td>
<td>Builds tree of clusters</td>
<td>Exploring nested structures</td>
</tr>
<tr class="odd">
<td>DBSCAN</td>
<td>Density-based, finds outliers</td>
<td>Arbitrarily shaped clusters</td>
</tr>
<tr class="even">
<td>HDBSCAN</td>
<td>Hierarchical density-based</td>
<td>Auto-determines cluster count</td>
</tr>
</tbody>
</table>
<p><strong>Outlier Reduction:</strong> DBSCAN assigns noise points to
cluster 0. Two strategies available via <code>outlier_strategy</code>
(follows BERTopic methodology):</p>
<ul>
<li>
<code>"centroid"</code> (default): Euclidean distance to nearest
centroid in UMAP space</li>
<li>
<code>"embeddings"</code>: Cosine similarity in original
high-dimensional embedding space</li>
</ul>
<p>Set <code>reduce_outliers = TRUE</code> (default) to enable outlier
reassignment.</p>
<p><strong>Usage:</strong> Choose discovery mode (Automatic, Manual,
Advanced). Select semantic feature space and algorithm. Automatic mode
finds optimal cluster count. Use visualizations and quality metrics to
evaluate results.</p>
<p><strong>Learn More:</strong> <a href="https://scikit-learn.org/stable/modules/clustering.html" class="external-link">scikit-learn
Clustering Guide</a></p>
</details><hr>
<details><summary><strong>Dimensionality Reduction</strong>
</summary><p>Dimensionality reduction transforms high-dimensional data into 2D or
3D visualizations while preserving the structure and relationships
between documents.</p>
<p><strong>Algorithms:</strong></p>
<table class="table">
<colgroup>
<col width="30%">
<col width="36%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th>Algorithm</th>
<th>Description</th>
<th>Trade-offs</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>PCA</td>
<td>Principal Component Analysis, finds linear patterns</td>
<td>Fast, interpretable</td>
</tr>
<tr class="even">
<td>t-SNE</td>
<td>Preserves local structure, reveals clusters</td>
<td>Slow, good for visualization</td>
</tr>
<tr class="odd">
<td>UMAP</td>
<td>Balances local and global structure</td>
<td>Faster than t-SNE, better topology</td>
</tr>
</tbody>
</table>
<p><strong>Usage:</strong> Select a semantic feature space (words,
n-grams, or embeddings), then choose a reduction method. Adjust
parameters (perplexity, neighbors, dimensions) based on your data size
and structure. Use for visual exploration before clustering.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/reduce_dimensions.html">reduce_dimensions</a></span><span class="op">(</span><span class="va">embeddings</span>, method <span class="op">=</span> <span class="st">"umap"</span>, n_components <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_semantic_viz.html">plot_semantic_viz</a></span><span class="op">(</span><span class="va">reduced</span>, plot_type <span class="op">=</span> <span class="st">"dimensionality_reduction"</span><span class="op">)</span></span></code></pre></div>
<p><strong>Learn More:</strong> <a href="https://scikit-learn.org/stable/modules/manifold.html" class="external-link">scikit-learn
Manifold Learning</a></p>
</details><hr>
</div>
</div>
<div class="section level2">
<h2 id="network-analysis">Network Analysis<a class="anchor" aria-label="anchor" href="#network-analysis"></a>
</h2>
<p>Visualize word relationships as interactive networks with community
detection.</p>
<div class="section level3">
<h3 id="word-co-occurrence-network">Word Co-occurrence Network<a class="anchor" aria-label="anchor" href="#word-co-occurrence-network"></a>
</h3>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">network</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/word_co_occurrence_network.html">word_co_occurrence_network</a></span><span class="op">(</span></span>
<span>  <span class="va">dfm_object</span>,</span>
<span>  co_occur_n <span class="op">=</span> <span class="fl">10</span>,                    <span class="co"># Minimum co-occurrence count</span></span>
<span>  top_node_n <span class="op">=</span> <span class="fl">30</span>,                    <span class="co"># Top nodes to display</span></span>
<span>  node_label_size <span class="op">=</span> <span class="fl">22</span>,               <span class="co"># Font size (12-40)</span></span>
<span>  community_method <span class="op">=</span> <span class="st">"leiden"</span>         <span class="co"># Community detection algorithm</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">network</span><span class="op">$</span><span class="va">plot</span>   <span class="co"># Interactive visNetwork plot</span></span>
<span><span class="va">network</span><span class="op">$</span><span class="va">table</span>  <span class="co"># Node metrics (degree, eigenvector, community)</span></span>
<span><span class="va">network</span><span class="op">$</span><span class="va">stats</span>  <span class="co"># 9 network statistics</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="word-correlation-network">Word Correlation Network<a class="anchor" aria-label="anchor" href="#word-correlation-network"></a>
</h3>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corr_network</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/word_correlation_network.html">word_correlation_network</a></span><span class="op">(</span></span>
<span>  <span class="va">dfm_object</span>,</span>
<span>  common_term_n <span class="op">=</span> <span class="fl">20</span>,                 <span class="co"># Minimum term frequency</span></span>
<span>  corr_n <span class="op">=</span> <span class="fl">0.4</span>,                       <span class="co"># Minimum correlation threshold</span></span>
<span>  community_method <span class="op">=</span> <span class="st">"leiden"</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="category-specific-analysis">Category-Specific Analysis<a class="anchor" aria-label="anchor" href="#category-specific-analysis"></a>
</h3>
<p>Enable per-category networks in the Shiny app to generate separate
networks for each category, displayed in a tabbed interface.</p>
<hr>
<details><summary><strong>Network Statistics (9 Metrics)</strong>
</summary><p>Each network returns comprehensive statistics:</p>
<table class="table">
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>Metric</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Nodes</td>
<td>Total unique words in network</td>
</tr>
<tr class="even">
<td>Edges</td>
<td>Total connections between nodes</td>
</tr>
<tr class="odd">
<td>Density</td>
<td>Proportion of possible edges present (0-1)</td>
</tr>
<tr class="even">
<td>Diameter</td>
<td>Longest shortest path in network</td>
</tr>
<tr class="odd">
<td>Global Clustering</td>
<td>Overall network clustering tendency</td>
</tr>
<tr class="even">
<td>Avg Local Clustering</td>
<td>Average of local clustering coefficients</td>
</tr>
<tr class="odd">
<td>Modularity</td>
<td>Quality of community structure (higher = better separation)</td>
</tr>
<tr class="even">
<td>Assortativity</td>
<td>Tendency of similar nodes to connect</td>
</tr>
<tr class="odd">
<td>Avg Path Length</td>
<td>Average distance between nodes</td>
</tr>
</tbody>
</table></details><hr>
<details><summary><strong>Community Detection Methods</strong>
</summary><p>Community detection identifies clusters of semantically related
nodes.</p>
<table class="table">
<colgroup>
<col width="25%">
<col width="41%">
<col width="32%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Description</th>
<th>Best For</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>leiden</code></td>
<td>Modern algorithm, guarantees well-connected communities</td>
<td>Default, best quality</td>
</tr>
<tr class="even">
<td><code>louvain</code></td>
<td>Fast modularity optimization</td>
<td>Large networks</td>
</tr>
<tr class="odd">
<td><code>label_prop</code></td>
<td>Propagates labels through network</td>
<td>Very large networks</td>
</tr>
<tr class="even">
<td><code>fast_greedy</code></td>
<td>Hierarchical agglomerative</td>
<td>Quick exploration</td>
</tr>
</tbody>
</table>
<p><strong>Learn More:</strong> <a href="https://igraph.org/r/doc/communities.html" class="external-link">igraph Community
Detection</a></p>
</details><hr>
</div>
</div>
<div class="section level2">
<h2 id="temporal-analysis">Temporal Analysis<a class="anchor" aria-label="anchor" href="#temporal-analysis"></a>
</h2>
<p>Track themes over time:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">temporal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/temporal_semantic_analysis.html">temporal_semantic_analysis</a></span><span class="op">(</span></span>
<span>  texts <span class="op">=</span> <span class="va">united_tbl</span><span class="op">$</span><span class="va">united_texts</span>,</span>
<span>  timestamps <span class="op">=</span> <span class="va">united_tbl</span><span class="op">$</span><span class="va">year</span></span>
<span><span class="op">)</span></span></code></pre></div>
<hr>
<details><summary><strong>Embedding Models</strong>
</summary><table class="table">
<thead><tr class="header">
<th>Model</th>
<th>Speed</th>
<th>Quality</th>
<th>Use Case</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>all-MiniLM-L6-v2</td>
<td>Fast</td>
<td>Good</td>
<td>General purpose</td>
</tr>
<tr class="even">
<td>all-mpnet-base-v2</td>
<td>Slow</td>
<td>Best</td>
<td>Highest quality</td>
</tr>
<tr class="odd">
<td>paraphrase-multilingual</td>
<td>Medium</td>
<td>Good</td>
<td>Multiple languages</td>
</tr>
</tbody>
</table>
<p><strong>Learn More:</strong> <a href="https://www.sbert.net/docs/pretrained_models.html" class="external-link">Sentence
Transformers Models</a></p>
</details><hr>
</div>
<div class="section level2">
<h2 id="next-steps">Next Steps<a class="anchor" aria-label="anchor" href="#next-steps"></a>
</h2>
<ul>
<li><a href="topic_modeling.html">Topic Modeling</a></li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Mikyung Shin.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
